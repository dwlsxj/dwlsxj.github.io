{"meta":{"title":"BattleHeart","subtitle":"个人博客","description":"专注于技术的分享","author":"BattleHeart","url":"https://www.battleheart.cn","root":"/"},"pages":[{"title":"关于我","date":"2018-10-01T14:01:41.000Z","updated":"2018-10-06T07:21:43.931Z","comments":true,"path":"about/index.html","permalink":"https://www.battleheart.cn/about/index.html","excerpt":"","text":"学校：湖北工程学院专业：电子信息科学与技术职位：Java开发工程师联系方式：dwlsxj#126.comQQ: 272156767个人爱好：对技术情有独钟，平时喜欢研究一些技术内容。也逐步将其形成文档，方便后面的学习以及交流。","author":"BattleHeart"},{"title":"404 Not Found：该页无法显示","date":"2018-12-11T05:26:53.105Z","updated":"2018-10-01T13:51:09.892Z","comments":false,"path":"/404.html","permalink":"https://www.battleheart.cn//404.html","excerpt":"","text":""},{"title":"留言","date":"2016-02-01T12:29:57.000Z","updated":"2018-09-20T14:11:08.406Z","comments":true,"path":"comment/index.html","permalink":"https://www.battleheart.cn/comment/index.html","excerpt":"","text":""},{"title":"实验室","date":"2016-02-01T12:29:57.000Z","updated":"2018-09-21T07:35:15.200Z","comments":true,"path":"lab/index.html","permalink":"https://www.battleheart.cn/lab/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-10-01T13:24:53.000Z","updated":"2018-10-01T13:24:53.815Z","comments":true,"path":"tags/index.html","permalink":"https://www.battleheart.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Semaphore信号量之AQS共享锁-非公平模式","slug":"Semaphore","date":"2019-08-24T08:40:52.000Z","updated":"2019-08-25T08:42:08.978Z","comments":true,"path":"2019/08/24/Semaphore/","link":"","permalink":"https://www.battleheart.cn/2019/08/24/Semaphore/","excerpt":"","text":"目录[TOC] 介绍之前我们已经讲解过关于AQS的独占锁，这一章节主要讲解AQS的共享锁，以Semaphore信号量来进行讲解，相信通过看了本章节内容的同学可以对AQS的共享模式有一个了解，Semaphore信号量提供了用于控制资源同时被访问的个数，也就是它会维护一个许可证，访问资源之前需要申请许可证，申请许可证成功后才可以进行访问，如果申请访问资源获取的了许可证，则可以进行资源访问，同时颁发许可证中心的许可证会进行增加，等到访问资源的线程释放资源后，许可证使用情况会进行减少。 例子1234567891011121314151617181920212223public class SemaphoreDemo &#123; private static final Semaphore semaphore = new Semaphore(3); private static final AtomicInteger atomicInteger = new AtomicInteger(); public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); System.out.println(Thread.currentThread().getName() + \"开始执行\"); Thread.sleep(100); System.out.println(Thread.currentThread().getName() + \"执行完毕\"); semaphore.release(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); &#125; &#125;&#125; 运行结果如下： 12345678910pool-1-thread-2开始执行pool-1-thread-3开始执行pool-1-thread-1开始执行pool-1-thread-4开始执行pool-1-thread-6开始执行pool-1-thread-5开始执行pool-1-thread-7开始执行pool-1-thread-9开始执行pool-1-thread-8开始执行pool-1-thread-10开始执行 通过一个例子来拨开Semaphore的面纱，上面我们定义了信号量为3个，也就是同时可以获得锁的线程只有3个，通过调用semaphore.acquire();申请信号量，如果申请成功则执行下面的逻辑，在后面通过semaphore.release();释放掉信号量的占用，也就是说通过semaphore.acquice从信号量中获取一个许可，如果许可通过则执行下面的语句，如果没有许可可发放则等待，然后通过semaphore.release();归还一个许可，上面例子中的输出内容也可清晰的看到同事只有两个线程能够访问资源。 借助图示来说明一下： 首先初始化的时候下面图示内容是放置了3个许可证，如下图所示： 左边是线程，中间是要访问的资源文件，最右侧代表的是许可证池，当第一个线程尝试访问资源时，需要先从信号量中获得一个许可，如果信号量中可以获得许可则可以访问资源，如果没有许可可以颁发则表示需要等待，下面来看一下操作： 首先线程1访问资源时，在没有许可的访问时，是行不通的，是需要先进行许可的申请，申请成功后才可以访问资源，此时信号量中的许可会进行减少，看上图中只剩下了两个许可，如果四个线程同时访问时必然会有一个线程处于等待状态，如下图所示： 如上图所示中间两个线程简化了申请的过程，直接拥有许可访问权限，如果申请许可失败了，则会等待其他线程归还许可，发现线程4正在等待许可中，当其他线程调用release方法后会将许可归还给信号量中，如下图所示： 这是线程4发现已经有可用的许可了，他就会不在等待拿着许可赶紧去访问资源，这里我就不再画图了，和上面一样，大致我们已经了解了关于信号量的内容，接下来我们就要对源码进行分析。 源码分析Semaphore方法介绍Semaphore`主要方法有以下内容： 方法名 描述 acquire() 尝试获得一个准入许可，如无法获得，则线程等待，直到有线程释放一个许可或当线程被中断。 acquire(int permits) 尝试获得permits个准入许可，如无法获得，则线程等待，直到有线程释放permits个许可或当线程被中断。 acquireUninterruptibly() 尝试获得一个准入许可，如无法获得，则线程等待，直到有线程释放一个许可，但是不响应中断请求 acquireUninterruptibly(int permits) 尝试获得permits个准入许可，如无法获得，则线程等待，直到有线程释放permits个许可，但是不响应中断请求 release() 用于在线程访问资源结束后，释放一个许可，以使其他等待许可的线程可以进行资源访问。 release(int permits) 用于在线程访问资源结束后，释放permits个许可，以使其他等待许可的线程可以进行资源访问。 tryAcquire() 尝试获得一个许可，如果获得许可成功返回true，如果失败则返回fasle，它不会等待，立即返回 tryAcquire(int permits) 尝试获得permits个许可，如果获得许可成功返回true，如果失败则返回fasle，它不会等待，立即返回 tryAcquire(int permits, long timeout, TimeUnit unit) 尝试在指定时间内获得permits个许可，如果在指定时间内没有获得许可则则返回false，反之返回true tryAcquire(long timeout, TimeUnit unit) 尝试在指定时间内获得一个许可，如果在指定时间内没有获得许可则则返回false，反之返回true availablePermits()： 当前可用的许可数 获得信号量通过上面方法的大致介绍，Semaphore提供了对信号量获取的操作，获取的过程中有等待操作，也有立即返回的方法，有的响应中断有的又不响应中断，下面会以一些简单的例子，进行分析一下源码内容，针对下面的例子来进行分析： 123456789101112131415161718192021222324public class SemaphoreDemo &#123; private static final Semaphore semaphore = new Semaphore(1); private static final AtomicInteger atomicInteger = new AtomicInteger(); public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 2; i++) &#123; Thread.sleep(100); executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); System.out.println(Thread.currentThread().getName() + \"开始执行\"); Thread.sleep(10); System.out.println(Thread.currentThread().getName() + \"执行完毕\");// semaphore.release(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); &#125; &#125;&#125; 针对上面的例子，我们先初始化了1个信号量，线程池提交了2个任务，这时候大家也想到了运行结果，运行结果就是只有1一个线程能够执行完毕，其余的线程都需要等到操作，因为信号量被消耗了，下面是输出结果： 12pool-1-thread-1开始执行pool-1-thread-1执行完毕 我们这里特别在提交到线程池任务的时候睡眠了一会，其实想要达到的目的是能够让每个线程执行按照顺序排下去，不然可能顺序就不定了，当然也没有太大影响，这里只是为了方便分析，当第一个线程提交任务到线程池时，它会先经过semaphore.acquire()方法来进行获得一个许可操作，下面我们来看一下源码： 123public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125; 我们可以看到它调用了sync.acquireSharedInterruptibly(1)方法，这个snyc其实是Semaphore内部类Sync的实例对象，那么问题来了，这个sync变量是什么时候初始化的呢？其实当我们初始化Semaphore，就已经将sync变量初始化了，接下来我们看一下Semaphore构造函数： 12345678// 非公平模式public Semaphore(int permits) &#123; sync = new NonfairSync(permits);&#125;// fair=true为公平模式，false=非公平模式public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits);&#125; 构造函数一：初始化信号量数量为permits个，并采用非公平模式 构造函数二：如果指定fair为true，则采用公平模式，如果指定为false，则采用非公平模式，并且初始化信号量数量为permits个。 12345678910111213141516171819202122232425262728293031323334353637/** * 非公平模式 */static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = -2694183684443567898L; NonfairSync(int permits) &#123; super(permits); &#125; //实现AQS的tryAcquireShared方法，尝试获得锁。 protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires); &#125;&#125;/** * 公平模式 */static final class FairSync extends Sync &#123; private static final long serialVersionUID = 2014338818796000944L; FairSync(int permits) &#123; super(permits); &#125; //实现AQS的tryAcquireShared方法，尝试获得锁。 protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; if (hasQueuedPredecessors()) return -1; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125;&#125; 我们可以发现Semaphore提供了两种模式的锁机制，一种是公平模式，一种是非公平模式，公平模式其实就是如果发现了有线程在排队等待，则自觉到后面去排队，而非公平模式则不一样，它不管你有没有在排队的线程，谁先抢到是谁的，说到这里我们发现上例子中当声明Semaphore时，其实默认使用了非公平模式NonfairSync，指定了信号量数量为1个，其实它内部Sync中调用了AQS的setState方法，设置同步器状态state为1，详细如下图所示： 接下来我们在回到acquire方法中，它调用了sync.acquireSharedInterruptibly(1);，细心地朋友会发现NonfairSync和父类Sync中并没有该方法，其实该方法是AQS提供的方法，接下来我们看一下这个方法到底做了什么？源码内容如下所示： 1234567public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) //如果线程被中断则抛出异常。 throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) //尝试获取信号量，如果获得信号量小于0，则代表获取失败则运行下面的语句。 doAcquireSharedInterruptibly(arg); //将当前线程节点加入到队列中，等到其他线程释放信号量。&#125; 先对线程进行判断是否被中断，如果被中断则相应中断，抛出InterruptedException异常。 尝试获得信号量，如果信号量已经小于0，则代表没有信号量可以获取，获取失败，则会运行doAcquireSharedInterruptibly方法，将当前线程挂起等待其他线程释放信号量。 接下来我们看一下tryAcquireShared方法实现，tryAcquireShared这个方法是AQS提供给子类实现的方法，它自身并没有实现，只是抛出了异常，实现它的类必然是Semaphore的Sync类，我们发现实现该方法有两个，包括非公平模式的NonfairSync，另外一个是公平模式下的FairSync，由于我们上例子中采用的是非公平模式，我们看一下非公平模式下的tryAcquireShared实现逻辑： 123protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires);&#125; 它（NonfairSync）内部调用了父类Sync的nonfairTryAcquireShared方法，继续刨根问底看一下这个方法： 1234567891011121314final int nonfairTryAcquireShared(int acquires) &#123; //这里上来就是个死循环 for (;;) &#123; //获取可用的信号量数量。 int available = getState(); //剩余线程数，其实就是当前可用信号量数量-申请的信号量数量 int remaining = available - acquires; //1. 如果剩余信号量数量小于0，代表没有信号量可用 //2. 修改state成功，则代表申请信号量成功。 if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125;&#125; 如果读过前面ReentrantLock源码的朋友会发现，它对state是增加的，也就是如果state值被设置上了值，则代表已经有线程获得了锁，其他线程不允许获取当前锁，如果是当前线程重新获得锁，则state值会增加，这也是重入锁的关键点，而Semaphore与之不同点在于，它是对state同步器状态进行减少操作，换句话说先初始化若干信号量，如果获得信号量时，剩余信号量小于0，则代表没有可用的信号量，则直接返回，如果获得信号量成功则对state值进行修改，回到上面的例子中，我们刚分析道其中第一个线程，第一个线程获得到了信号量，此时剩余信号量为0，它会将state值设置为0，设置之后回到了acquireSharedInterruptibly的if (tryAcquireShared(arg) &lt; 0)语句中，if语句为true，不进入到if语句内部，此时AQS的情况如下图所示： 第一个线程情况运行结束，但是他并没有释放信号量，接下来就要对第二个线程，当第二个线程开始运行的时候，它也会重复线程1的操作，首先先去申请信号量，当然当它在申请信号量的时候，发现state已经变成0了，当它执行到tryAcquireShared去获取信号量时，可用信号量为0个，当可用信号量减去申请的信号量个数1时，此时剩余信号量变成了-1，所以这时候if语句的条件remaining &lt; 0是满足的，进入到if语句中，返回的是剩余信号量-1，此时会跳转到调用地方，也就是AQS的acquireSharedInterruptibly方法中，这时候发现if语句中（tryAcquireShared(arg) &lt; 0）返回结果是-1，会进入到if语句内部执行doAcquireSharedInterruptibly方法，这个方法主要操作是将当前线程放入到等待队列中，等到其他线程释放信号量，接下来慢慢剖析一下内部源码AQS-&gt;doAcquireSharedInterruptibly： 1234567891011121314151617181920212223242526272829/** * Acquires in shared interruptible mode. * @param arg the acquire argument */private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); //将节点添加到队列中 boolean failed = true; //失败标志位，如果出现中断，或者异常抛出时会进行取消操作 try &#123; for (;;) &#123; final Node p = node.predecessor(); //获取当前节点的前节点 if (p == head) &#123; //如果当前节点的前节点为头节点 int r = tryAcquireShared(arg); //尝试获得锁 if (r &gt;= 0) &#123; //如果可以获得信号量 setHeadAndPropagate(node, r); //设置当前节点为头节点 p.next = null; // help GC //帮助GC回收 failed = false; //设置失败为false，也就是正常获取 return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 这时候当我们的程序运行到addWaiter，来看一下这个时候队列的情况： 上图内容是第二个线程获取信号量时，获取失败，则加入到队列的情况，首先入队的时候如果队列为空，它会先新建一个Node节点，这个节点Ref-405是头节点，然后再将当前线程的节点指向头节点也就是上图中所示内容，因为这里addWaiter内部代码和之前分析的AQS的独占锁（也就是ReentrantLock源码）的时候已经分析过了，这里就不在赘述了，将线程加入到等待队列中之后，接下来进入到for死循环中去，首先上来获取当前节点的头节点，也就是上图的Ref-405,然后判断是不是头节点，这里面的内容其实就是再去尝试争抢一下信号量，看有没有信号量释放，如果返回的信号量剩余个数大于等于0，则代表争抢信号量成功，需要对节点进行处理，但是我们这个例子中，当进行tryAcquireShared时，返回的值是-1，所以获取信号量失败，不会进入到下面内容，但是我们在这里先进行分析分析一下这个方法setHeadAndPropagate，为后面埋下伏笔： 1234567891011121314//从方法中也可以看出来大致意思是设置头节点，并且根据条件是否唤醒后继节点。private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // 记录一下原来的head头节点。 setHead(node); // 设置新的节点设置为头节点。 if (propagate &gt; 0 || //如果有信号量 h == null || //头节点为空情况下 h.waitStatus &lt; 0 || //如果原来的头结点的状态是负数，这里指的是SIGNAL和PROPAGATE两个状态 (h = head) == null || // 重新阅读头节点防止额外的竞争。 h.waitStatus &lt; 0) &#123; //如果原来的头结点的状态是负数，这里指的是SIGNAL和PROPAGATE两个状态 Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; 判断是否还有信号量的存在，如果有则释放队列中等待的线程 如果原来的头结点的状态是负数，这里指的是SIGNAL和PROPAGATE两个状态 重新阅读头节点防止额外的竞争。 当他没有进入到setHeadAndPropagate方法，它会走下面的步骤： 123if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); shouldParkAfterFailedAcquire将头节点修改为SIGNAL，parkAndCheckInterrupt将线程进行阻塞，运行到这里是线程被挂起，等待其他线程唤醒，此时队列状态如下所示： 释放信号量当我们调用semaphore.release()进行释放信号量时，它其实调用的是AbstractQueuedSynchronizer中的releaseShared(int arg)方法，我们来看一下源码内容： 123public void release() &#123; sync.releaseShared(1);&#125; 接下来分析一下AQS中的releaseShared方法： 123456789public final boolean releaseShared(int arg) &#123; // 调用Semaphore实现的tryReleaseShared方法。 if (tryReleaseShared(arg)) &#123; // 唤醒后记节点 doReleaseShared(); return true; &#125; return false;&#125; 先进尝试释放信号量，如果信号量释放成功，则进行调用doReleaseShared来进行唤醒等待的节点，告知队列中等待的节点已经有信号量了可以进行获取了。 12345678910111213protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; // 获取当前的state值 int current = getState(); // 将当前的state值添加releases个信号量 int next = current + releases; if (next &lt; current) // overflow throw new Error(\"Maximum permit count exceeded\"); // cas修改state值 if (compareAndSetState(current, next)) return true; &#125;&#125; 其实最主要的方法是方法是doReleaseShared方法，我们来看一下源码： 12345678910111213141516171819202122232425/** * 唤醒队列中的节点，以及修改头结点的waitStatus状态为PROPAGATE * 1. 如果头节点等待状态为SIGNAL，则将头节点状态设为0，并唤醒后继节点 * 2. 如果头节点等待状态为0，则将头节点状态设为PROPAGATE，保证唤醒能够正常传播下去。 */private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; // 如果头结点的状态为SIGNAL则进行唤醒操作。 if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; // 如果头节点状态为0，则将头节点状态修改为PROPAGATE，至于为什么会变成0，为什么要有PROPAGATE？，请看下文。 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; PROPAGATE状态存在的意义这里可能大家会有一个疑问，为什么不是直接propagate &gt; 0，然后就直接唤醒下一个节点呢？这里我要引用一下之前的版本中的一个bug来说明一下： BUG-6801020 根据BUG中的描述影响的版本号是 JDK 6u11,6u17 两个版本，BUG中提及到了复现bug的代码如下所示： 1234567891011121314151617181920212223242526272829303132333435363738import java.util.concurrent.Semaphore;public class TestSemaphore &#123; private static Semaphore sem = new Semaphore(0); private static class Thread1 extends Thread &#123; @Override public void run() &#123; sem.acquireUninterruptibly(); &#125; &#125; private static class Thread2 extends Thread &#123; @Override public void run() &#123; sem.release(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; for (int i = 0; i &lt; 10000000; i++) &#123; Thread t1 = new Thread1(); Thread t2 = new Thread1(); Thread t3 = new Thread2(); Thread t4 = new Thread2(); t1.start(); t2.start(); t3.start(); t4.start(); t1.join(); t2.join(); t3.join(); t4.join(); System.out.println(i); &#125; &#125;&#125; 接下来看一下受影响版本号中的setHeadAndPropagate 和releaseShared两个方法源码，如下： 1234567891011121314151617181920212223private void setHeadAndPropagate(Node node, int propagate) &#123; setHead(node); // 这里是区别点，他这里直接是比较的信号量如果存在，并且当前节点的等待状态不等于0，才会去唤醒下一个线程。 if (propagate &gt; 0 &amp;&amp; node.waitStatus != 0) &#123; /* * Don't bother fully figuring out successor. If it * looks null, call unparkSuccessor anyway to be safe. */ Node s = node.next; if (s == null || s.isShared()) unparkSuccessor(node); &#125;&#125;public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 在JDK JDK 6u11,6u17 版本中发现中是没有PROPAGATE这种状态的，在后面的版本中引入是为了解决共享模式下并发释放导致的线程hang住问题，上面例子运行一段时间后，偶尔会出现线程hang住的情况。上面例子中初始化了四个线程，信号量初始化时是0个，t1线程和t2线程是获取信号量，t3和t4线程是释放信号量，假设某种情况极端的情况下t1和t2添加到了队列中，如下图所示： t1时刻的时候，t3线程调用了releaseShared方法，会调用unparkSuccessor，这个方法是用来通知等待线程，此时head中的waitStatus由-1变成0，然后唤醒线程t1，此时信号量为1。 由于线程t1刚刚被唤醒，它的头节点还没有进行切换，因为我们在上文中可以直到在线程等待的时候是doAcquireSharedInterruptibly方法里面，当线程唤醒的时候也是从这个方法中进行执行，当t1线程尝试获得信号量时，发现可以获得信号量，tryAcquireShared返回的是0，因为消耗了一个信号量，而此时当前线程没有进行继续往下操作，而是进行了线程切换，此时线程状态如下： 此时切换到t4线程，t4调用releaseShared，此时头节点的waitStatus=0，直接返回false，并未调用unparkSuccessor，但是此时信号量变成了1。 此时t1线程被唤醒，继续执行将head节点指向了Ref-505，并且当时的信号量只有1个，他自己消耗了信号量，虽然现在state=1，但是我们可以看线程切换时，信号量的state=0，所以线程切换回去之后，它的propagate=0，调用setHeadAndPropagate方法的时候，他没有进入到if语句的内部，所以t2线程一直没有被唤醒，导致主线程挂起。 jdk1.8中的setHeadAndPropagate并没有直接调用unparkSuccessor方法，而是修改调用doReleaseShared方法，我们来看一下这个方法跟上面bug中有什么区别： 123456789101112131415161718192021222324252627282930313233/** * 1.唤醒队列中的节点 * 2.如果队列头节点waitStatus=0，则将当前head头节点修改为PROPAGATE(-3)状态 */private void doReleaseShared() &#123; /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; 这里我们回到上面第三步，此时切换到t4线程，t4调用releaseShared，此时头节点的waitStatus=0，直接返回false，并未调用unparkSuccessor，但是此时信号量变成了1，并且将head头节点的waitStatus状态修改为-3。 回到上面第四步骤：此时t1线程被唤醒，继续执行将head节点指向了Ref-505，并且当时的信号量只有1个，他自己消耗了信号量，虽然现在state=1，但是我们可以看线程切换时，信号量的state=0，所以线程切换回去之后，它的propagate=0，调用setHeadAndPropagate方法的时候，此时head头节点的状态是PROPAGATE(-3),会进入到if语句中执行doReleaseShared方法，此时唤醒线程t2。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://www.battleheart.cn/tags/并发编程/"},{"name":"多线程","slug":"多线程","permalink":"https://www.battleheart.cn/tags/多线程/"}]},{"title":"Java线程池原理浅析","slug":"java-thread-pool-principle","date":"2019-06-13T14:58:38.000Z","updated":"2019-08-25T08:18:53.036Z","comments":true,"path":"2019/06/13/java-thread-pool-principle/","link":"","permalink":"https://www.battleheart.cn/2019/06/13/java-thread-pool-principle/","excerpt":"","text":"什么是线程池？为了避免频繁重复的创建和销毁线程，我们可以让这些线程进行复用，在线程池中，总会有活跃的线程在占用，但是线程池中也会存在没有占用的线程，这些线程处于空闲状态，当有任务的时候会从池子里面拿去一个线程来进行使用，当完成工作后，并没有销毁线程，而是将将线程放回到池子中去。 线程池主要解决两个问题： 一是当执行大量异步任务时线程池能够提供很好的性能。 二是线程池提供了一种资源限制和管理的手段，比如可以限制现成的个数，动态新增线程等。 ​ -《Java并发编程之美》 上面内容出自《Java并发编程之美》这本书，第一个问题上面已经提到过，线程的频繁创建和销毁是很损耗性能的，但是线程池中的线程是可以复用的，可以较好的提升性能问题，线程池内部是采用了阻塞队列来维护Runnable对象。 原理分析JDK为我们封装了一套操作多线程的框架Executors，帮助我们可以更好的控制线程池，Executors下提供了一些线程池的工厂方法： newFixedThreadPool：返回固定长度的线程池，线程池中的线程数量是固定的。 newCacheThreadPool：该方法返回一个根据实际情况来进行调整线程数量的线程池，空余线程存活时间是60s newSingleThreadExecutor：该方法返回一个只有一个线程的线程池。 newSingleThreadScheduledExecutor：该方法返回一个SchemeExecutorService对象，线程池大小为1，SchemeExecutorService接口在ThreadPoolExecutor类和 ExecutorService接口之上的扩展，在给定时间执行某任务。 newSchemeThreadPool：该方法返回一个SchemeExecutorService对象，可指定线程池线程数量。 对于核心的线程池来说，它内部都是使用了ThreadPoolExecutor对象来实现的，只不过内部参数信息不一样，我们先来看两个例子：nexFixedThreadPool和newSingleThreadExecutor如下所示： 12345678910111213public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory);&#125;public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 由上面的线程池的创建过程可以看到它们都是ThreadPoolExecutor的封装，接下来我们来看一下ThreadPoolExecutor的参数说明： 参数名称 参数描述 corePoolSize 指定线程池线程的数量 maximumPoolSize 指定线程池中线程的最大数量 keepAliveTime 当线程池线程的数量超过corePoolSize的时候，多余的空闲线程存活的时间，如果超过了corePoolSize，在keepAliveTime的时间之后，销毁线程 unit keepAliveTime的单位 workQueue 工作队列，将被提交但尚未执行的任务缓存起来 threadFactory 线程工厂，用于创建线程，不指定为默认线程工厂DefaultThreadFactory handler 拒绝策略 其中workQueue代表的是提交但未执行的队列，它是BlockingQueue接口的对象，用于存放Runable对象，主要分为以下几种类型： 直接提交的队列：SynchronousQueue队列，它是一个没有容量的队列，前面我有对其进行讲解，当线程池进行入队offer操作的时候，本身是无容量的，所以直接返回false，并没有保存下来，而是直接提交给线程来进行执行，如果没有空余的线程则执行拒绝策略。 有界的任务队列：可以使用ArrayBlockingQueue队列，因为它内部是基于数组来进行实现的，初始化时必须指定容量参数，当使用有界任务队列时，当有任务进行提交时，线程池的线程数量小于corePoolSize则创建新的线程来执行任务，当线程池的线程数量大于corePoolSize的时候，则将提交的任务放入到队列中，当提交的任务塞满队列后，如果线程池的线程数量没有超过maximumPoolSize，则创建新的线程执行任务，如果超过了maximumPoolSize则执行拒绝策略。 无界的任务队列：可以使用LinkedBlockingQueue队列，它内部是基于链表的形式，默认队列的长度是Integer.MAX_VALUE，也可以指定队列的长度，当队列满时进行阻塞操作，当然线程池中采用的是offer方法并不会阻塞线程，当队列满时则返回false，入队成功则则返回true，当使用LinkedBlockingQueue队列时，有任务提交到线程池时，如果线程池的数量小于corePoolSize，线程池会产生新的线程来执行任务，当线程池的线程数量大于corePoolSize时，则将提交的任务放入到队列中，等待执行任务的线程执行完之后进行消费队列中的任务，若后续仍有新的任务提交，而没有空闲的线程时，它会不断往队列中入队提交的任务，直到资源耗尽。 优先任务队列：t有限任务队列是带有执行优先级的队列，他可以使用PriorityBlockingQueue队列，可以控制任务的执行先后顺序，它是一个无界队列，该队列可以根据任务自身的优先级顺序先后执行，在确保性能的同时，也能有很好的质量保证。 上面讲解了关于线程池内部都是通过ThreadPoolExecutor来进行实现的，那么下面我以一个例子来进行源码分析： 1234567891011121314151617181920public class ThreadPoolDemo1 &#123; public static void main(String[] args) &#123; ExecutorService executorService = new ThreadPoolExecutor(5, 10, 60L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;&gt;(5), new CustomThreadFactory()); for (int i = 0; i &lt; 15; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; Thread.sleep(50000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"由线程：\" + Thread.currentThread().getName() + \"执行任务完成\"); &#125;); &#125; &#125;&#125; 上面定义了一个线程池，线程池初始化的corePoolSize为5，也就是线程池中线程的数量为5，最大线程maximumThreadPoolSize为10，空余的线程存活的时间是60s，使用ArrayBlockingQueue来作为阻塞队列，这里还发现我自定义了ThreadFactory线程池工厂，这里我真是针对线程创建的时候输出线程池的名称，源码如下所示： 123456789101112131415161718192021222324252627282930313233/** * 自定义的线程池构造工厂 */public class CustomThreadFactory implements ThreadFactory &#123; private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; public CustomThreadFactory() &#123; SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = \"pool-\" + poolNumber.getAndIncrement() + \"-thread-\"; &#125; @Override public Thread newThread(Runnable r) &#123; String name = namePrefix + threadNumber.getAndIncrement(); Thread t = new Thread(group, r, name, 0); System.out.println(\"线程池创建，线程名称为：\" + name); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125;&#125; 代码和DefaultThreadFactory一样，只是在newThread新建线程的动作的时候输出了线程池的名称，方便查看线程创建的时机，上面main方法中提交了15个任务，调用了execute方法来进行提交任务，在分析execute方法之前我们先了解一下线程的状态： 1234567891011121314151617181920212223242526//假设Integer类型是32位的二进制表示。//高3位代表线程池的状态，低29位代表的是线程池的数量//默认是RUNNING状态，线程池的数量为0private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));//线程个数位数，表示的Integer中除去最高的3位之后剩下的位数表示线程池的个数private static final int COUNT_BITS = Integer.SIZE - 3;//线程池的线程的最大数量//这里举例是32为机器，表示为00011111111111111111111111111111private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;//线程池的状态// runState is stored in the high-order bits//11100000000000000000000000000000//接受新任务并且处理阻塞队列里面任务private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;//00000000000000000000000000000000//拒绝新任务但是处理阻塞队列的任务private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;//00100000000000000000000000000000//拒接新任务并且抛弃阻塞队列里面的任务，同时会中断正在处理的任务private static final int STOP = 1 &lt;&lt; COUNT_BITS;//01000000000000000000000000000000//所有任务都执行完(包括阻塞队列中的任务)后当线程池活动线程数为0，将要调用terminated方法。private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;//01100000000000000000000000000000//终止状态，terminated方法调用完成以后的状态private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; 通过上面内容可以看到ctl其实存放的是线程池的状态和线程数量的变量，默认是RUNNING，也就是11100000000000000000000000000000，这里我们来假设运行的机器上的Integer的是32位的，因为有些机器上可能Integer并不是32位，下面COUNT_BITS来控制位数，也就是先获取Integer在该平台上的位数，比如说是32位，然后32位-3位=29位，也就是低29位代表的是现成的数量，高3位代表线程的状态，可以清晰看到下面的线程池的状态都是通过低位来进行向左位移的操作的，除了上面的变量，还提供了操作线程池状态的方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 操作ctl变量，主要是进行分解或组合线程数量和线程池状态。// 获取高3位，获取线程池状态private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;// 获取低29位，获取线程池中线程的数量private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;// 组合ctl变量，rs=runStatue代表的是线程池的状态，wc=workCount代表的是线程池线程的数量private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125;/* * Bit field accessors that don't require unpacking ctl. * These depend on the bit layout and on workerCount being never negative. *///指定的线程池状态c小于状态sprivate static boolean runStateLessThan(int c, int s) &#123; return c &lt; s;&#125;//指定的线程池状态c至少是状态sprivate static boolean runStateAtLeast(int c, int s) &#123; return c &gt;= s;&#125;// 判断线程池是否运行状态private static boolean isRunning(int c) &#123; return c &lt; SHUTDOWN;&#125;/** * CAS增加线程池线程数量. */private boolean compareAndIncrementWorkerCount(int expect) &#123; return ctl.compareAndSet(expect, expect + 1);&#125;/** * CAS减少线程池线程数量 */private boolean compareAndDecrementWorkerCount(int expect) &#123; return ctl.compareAndSet(expect, expect - 1);&#125;/** * 将线程池的线程数量进行较少操作，如果竞争失败直到竞争成功为止。 */private void decrementWorkerCount() &#123; do &#123;&#125; while (! compareAndDecrementWorkerCount(ctl.get()));&#125; 下来我们看一下ThreadPoolExecutor对象下的execute方法： 12345678910111213141516171819202122232425262728293031public void execute(Runnable command) &#123; // 判断提交的任务是不是为空，如果为空则抛出NullPointException异常 if (command == null) throw new NullPointerException(); // 获取线程池的状态和线程池的数量 int c = ctl.get(); // 如果线程池的数量小于corePoolSize，则进行添加线程执行任务 if (workerCountOf(c) &lt; corePoolSize) &#123; //添加线程修改线程数量并且将command作为第一个任务进行处理 if (addWorker(command, true)) return; // 获取最新的状态 c = ctl.get(); &#125; // 如果线程池的状态是RUNNING，将命令添加到队列中 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; //二次检查线程池状态和线程数量 int recheck = ctl.get(); //线程不是RUNNING状态，从队列中移除当前任务，并且执行拒绝策略。 //这里说明一点，只有RUNNING状态的线程池才会接受新的任务，其余状态全部拒绝。 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); //如果线程池的线程数量为空时，代表线程池是空的，添加一个新的线程。 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; //如果队列是满的，或者是SynchronousQueue队列时，则直接添加新的线程执行任务，如果添加失败则进行拒绝 //可能线程池的线程数量大于maximumPoolSize则采取拒绝策略。 else if (!addWorker(command, false)) reject(command);&#125; 通过分析execute方法总结以下几点： 当线程池中线程的数量小于corePoolSize时，直接添加线程到线程池并且将当前任务做为第一个任务执行。 如果线程池的状态的是RUNNING，则可以接受任务，将任务放入到阻塞队列中，内部进行二次检查，有可能在运行下面内容时线程池状态已经发生了变化，在这个时候如果线程池状态变成不是RUNNING，则将当前任务从队列中移除，并且进行拒绝策略。 如果阻塞队列已经满了或者SynchronousQueue这种特殊队列无空间的时候，直接添加新的线程执行任务，当线程池的线程数量大于maximumPoolSize时相应拒绝策略。 入队操作用的是offer方法，该方法不会阻塞队列，如果队列已经满时或超时导致入队失败，返回false，如果入队成功返回true。 针对上面例子源码我们来做一下分析，我们源码中阻塞队列采用的是ArrayBlockingQueue队列，并且指定队列的长度是5，我们看下面提交的线程池的任务是15个，而且corePoolSize设置的是5个核心线程，最大线程数（maximumPoolSzie）是10个（包括核心线程数），假设所有任务都同时提交到了线程池中，其中有5个任务会被提交到线程中作为第一个任务进行执行，会有5个任务被添加到阻塞队列中，还有5个任务提交到到线程池中的时候发现阻塞队列已经满了，这时候会直接提交任务，发现当前线程数是5小于最大线程数，可以进行新建线程来执行任务。 这里我们只是假设任务全部提交，因为我们在任务中添加了Thread.sleep睡眠一会，在for循环结束提交任务之后可能才会结束掉任务的睡眠执行任务后面内容，所以可以看做是全部提交任务，但是没有任务完成，如果有任务完成的话，可能就不会是触发最大的线程数，有可能就是一个任务完成后从队列取出来，然后另一个任务来的时候可以添加到队列中，上图中可以看到，有5个核心core线程在执行任务，任务队列中有5个任务在等待空余线程执行，而还有5个正在执行的线程，核心线程是指在corePoolSize范围的线程，而非核心线程指的是大于corePoolSize但是小于等于MaximumPoolSize的线程，就是这些非核心线程并不是一直存活的线程，它会跟随线程池指定的参数来进行销毁，我们这里指定了60s后如果没有任务提交，则会进行销毁操作，当然工作线程并不指定那些线程必须回收那些线程就必须保留，是根据从队列中获取任务来决定，如果线程获取任务时发现线程池中的线程数量大于corePoolSize，并且阻塞队列中为空时，则阻塞队列会阻塞60s后如果还有没有任务就返回false，这时候会释放线程，调用processWorkerExit来处理线程的退出，接下来我们来分析下addWorker都做了什么内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; //获取线程池的状态和线程池线程的数量 int c = ctl.get(); //单独获取线程池的状态 int rs = runStateOf(c); //检查队列是否只在必要时为空 if (rs &gt;= SHUTDOWN &amp;&amp; //线程池的状态是SHUTDOWN、STOP、TIDYING、TERMINATED ! (rs == SHUTDOWN &amp;&amp; //可以看做是rs!=SHUTDOWN,线程池状态为STOP、TIDYING、TERMINATED firstTask == null &amp;&amp; //可以看做firstTask!=null，并且rs=SHUTDOWN ! workQueue.isEmpty())) //可以看做rs=SHUTDOWN，并且workQueue.isEmpty()队列为空 return false; //循环CAS增加线程池中线程的个数 for (;;) &#123; //获取线程池中线程个数 int wc = workerCountOf(c); //如果线程池线程数量超过最大线程池数量，则直接返回 if (wc &gt;= CAPACITY || //如果指定使用corePoolSize作为限制则使用corePoolSize，反之使用maximumPoolSize，最为工作线程最大线程线程数量，如果工作线程大于相应的线程数量则直接返回。 wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; //CAS增加线程池中线程的数量 if (compareAndIncrementWorkerCount(c)) //跳出增加线程池数量。 break retry; //如果修改失败，则重新获取线程池的状态和线程数量 c = ctl.get(); // Re-read ctl //如果最新的线程池状态和原有县城出状态不一样时，则跳转到外层retry中，否则在内层循环重新进行CAS if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; //工作线程是否开始启动标志 boolean workerStarted = false; //工作线程添加到线程池成功与否标志 boolean workerAdded = false; Worker w = null; try &#123; //创建一个Worker对象 w = new Worker(firstTask); //获取worker中的线程，这里线程是通过ThreadFactory线程工厂创建出来的，详细看下面源码信息。 final Thread t = w.thread; //判断线程是否为空 if (t != null) &#123; //添加独占锁，为添加worker进行同步操作，防止其他线程同时进行execute方法。 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //获取线程池的状态 int rs = runStateOf(ctl.get()); //如果线程池状态为RUNNING或者是线程池状态为SHUTDOWN并且第一个任务为空时，当线程池状态为SHUTDOWN时，是不允许添加新任务的，所以他会从队列中获取任务。 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); //添加worker到集合中 workers.add(w); int s = workers.size(); //跟踪最大的线程池数量 if (s &gt; largestPoolSize) largestPoolSize = s; //添加worker成功 workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; //如果添加worker成功就启动任务 if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; //如果没有启动，w不为空就已出worker，并且线程池数量进行减少。 if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; 通过上面addWorker方法可以分为两个部分来进行讲解，第一部分是对线程池中线程数量的通过CAS的方式进行增加，其中第一部分中上面有个if语句，这个地方着重分析下： 12345if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; 可以看成下面的样子，将！放到括号里面，变成下面的样子： 12345if (rs &gt;= SHUTDOWN &amp;&amp; (rs != SHUTDOWN || firstTask != null || workQueue.isEmpty())) return false; 线程池的状态是SHUTDOWN、STOP、TIDYING、TERMINATED 当线程池状态是STOP、TIDYING、TERMINATED时，这些状态的时候不需要进行线程的添加和启动操作，因为如果是上面的状态，其实线程池的线程正在进行销毁操作，意味着线程调用了shutdownNow等方法。 如果线程池状态为SHUTDOWN并且第一个任务不为空时，不接受新的任务，直接返回false，也就是说SHUTDOWN的状态，不会接受新任务，只会针对队列中未完成的任务进行操作。 当线线程池状态为SHUTDOWN并且队列为空时，直接返回不进行任务添加。 上半部分分为内外两个循环，外循环对线程池状态的判断，用于判断是否需要添加工作任务线程，通过上面讲的内容进行判断，后面内循环则是通过CAS操作增加线程数，如果指定了core参数为true，代表线程池中线程的数量没有超过corePoolSize，当指定为false时，代表线程池中线程数量达到了corePoolSize，并且队列已经满了，或者是SynchronousQueue这种无空间的队列，但是还没有达到最大的线程池maximumPoolSize，所以它内部会根据指定的core参数来判断是否已经超过了最大的限制，如果超过了就不能进行添加线程了，并且进行拒绝策略，如果没有超过就增加线程数量。 第二部分主要是把任务添加到worker中，并启动线程，这里我们先来看一下Worker对象。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// 这里发现它是实现了AQS，是一个不可重入的独占锁模式// 并且它还集成了Runable接口，实现了run方法。private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; private static final long serialVersionUID = 6138294804551838833L; /** 执行任务的线程，通过ThreadFactory创建 */ final Thread thread; /** 初始化第一个任务*/ Runnable firstTask; /** 每个线程完成任务的数量 */ volatile long completedTasks; /** * 首先现将state值设置为-1，因为在AQS中state=0代表的是锁没有被占用，而且在线程池中shutdown方法会判断能否争抢到锁，如果可以获得锁则对线程进行中断操作，如果调用了shutdownNow它会判断state&gt;=0会被中断。 * firstTask第一个任务，如果为空则会从队列中获取任务，后面runWorker中。 */ Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; /** 委托调用外部的runWorker方法 */ public void run() &#123; runWorker(this); &#125; //是否独占锁 protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; public void lock() &#123; acquire(1); &#125; public boolean tryLock() &#123; return tryAcquire(1); &#125; public void unlock() &#123; release(1); &#125; public boolean isLocked() &#123; return isHeldExclusively(); &#125; //这里就是上面shutdownNow中调用的线程中断的方法，getState()&gt;=0 void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125;&#125; 可以看到Worker是一个实现了AQS的锁，它是一个不可重入的独占锁，并且他也实现了Runnable接口，实现了run方法，在构造函数中将AQS的state设置为-1，为了避免线程还没有进入runWorker方法前，就调用了shutdown或shutdownNow方法，会被中断，设置为-1则不会被中断。后面我们看到run方法，它调用的是ThreadPoolExecutor的runWorker方法，我们这里回想一下，在addWorker方法中，添加worker到HashSet&lt;Worker&gt;中后，他会将workerAdded设置为true，代表添加worker成功，后面有调用了下面代码： 1234if (workerAdded) &#123; t.start(); workerStarted = true;&#125; 这个t代表的就是在Worker构造函数中的使用ThreadFactory创建的线程，并且将自己（Worker自己）传递了当前线程，创建的线程就是任务线程，任务线程启动的时候会调用Worker下的run方法，run方法内部又委托给外部方法runWorker来进行操作，它的参数传递的是调用者自己，Worker中的run方法如下所示： 123public void run() &#123; runWorker(this); //this指Worker对象本身&#125; 这里简单画一张图来表示下调用的逻辑。 整体的逻辑是先进行创建线程，线程将Worker设置为执行程序，并将线程塞到Worker中，然后再addWorker中将Worker中的线程取出来，进行启动操作，启动后他会调用Worker中的run方法，然后run方法中将调用ThreadPoolExecutor的runWorker，然后runWorker又会调用Worker中的任务firstTask，这个fistTask是要真正执行的任务，也是用户自己实现的代码逻辑。 接下来我们就要看一下runWorker方法里面具体内容： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253final void runWorker(Worker w) &#123; //调用者也就是Worker中的线程 Thread wt = Thread.currentThread(); //获取Worker中的第一个任务 Runnable task = w.firstTask; //将Worker中的任务清除代表执行了第一个任务了，后面如果再有任务就从队列中获取。 w.firstTask = null; //这里还记的我们在new Worker的时候将AQS的state状态设置为-1，这里先进行解锁操作，将state设置为0 w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; //循环进行获取任务，如果第一个任务不为空，或者是如果第一个任务为空，从任务队列中获取任务，如果有任务则返回获取的任务信息，如果没有任务可以获取则进行阻塞，阻塞也分两种第一种是阻塞直到任务队列中有内容，第二种是阻塞队列一定时间之后还是没有任务就直接返回null。 while (task != null || (task = getTask()) != null) &#123; //先获取worker的独占锁，防止其他线程调用了shutdown方法。 w.lock(); // 如果线程池正在停止，确保线程是被中断的，如果没有则确保线程不被中断操作。 if ((runStateAtLeast(ctl.get(), STOP) || //如果线程池状态为STOP、TIDYING、TERMINATED直接拒绝任务中断当前线程 (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; //执行任务之前做一些操作，可进行自定义 beforeExecute(wt, task); Throwable thrown = null; try &#123; //运行任务在这里喽。 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; //执行任务之后做一些操作，可进行自定义 afterExecute(task, thrown); &#125; &#125; finally &#123; //将任务清空为了下次任务获取 task = null; //统计当前Worker完成了多少任务 w.completedTasks++; //独占锁释放 w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; //处理Worker的退出操作，执行清理工作。 processWorkerExit(w, completedAbruptly); &#125;&#125; 我们看到如果Worker是第一次被启动，它会从Worker中获取firstTask任务来执行，然后执行成功后，它会getTask()来从队列中获取任务，这个地方比较有意思，它是分情况进行获取任务的，我们都直到BlockingQueue中提供了几种从队列中获取的方法，这个getTask中使用了两种方式，第一种是使用poll进行获取队列中的信息，它采用的是过一点时间如果队列中仍没有任务时直接返回null，然后还有一个就是take方法，take方法是如果队列中没有任务则将当前线程进行阻塞，等待队列中有任务后，会通知等待的队列线程进行消费任务，让我们看一下getTask方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647private Runnable getTask() &#123; boolean timedOut = false; //poll获取超时 for (;;) &#123; //获取线程池的状态和线程数量 int c = ctl.get(); //获取线程池的状态 int rs = runStateOf(c); //线程池状态大于等于SHUTDOWN //1.线程池如果是大于STOP的话减少工作线程池数量 //2.如果线程池状态为SHUTDOW并且队列为空时，代表队列任务已经执行完，返回null，线程数量减少1 if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; //获取线程池数量。 int wc = workerCountOf(c); //如果allowCoreThreadTimeOut为true，则空闲线程在一定时间未获得任务会清除 //或者如果线程数量大于corePoolSize的时候会进行清除空闲线程 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; //1.如果线程池数量大于最大的线程池数量或者对（空余线程进行清除操作并且poll超时了，意思是队列中没有内容了，导致poll间隔一段时间后没有获取内容超时了。 //2.如果线程池的数量大于1或者是队列已经是空的 //总之意思就是当线程池的线程池数量大于corePoolSize，或指定了allowCoreThreadTimeOut为true，当队列中没有数据或者线程池数量大于1的情况下，尝试对线程池的数量进行减少操作，然后返回null，用于上一个方法进行清除操作。 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; //如果timed代表的是清除空闲线程的意思 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : //等待一段时间如果没有获取到返回null。 workQueue.take(); //阻塞当前线程 //如果队列中获取到内容则返回 if (r != null) return r; //如果没有获取到超时了则设置timeOut状态 timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125; 工作线程调用getTask从队列中进行获取任务。 如果指定了allowCoreThreadTimeOut或线程池线程数量大于corePoolSize则进行清除空闲多余的线程，调用阻塞队列的poll方法，在指定时间内如果没有获取到任务直接返回false。 如果线程池中线程池数量小于corePoolSize或者allowCoreThreadTimeOut为false默认值，则进行阻塞线程从队列中获取任务，直到队列有任务唤醒线程。 我们还记得第一张图中有标记出来是core线程和普通线程，其实这样标记不是很准确，准确的意思是如果线程池的数量超过了corePoolSize并且没有特别指定allowCoreThreadTimeOut的情况下，它会清除掉大于corePoolSize并且小于等于maximumPoolSize的一些线程，标记出core线程的意思是有corePoolSize不会被清除，但是会清除大于corePoolSize的线程，也就是线程池中的线程对获取任务的时候进行判断，也就是getTask中进行判断，如果当前线程池的线程数量大于corePoolSize就使用poll方式获取队列中的任务，当过一段时间还没有任务就会返回null，返回null之后设置timeOut=true，并且获取getTask也会返回null，到此会跳到调用者runWorker方法中，一直在while (task != null || (task = getTask()) != null)此时的getTask返回null跳出while循环语句，设置completedAbruptly = false，表示不是突然完成的而是正常完成，退出后它会执行finally的processWorkerExit(w, completedAbruptly)，执行清理工作。我们来看下源码： 12345678910111213141516171819202122232425262728293031323334private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; if (completedAbruptly) // 如果突然完成则调整线程数量 decrementWorkerCount(); // 减少线程数量1 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); //获取锁,同时只有一个线程获得锁 try &#123; completedTaskCount += w.completedTasks; //统计整个线程池完成的数量 workers.remove(w); //将完成任务的worker从HashSet中移除 &#125; finally &#123; mainLock.unlock(); //释放锁 &#125; //尝试设置线程池状态为TERMINATED //1.如果线程池状态为SHUTDOWN并且线程池线程数量与工作队列为空时，修改状态。 //2.如果线程池状态为STOP并且线程池线程数量为空时，修改状态。 tryTerminate(); // 获取线程池的状态和线程池的数量 int c = ctl.get(); // 如果线程池的状态小于STOP，也就是SHUTDOWN或RUNNING状态 if (runStateLessThan(c, STOP)) &#123; //如果不是突然完成，也就是正常结束 if (!completedAbruptly) &#123; //如果指定allowCoreThreadTimeOut=true(默认false)则代表线程池中有空余线程时需要进行清理操作，否则线程池中的线程应该保持corePoolSize int min = allowCoreThreadTimeOut ? 0 : corePoolSize; //这里判断如果线程池中队列为空并且线程数量最小为0时，将最小值调整为1，因为队列中还有任务没有完成需要增加队列，所以这里增加了一个线程。 if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; //如果当前线程数效益核心个数，就增加一个Worker addWorker(null, false); &#125; 通过上面的源码可以得出，如果线程数超过核心线程数后，在runWorker中就不会等待队列中的消息，而是会进行清除操作，上面的清除代码首先是先对线程池的数量进行较少操作，其次是统计整个线程池中完成任务的数量，然后就是尝试修改线程池的状态由SHUTDOWN-&gt;TIDYING-&gt;TERMINATED或者是由STOP-&gt;TIDYING-&gt;TERMINATED，修改线程池状态为TERMINATED，需要有两个条件： 当线程池线程数量和工作队列为空，并且线程池的状态为SHUTDOWN时，才会将状态进行修改，修改的过程是SHUTDOWN-&gt;TIDYING-&gt;TERMINATED 当线程池的状态为STOP并且线程池数量为空时，才会尝试修改状态，修改过程是STOP-&gt;TIDYING-&gt;TERMINATED 如果设置为TERMINATED状态，还需要调用条件变量termination的signalAll()方法来唤醒所有因为调用awaitTermination方法而被阻塞的线程，换句话说当调用awaitTermination后，只有线程池状态变成TERMINATED才会被唤醒。 接下来我们就来分析一下这个tryTerminate方法，看一下他到底符不符合我们上述说的内容： 1234567891011121314151617181920212223242526272829303132333435363738final void tryTerminate() &#123; for (;;) &#123; // 获取线程池的状态和线程池的数量组合状态 int c = ctl.get(); //这里单独下面进行分析，这里说明两个问题，需要反向来想这个问题。 //1.如果线程池状态STOP则不进入if语句 //2.如果线程池状态为SHUTDOWN并且工作队列为空时，不进入if语句 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; //如果线程池数量不为空时，进行中断操作。 if (workerCountOf(c) != 0) &#123; // Eligible to terminate interruptIdleWorkers(ONLY_ONE); return; &#125; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //修改状态为TIDYING，并且将线程池的数量进行清空 if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; try &#123; //执行一些逻辑，默认是空的 terminated(); &#125; finally &#123; //修改状态为TERMINATED ctl.set(ctlOf(TERMINATED, 0)); //唤醒调用awaitTermination方法的线程 termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // else retry on failed CAS &#125; 我们单独将上面的if语句摘出来进行分析，将上面的第一个if判断进行修改如下，可以看到return在else里面，这时候内部if判断进行转换，转换成如下所示： 1234567if (!isRunning(c) &amp;&amp; !runStateAtLeast(c, TIDYING) &amp;&amp; //只能是SHUTDOWN和STOP (runStateOf(c) != SHUTDOWN || workQueue.isEmpty()))&#123; //这里执行逻辑&#125;else &#123; return;&#125; 逐一分析分析内容如下： !isRunning(c)代表不是RUNNING，则可能的是SHUTDOWN，STOP，TIDYING，TERMINATED这四种状态 中间的连接符是并且的意思，跟着runStateAtLeast(c, TIDYING)这句话的意思是至少是TIDYING，TERMINATED这两个，反过来就是可能是RUNNING，SHUTDOWN，STOP，但是前面已经判断了不能是RUNINNG状态，所以前面两个连在一起就是只能是状态为SHUTDOWN，STOP runStateOf(c) != SHUTDOWN || workQueue.isEmpty()当前面的状态是SHUTDOWN时，则会出发workQueue.isEmpty(),连在一起就是状态是SHUTDOWN并工作队列为空，当线程池状态为STOP时，则会进入到runStateOf(c) != SHUTDOWN，直接返回true，就代表线程池状态为STOP 后面还有一个语句一个if语句将其转换一下逻辑就是下面的内容： 123456if (workerCountOf(c) == 0) &#123; //执行下面的逻辑 &#125;else&#123; interruptIdleWorkers(ONLY_ONE); return;&#125; 这里我们也进行转换下，就可以看出来当线程池的数量为空时，才会进行下面的逻辑，下面的逻辑就是修改线程池状态为TERMINATED，两个连在一起就是上面分析的修改状态为TERMINATED的条件，这里画一张图来表示线程池状态的信息： 其实上面图中我们介绍了关于从SHUTDOWN或STOP到TERMINATED的变化，没有讲解关于如何从RUNNING状态转变成SHUTDOWN或STOP状态，其实是调用了shutdown()或shutdownNow方法对其进行状态的变换，下面来看一下shutdown方法源码： 12345678910111213141516171819public void shutdown() &#123; //获取全局锁 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //权限检查 checkShutdownAccess(); //设置线程池状态为SHUTDOWN，如果状态已经是大于等于SHUTDOWN则直接返回 advanceRunState(SHUTDOWN); //如果线程没有设置中断标识并且线程没有运行则设置中断标识 interruptIdleWorkers(); //空的可以实现的内容 onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; //尝试修改线程池状态为TERMINATED tryTerminate();&#125; 首先对当前线程进行权限检测，查看是否设置了安全管理器，如果设置了则要看当前调用shutdown的线程有没有权限都关闭线程的权限，如果有权限还要看是否有中断工作现成的权限，如果没有权限则抛出SecurityException或NullPointException异常。 设置线程池状态为SHUTDOWN，如果状态已经是大于等于SHUTDOWN则直接返回 如果线程没有设置中断标识并且线程没有运行则设置中断标识 尝试修改线程池状态为TERMINATED 接下来我们来看一下advanceRunState内容如下所示： 12345678910private void advanceRunState(int targetState) &#123; for (;;) &#123; //获取线程池状态和线程池的线程数量 int c = ctl.get(); if (runStateAtLeast(c, targetState) || //如果线程池的状态&gt;=SHUTDOWN ctl.compareAndSet(c, ctlOf(targetState, workerCountOf(c)))) //设置线程池状态为SHUTDOWN //返回 break; &#125;&#125; 当线程池的状态&gt;=SHUTDOWN，直接返回 如果线程池状态为RUNNING，设置线程池状态为SHUTDOWN，设置成功则返回 interruptIdleWorkers代码如下所示： 123private void interruptIdleWorkers() &#123; interruptIdleWorkers(false);&#125; 1234567891011121314151617181920212223242526private void interruptIdleWorkers(boolean onlyOne) &#123; //获取全局锁，同时只能有一个线程能够调用shutdown方法 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //遍历工作线程 for (Worker w : workers) &#123; Thread t = w.thread; //如果当前线程没有设置中断标志并且可以获取Worker自己的锁 if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; //设置中断标志 t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); &#125; &#125; //执行一次，清理空闲线程。 if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125; 我们看到当我们调用shutdown方法的时候，只是将空闲的线程给设置了中断标识，也就是活跃正在执行任务的线程并没有设置中断标识，直到将任务全部执行完后才会逐步清理线程操作，我们还记的在getTask中的方法里面有这样一段代码： 12345// Check if queue empty only if necessary.if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null;&#125; 判断是否是状态&gt;=SHUTDOWN，并且队列为空时，将线程池数量进行减少操作，内部进行CAS操作，直到CAS操作成功为止，并且返回null，返回null后，会调用processWorkerExit(w, false);清理Workers线程信息，并且尝试将线程设置为TERMINATED状态，上面是对所有shutdown方法的分析，下面来看一下shutdownNow方法并且比较两个之间的区别： 1234567891011121314151617181920public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //权限检查 checkShutdownAccess(); //设置线程池状态为STOP，如果状态已经是大于等于STOP则直接返回 advanceRunState(STOP); //这里是和SHUTDOWN区别的地方，这里是强制进行中断操作 interruptWorkers(); //将为完成任务复制到list集合中 tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); &#125; //尝试修改线程池状态为TERMINATED tryTerminate(); return tasks;&#125; shutdownNow方法返回了未完成的任务信息列表tasks = drainQueue();，其实该方法和shutdown方法主要的区别在于一下几点内容： shutdownNow方法将线程池状态设置为STOP，而shutdown则将状态修改为SHUTDOWN shutdownNow方法将工作任务进行中断操作，也就是说如果工作线程在工作也会被中断，而shutdown则是先尝试获取锁如果获得锁成功则进行中断标志设置，也就是中断操作，如果没有获取到锁则等待进行完成后自动退出。 shutdownNow方法返回未完成的任务列表。 下面代码是shutDownNow的interruptWorkers方法： 1234567891011private void interruptWorkers() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) //直接进行中断操作。 w.interruptIfStarted(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; 内部调用了Worker的interruptIfStarted方法，方法内部是针对线程进行中断操作，但是中断的前提条件是AQS的state状态必须大于等于0，如果状态为-1的则不会被中断，但是如果任务运行起来的时候在runWorker中则不会执行任务，因为线程池状态为STOP，如果线程池状态为STOP则会中断线程，下面代码是Worker中的interruptIfStarted: 12345678910void interruptIfStarted() &#123; Thread t; //当前Worker锁状态大于等于0并且线程没有被中断 if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125;&#125; 拒绝策略JDK内置的拒绝策略如下： AbortPolicy策略：该策略会直接抛出异常，阻止系统正常工作 CallerRunsPolicy策略：只要线程池没有关闭线程池状态是RUNNING状态，该略略直接调用线程中运行当前被丢弃的任务 DiscardOledestPolicy策略：该策略将丢弃最老的一个请求，也就是即将被执行的第一个任务，并尝试再次提交任务 DiscardPolicy策略：该策略默默丢弃无法处理的任务，不予任何处理。 ​ 总结首先先上一张图，针对这张图来进行总结： 主线程进行线程池的调用，线程池执行execute方法 线程池通过addWorker进行创建线程，并将线程放入到线程池中，这里我们看到第二步是将线程添加到核心线程中，其实线程池内部不分核心线程和非核心线程，只是根据corePoolSize和maximumPoolSize设置的大小来进行区分，因为超过corePoolSize的线程会被回收，至于回收那些线程，是根据线程获取任务的时候进行判断，当前线程池数量大于corePoolSize，或者指定了allowCoreThreadTimeOut为true，则他等待一定时间后会返回，不会一直等待 当线程池的数量达到corePoolSize时，线程池首先会将任务添加到队列中 当队列中任务也达到了队列设置的最大值时，它会创建新的线程，注意的是此时的线程数量已经超过了corePoolSize，但是没有达到maximumPoolSize最大值。 当线程池的线程数量达到了maximumPoolSize，则会相应拒绝策略。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://www.battleheart.cn/tags/并发编程/"},{"name":"多线程","slug":"多线程","permalink":"https://www.battleheart.cn/tags/多线程/"}]},{"title":"图解AQS原理之ReentrantLock详解-公平锁","slug":"reentrantlock-principle-fair","date":"2019-06-02T09:23:58.000Z","updated":"2019-06-03T02:25:14.782Z","comments":true,"path":"2019/06/02/reentrantlock-principle-fair/","link":"","permalink":"https://www.battleheart.cn/2019/06/02/reentrantlock-principle-fair/","excerpt":"","text":"概述前面已经讲解了关于AQS的非公平锁模式，关于NonfairSync非公平锁，内部其实告诉我们谁先争抢到锁谁就先获得资源，下面就来分析一下公平锁FairSync内部是如何实现公平的？如果没有看过非公平锁的先去了解下非公平锁，因为这篇文章前面不会讲太多内部结构，直接会对源码进行分析前文连接地址：图解AQS原理之ReentrantLock详解-非公平锁 本文分析的JDK版本是1.8 温馨提示：读本文内容建议结合之前写的非公平，前篇设计了很多基础性内容 源码分析在源码分析之前，我们先来看一下ReentrantLock如何切换获取锁的模式呢？其实是在构造器中传递指定的类型变量来控制使用锁的方式，如下所示： 123public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 当fair参数指定为true时，代表的是公平锁，如果指定为false则使用的非公平，无参的构造函数默认使用的是非公平模式，如下所示： 123public ReentrantLock() &#123; sync = new NonfairSync();&#125; 接下来我们以一个例子来进行后面的说明： 123456789101112131415161718192021222324252627282930313233public class ReentrantLockDemo &#123; public static void main(String[] args) throws Exception &#123; AddDemo runnalbeDemo = new AddDemo(); Thread thread = new Thread(runnalbeDemo::add); thread.start(); Thread.sleep(500); Thread thread1 = new Thread(runnalbeDemo::add); thread1.start(); System.out.println(runnalbeDemo.getCount()); &#125; private static class AddDemo &#123; private final AtomicInteger count = new AtomicInteger(); private final ReentrantLock reentrantLock = new ReentrantLock(true); private final Condition condition = reentrantLock.newCondition(); private void add() &#123; try &#123; reentrantLock.lockInterruptibly(); count.getAndIncrement(); &#125; catch (Exception ex) &#123; System.out.println(\"线程被中断了\"); &#125; finally &#123;// reentrantLock.unlock(); &#125; &#125; int getCount() &#123; return count.get(); &#125; &#125;&#125; 我们通过源码可以看到这里我们启动了两个线程，两个线程分别进行同步锁操作，这里我并没有释放掉锁，因为方便分析队列的情况，当然你也可以在内部写一个死循环，不释放锁就可以了，我这里简单的不释放锁，使用的是可中断的获取锁操作方法lockInterruptibly，这里内部的原理我们上一篇文章中已经讲解过了，这里并不过多的去分析内部原理，这个ReentrantLock的lockInterruptibly调用内部类AQS的acquireInterruptibly，但是其实是FairSync内部类继承了内部类Sync，而内部类Sync有继承了AbstractQueuedSynchronizer简称AQS，acquireInterruptibly源码信息如下所示： 1234567public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg);&#125; 这里我们通过上一篇文章得知tryAcquire是需要子类去实现的方法，我们在例子中指定了使用的是公平锁，所以tryAcquire方法的实现是在ReentrentLock的FairSync类中，我们来具体看一下这个方法，重点也在这个方法中其他的其实都是一样的，因为用的方法都会一样的非公平和公平锁的调用，唯独不一样的就是子类实现的方法是不相同的，接下来我们就来看一下公平锁的tryAcquire是如何实现的？ 12345678910111213141516171819protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; //判断是否有等待的线程在队列中 compareAndSetState(0, acquires)) &#123; //尝试争抢锁操作 setExclusiveOwnerThread(current); //设置当前线程独占锁资源 return true; //获得锁成功 &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; //当前线程和独占锁资源的线程一致，则可以重入 int nextc = c + acquires; //state递增 if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); //设置state状态 return true; //获得锁成功 &#125; return false; //获得锁失败&#125; 对比非公平锁的NonfairSync类的tryAcquire方法，其实就是在锁可用的情况下增加了一个判断条件，这个判断方法就是hasQueuedPredecessors，从方法的名称来看说的是有等待的线程队列，换句话说已经有人在排队了，新来的线程你就不能加塞，而非公平模式的谁先争抢到锁就是谁的，管你先来不先来，接下来我们具体看一下这个 hasQueuedPredecessors方法源码： 12345678910public final boolean hasQueuedPredecessors() &#123; // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // 获得尾节点 Node h = head; // 获得头节点 Node s; return h != t &amp;&amp; //头节点和尾节点相同代表队列为空 ((s = h.next) == null || s.thread != Thread.currentThread()); //头节点的next节点为空代表头节点，以及s.thread不是当前线程不是自己的话代表队列中存在元素&#125; 通过上面的源码信息，可以得出其实内部主要就是判断有没有排队等待的节点，队列是否为空，如果为空的话则可以争抢锁，如果队列不为空，伙计你必须老老实实给我排队去，除非占有锁的线程和请求锁的线程是一样的，否则还是老老实实排队去，这就是公平模式的锁操作，还有一个lock方法，公平模式的lock方法，没有直接上来先获取锁，而是先尝试获得锁直接调用AQS的aquire方法进行尝试获取锁，下面是FairSync源码： 12345678910111213141516171819202122232425262728293031static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; acquire(1); //这里直接调用了aquire并没有尝试修改state状态 &#125; /** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */ protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125;&#125; 结束语本内容主要是结合上篇内容的一个续篇，可以结合上篇然后再看下篇会比较清晰些。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://www.battleheart.cn/tags/并发编程/"},{"name":"多线程","slug":"多线程","permalink":"https://www.battleheart.cn/tags/多线程/"}],"author":"BattleHeart"},{"title":"图解AQS原理之ReentrantLock详解-非公平锁","slug":"reentrantlock-principle-nonfairsync","date":"2019-06-02T01:30:59.000Z","updated":"2019-06-02T09:25:37.550Z","comments":true,"path":"2019/06/02/reentrantlock-principle-nonfairsync/","link":"","permalink":"https://www.battleheart.cn/2019/06/02/reentrantlock-principle-nonfairsync/","excerpt":"","text":"图解AQS原理之ReentrantLock详解-非公平锁概述并发编程中，ReentrantLock的使用是比较多的，包括之前讲的LinkedBlockingQueue和ArrayBlockQueue的内部都是使用的ReentrantLock，谈到它又不能的不说AQS，AQS的全称是AbstractQueuedSynchronizer，这个类也是在java.util.concurrent.locks下面，提供了一个FIFO的队列，可以用于构建锁的基础框架，内部通过原子变量state来表示锁的状态，当state大于0的时候表示锁被占用，如果state等于0时表示没有占用锁，ReentrantLock是一个重入锁，表现在state上，如果持有锁的线程重复获取锁时，它会将state状态进行递增，也就是获得一个信号量，当释放锁时，同时也是释放了信号量，信号量跟随减少，如果上一个线程还没有完成任务，则会进行入队等待操作。 本文分析内容主要是针对jdk1.8版本 约束：文中图片的ref-xxx代表引用地址 图片中的内容prve更正为prev，由于文章不是一天写的所以有些图片更正了有些没有。 AQS主要字段1234567891011121314/** * 头节点指针，通过setHead进行修改 */private transient volatile Node head;/** * 队列的尾指针 */private transient volatile Node tail;/** * 同步器状态 */private volatile int state; AQS需要子类实现的方法AQS是提供了并发的框架，它内部提供一种机制，它是基于模板方法的实现，整个类中没有任何一个abstract的抽象方法，取而代之的是，需要子类去实现的那些方法通过一个方法体抛出UnsupportedOperationException异常来让子类知道，告知如果没有实现模板的方法，则直接抛出异常。 方法名 方法描述 tryAcquire 以独占模式尝试获取锁，独占模式下调用acquire，尝试去设置state的值，如果设置成功则返回，如果设置失败则将当前线程加入到等待队列，直到其他线程唤醒 tryRelease 尝试独占模式下释放状态 tryAcquireShared 尝试在共享模式获得锁，共享模式下调用acquire，尝试去设置state的值，如果设置成功则返回，如果设置失败则将当前线程加入到等待队列，直到其他线程唤醒 tryReleaseShared 尝试共享模式下释放状态 isHeldExclusively 是否是独占模式，表示是否被当前线程占用 AQS是基于FIFO队列实现的，那么队列的Node节点又是存放的什么呢？ Node字段信息 字段名 类型 默认值 描述 SHARED Node new Node() 一个标识，指示节点使用共享模式等待 EXCLUSIVE Nodel Null 一个标识，指示节点使用独占模式等待 CANCELLED int 1 节点因超时或被中断而取消时设置状态为取消状态 SIGNAL int -1 当前节点的后节点被park，当前节点释放时，必须调用unpark通知后面节点，当后面节点竞争时，会将前面节点更新为SIGNAL CONDITION int -2 标识当前节点已经处于等待中，通过条件进行等待的状态 PROPAGATE int -3 共享模式下释放节点时设置的状态，被标记为当前状态是表示无限传播下去 0 int 不属于上面的任何一种状态 waitStatus int 0 等待状态，默认初始化为0，表示正常同步等待， pre Node Null 队列中上一个节点 next Node Null 队列中下一个节点 thread Thread Null 当前Node操作的线程 nextWaiter Node Null 指向下一个处于阻塞的节点 通过上面的内容我们可以看到waitStatus其实是有5个状态的，虽然这里面0并不是什么字段，但是他是waitStatus状态的一种，表示不是任何一种类型的字段，上面也讲解了关于AQS中子类实现的方法，AQS提供了独占模式和共享模式两种，但是ReentrantLock实现的是独占模式的方式，下面来通过源码的方式解析ReentrantLock。 ReentrantLock源码分析首先在源码分析之前我们先来看一下ReentrantLock的类的继承关系，如下图所示： 可以看到ReentrantLock继承自Lock接口，它提供了一些获取锁和释放锁的方法，以及条件判断的获取的方法，通过实现它来进行锁的控制，它是显示锁，需要显示指定起始位置和终止位置，Lock接口的方法介绍： 方法名称 方法描述 lock 用来获取锁，如果锁已被其他线程获取，则进行等待。 tryLock 表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待 tryLock(long time, TimeUnit unit) 和tryLock()类似，区别在于它在拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回false。如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true lockInterruptibly 获取锁，如果获取锁失败则进行等到，如果等待的线程被中断会相应中断信息。 unlock 释放锁的操作 newCondition 获取Condition对象，该组件和当前的锁绑定，当前线程只有获得了锁，才能调用该组件wait()方法，而调用后，当前线程释放锁。 ReentrantLock也实现了上面接口的内容，前面讲解了很多理论行的内容，接下来我们以一个简单的例子来进行探讨 1234567891011121314151617181920212223242526272829public class ReentrantLockDemo &#123; public static void main(String[] args) throws Exception &#123; AddDemo runnalbeDemo = new AddDemo(); Thread thread = new Thread(runnalbeDemo::add); thread.start(); Thread thread1 = new Thread(runnalbeDemo::add); thread1.start(); Thread.sleep(1000); System.out.println(runnalbeDemo.getCount()); &#125; private static class AddDemo &#123; private final AtomicInteger count = new AtomicInteger(); private final ReentrantLock reentrantLock = new ReentrantLock(); private void add() &#123; try &#123; reentrantLock.lock(); count.getAndIncrement(); &#125; finally &#123;// reentrantLock.unlock(); &#125; &#125; int getCount() &#123; return count.get(); &#125; &#125;&#125; 首先声明内部类AddDemo，AddDemo的主要作用是将原子变量count进行递增的操作 AddDemo内部声明了ReentrantLock对象进行同步操作 AddDemo的add方法，进行递增操作，细心地同学发现，使用了lock方法获取锁，但是没有释放锁，这里面没有释放锁可以更让我们清晰的分析内部结构的变化。 主线程开启了两个线程进行同步进行递增的操作，最后让线程休眠一会输出累加的最后结果。 ReentrantLock内部提供了两种AQS的实现，一种公平模式，一种是非公平模式，如果没有特别指定在构造器中，默认是非公平的模式，我们可以看一下无参的构造函数。 123public ReentrantLock() &#123; sync = new NonfairSync();&#125; 当调用有参构造函数时，指定使用哪种模式来进行操作，参数为布尔类型，如果指定为false的话代表非公平模式，如果指定为true的话代表的是公平模式，如下所示： 123public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 我们使用的是非公平模式，后面再来进行分析公平模式，上面也讲到了分为两种模式，这两种模式为FairSync和NonfairSync两个内部静态类不可变类，不能被继承和实例化，这两个类是我们今天分析的重点，为什么说是重点呢，这里讲的内容是有关于AQS的，而FairSync和NonfairSync实现了抽象内部类Sync，Sync实现了AbstractQueuedSynchronizer这个类，这个类就是我们说的AQS也是主要同步操作的类，下面我们来看一下公平模式和非公平模式下类的继承关系，如下图所示： 非公平模式： 公平模式： 通过上面两个继承关系UML来看其实无差别，差别在于内部实现的原理不一样，回到上面例子中使用的是非公平模式，那先以非公平模式来进行分析， 假设第一个线程启动调用AddDemo的add方法时，首先执行的事reentrantLock.lock()方法，这个lock方法调用了sync.lock(),sync就是我们上面提到的两种模式的对象，来看一下源码内容： 123public void lock() &#123; sync.lock();&#125; 内部调用了sync.lock(),其实是调用了NonfairSync对象的lock方法，也就是下面的方法内容。 1234567891011121314151617181920/** * 非公平模式锁 */static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; /** * 执行锁动作，先进行修改状态，如果锁被占用则进行请求申请锁，申请锁失败则将线程放到队列中 */ final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; // 继承自AQS的tryAcquire方法，尝试获取锁操作，这个方法会被AQS的acquire调用 protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125; 我们看到lock方法首先先对state状态进行修改操作，如果锁没有被占用则获取锁，并设置当前线程独占锁资源，如果尝试获取锁失败了，则进行acqurie方法的调用，例子中第一个线程当尝试获取锁是内部state状态为0，进行修改操作的时候，发现锁并没有被占用，则获得锁，此时我们来看一下内部变化的情况，如下图所示： 此时只是将state的状态更新为1，表示锁已经被占用了，独占锁资源的线程是Thread0，也就是exclusiveOwnerThread的内容，头节点和尾节点都没有被初始化，当第二个线程尝试去获取锁的时候，发现锁已经被占用了，因为上一个线程并没有释放锁，所以第二线程直接获取锁时获取失败则进入到acquire方法中，这个方法是AbstractQueuedSynchronizer中的方法acquire，先来看一下具体的实现源码如下所示： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 我个人理解acquire方法不间断的尝试获取锁，如果锁没有获取到则现将节点加入到队列中，并将当前线程设置为独占锁资源，也就是独占了锁的意思，别的线程不能拥有锁，然后如果当前节点的前节点是头节点话，再去尝试争抢锁，则设置当前节点为头节点，并将原头节点的下一个节点设置为null，帮助GC回收它，如果不是头节点或争抢锁不成功，则会现将前面节点的状态设置直到设置为SIGNAL为止，代表下面有节点被等待了等待上一个线程发来的信号，然后就挂起当前线程。 我们接下来慢慢一步一步的分析，我们先来看一下NonfairSync中的tryAcquire，如下所示： 123protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires);&#125; 它调用的是他的父类方法，也就是ReentrantLock下Sync中的nonfairTryAcquire方法，这个方法主要就是去申请锁的操作，来看一下具体源码： 123456789101112131415161718final boolean nonfairTryAcquire(int acquires) &#123; //首先是一个被final修饰的方法 final Thread current = Thread.currentThread(); //获取当前线程 int c = getState(); //获取state的状态值 if (c == 0) &#123; //如果状态等于0代表线程没有被占用 if (compareAndSetState(0, acquires)) &#123; //cas修改state值 setExclusiveOwnerThread(current); //设置当前线程为独占模式 return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123;//如果state状态不等于0则先判断是否是当前线程占用锁，如果是则进行下面的流程。 int nextc = c + acquires; //这个地方就说明重入锁的原理，如果拥有锁的是当前线程，则每次获取锁state值都会跟随递增 if (nextc &lt; 0) // overflow //溢出了 throw new Error(\"Maximum lock count exceeded\"); setState(nextc); //直接设置state值就可以不需要CAS return true; &#125; return false; //都不是就返回false&#125; 通过源码我们可以看到其实他是有三种操作逻辑： 如果state为0，则代表锁没有被占用，尝试去修改state状态，并且将当前线程设置为独占锁资源，表示获得锁成功 如果state大于0并且拥有锁的线程和当前申请锁的线程一致，则代表重入了锁，state值会进行递增，表示获得锁成功 如果state大于0并且拥有锁的线程和当前申请锁的线程不一致则直接返回false，代表申请锁失败 当第二个线程去争抢锁的时候，state值已经设置为1了也就是已经被第一个线程占用了锁，所以这里它会返回false，而通过acquire方法内容可以看到if语句中是!tryAcquire(arg)，也就是!false=ture，它会进行acquireQueued(addWaiter(Node.EXCLUSIVE), arg))方法，这个方法里面又有一个addWaiter方法，从方法语义上能看到是添加等待队列的操作，方法的参数代表的是模式，Node.EXCLUSIVE表示的是在独占模式下等待，我们先来看一下addWaiter里面是如何进行操作，如下所示： 123456789101112131415private Node addWaiter(Node mode) &#123; //首先生成当前线程拥有的节点 Node node = new Node(Thread.currentThread(), mode); // 下面的内容是尝试快速进行插入末尾的操作，在没有其他线程同时操作的情况 Node pred = tail; //获取尾节点 if (pred != null) &#123; //尾节点不为空，代表队列不为空 node.prev = pred; //尾节点设置为当前节点的前节点 if (compareAndSetTail(pred, node)) &#123;//修改尾节点为当前节点 pred.next = node; //原尾节点的下一个节点设置为当前节点 return node; //返回node节点 &#125; &#125; enq(node); //如果前面入队失败，这里进行循环入队操作，直到入队成功 return node;&#125; 前面代码中可以看到，它有一个快速入队的操作，如果快速入队失败则进行死循环进行入队操作，当然我们上面例子中发现队列其实是为空的，也就是pred==null，不能进行快速入队操作，则进入到enq进行入队操作，下面看一下enq方法实现，如下所示： 123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; //死循环进行入队操作，直到入队成功 Node t = tail; //获取尾节点 if (t == null) &#123; // Must initialize //判断尾节点为空，则必须先进行初始化 if (compareAndSetHead(new Node()))//生成一个Node，并将当前Node作为头节点 tail = head; //head和tail同时指向上面Node节点 &#125; else &#123; node.prev = t; //设置入队的当前节点的前节点设置为尾节点 if (compareAndSetTail(t, node)) &#123; //将当前节点设置为尾节点 t.next = node; //修改原有尾节点的下一个节点为当前节点 return t; //返回最新的节点 &#125; &#125; &#125;&#125; 通过上面入队操作，可以清晰的了解入队操作其实就是Node节点的prev节点和next节点之前的引用，运行到这里我们应该能看到入队的状态了，如下图所示： 如上图可以清晰的看到，此时拥有锁的线程是Thread0，而当前线程是Threa1，头节点为初始化的节点，Ref-707引用地址所在的Node节点操作当前操作的节点信息，入队操作后并没有完成，而是继续往下进行，此时则进行acquireQueued这个方法，这个方法是不间断的去获取已经入队队列中的前节点的状态，如果前节点的状态为大于0，则代表当前节点被取消了，会一直往前面的节点进行查找，如果节点状态小于0并且不等于SIGNAL则将其设置为SIGNAL状态，设置成功后将当前线程挂起，挂起线程后也有可能会反复唤醒挂起操作，原因后面会讲到。 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; //取消节点标志位 try &#123; boolean interrupted = false; //中断标志位 for (;;) &#123; final Node p = node.predecessor(); //获取前节点 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //这里的逻辑是如果前节点为头结点并且获取到锁则进行头结点变换 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; //设置waitStatus状态 parkAndCheckInterrupt()) //挂起线程 interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); //取消操作 &#125;&#125; 前面的源码可以看到它在acquireQueued中对已经入队的节点进行尝试锁的获取，如果锁获得就修改头节点的指针，如果不是头节点或者争抢锁失败时，此时会进入到shouldParkAfterFailedAcquire方法，这个方法是获取不到锁时需要停止继续无限期等待锁，其实就是内部的操作逻辑也很简单，就是如果前节点状态为0时，需要将前节点修改为SIGNAL，如果前节点大于0则代表前节点已经被取消了，应该移除队列，并将前前节点作为当前节点的前节点，一直循环直到前节点状态修改为SIGNAL或者前节点被释放锁，当前节点获取到锁停止循环。 1234567891011121314151617181920212223private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * 此节点已经设置了状态，要求对当前节点进行挂起操作 */ return true; if (ws &gt; 0) &#123; /* * 如果前节点被取消，则将取消节点移除队列操作 */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus=0或者PROPAGATE时，表示当前节点还没有被挂起停止，需要等待信号来通知节点停止操作。 */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 上面的方法其实很容易理解就是等待挂起信号，如果前节点的状态为0或PROPAGATE则将前节点修改为SIGNAL，则代表后面前节点释放锁后会通知下一个节点，也就是说唤醒下一个可以唤醒的节点继续争抢所资源，如果前节点被取消了那就继续往前寻找不是被取消的节点，这里不会找到前节点为null的情况，因为它默认会有一个空的头结点，也就是上图内容，此时的队列状态是如何的我们看一下，这里它会进来两次，以为我们上图可以看到当前节点前节点是Ref-724此时waitStatus=0，他需要先将状态更改为SIGNAL也就是运行最有一个else语句，此时又会回到外面的for循环中，由于方法返回的是false则不会运行parkAndCheckInterrupt方法，而是又循环了一次，此时发现当前节点争抢锁又失败了，然后此时队列的状态如下图所示： 再次进入到方法之后发现前驱节点的waitStatus=-1，表示当前节点需要进行挂起等到，此时返回的结果是true，则会运行parkAndCheckInterrupt方法，这个方法很简单就是将当前线程进行挂起操作，如下所示： 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); //挂起线程 return Thread.interrupted(); //判断是否被中断，获取中断标识&#125; park挂起线程并且响应中断信息，其实我们从这里就能发现一个问题，Thread.interrupted方法是用来获取是否被中断的标志，如果被中断则返回true，如果没有被中断则返回false，当当前节点被中断后，其实就会返回true，返回true这里并没有结束，而是跳到调用地方，也就是acquireQueued方法内部： 123if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; 以一个案例来进行分析： 12345678910111213141516171819202122232425262728293031323334public class ReentrantLockDemo &#123; public static void main(String[] args) throws Exception &#123; AddDemo runnalbeDemo = new AddDemo(); Thread thread = new Thread(runnalbeDemo::add); thread.start(); Thread thread1 = new Thread(runnalbeDemo::add); thread1.start(); Thread thread2 = new Thread(runnalbeDemo::add); thread2.start(); Thread.sleep(10000); thread1.interrupt(); System.out.println(runnalbeDemo.getCount()); &#125; private static class AddDemo &#123; private final AtomicInteger count = new AtomicInteger(); private final ReentrantLock reentrantLock = new ReentrantLock(); private final Condition condition = reentrantLock.newCondition(); private void add() &#123; try &#123; reentrantLock.lock(); count.getAndIncrement(); &#125; finally &#123;// reentrantLock.unlock(); &#125; &#125; int getCount() &#123; return count.get(); &#125; &#125;&#125; 通过上面的例子可以发现，thread1调用中断方法interrupt()，当调用第一次方法的时候，它会进入到parkAndCheckInterrupt方法，然后线程响应中断，最后返回true，最后返回到acquireQueued方法内部，整个if语句为true，则开始设置interrupted=true，仅仅是设置了等于true，但是这离还会进入下一轮的循环，假如说上次的线程没有完成任务，则没有获取到锁，还是会进入到shouldParkAfterFailedAcquire由于已经修改了上一个节点的waitStatus=-1，直接返回true，然后再进入到parkAndCheckInterrupt又被挂起线程，但是如果上步骤操作他正抢到锁，则会返回ture，外面也会清除中断标志位，从这里可以清楚地看到acquire方法是一个不间断获得锁的操作，可能重复阻塞和解除阻塞操作。 上面阻塞队列的内容已经讲完了，接下来我们看一下unlock都为我们做了什么工作： 123public void unlock() &#123; sync.release(1);&#125; 我们可以看到他直接调用了独占模式的release方法，看一下具体源码： 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; //调用ReentrantLock中的Sync里面的tryRelease方法 Node h = head; //获取头节点 if (h != null &amp;&amp; h.waitStatus != 0) //头节点不为空且状态不为0时进行unpark方法 unparkSuccessor(h); //唤醒下一个未被取消的节点 return true; &#125; return false;&#125; release方法，首先先进行尝试去释放锁，如果释放锁仍然被占用则直接返回false，如果尝试释放锁时，发现锁已经释放，当前线程不在占用锁资源时，则会进入的下面进行一些列操作后返回true，接下来我们先来看一下ReentrantLock的Sync下的tryRelease方法，如下所示： 123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; //获取state状态，标志信息减少1 if (Thread.currentThread() != getExclusiveOwnerThread()) //线程不一致抛出异常 throw new IllegalMonitorStateException(); boolean free = false; //是否已经释放锁 if (c == 0) &#123; //state=0时表示锁已经释放 free = true; //将标志free设置为true setExclusiveOwnerThread(null); //取消独占锁信息 &#125; setState(c); //设置锁标志信息 return free; &#125; 看上面的源码，表示首先先获取state状态，如果state状态减少1之后和0不相等则代表有重入锁，则表示当前线程还在占用所资源，直到线程释放锁返回ture标识，还是以上例子为主（此时AddDemo中的unlock不在被注释），分析其现在的队列中的状态 释放锁后，进入到if语句中，判断当前头节点不为空且waitStatus!=0，通过上图也可以发现头节点为-1，则进入到unparkSuccessor方法内： 12345678910111213141516171819202122private void unparkSuccessor(Node node) &#123; /* * 获取节点的waitStatus状态 */ int ws = node.waitStatus; // 如果小于0则设置为0 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * 唤醒下一个节点，唤醒下一个节点之前需要判断节点是否存在或已经被取消了节点，如果没有节点则不需唤醒操作，如果下一个节点被取消了则一直一个没有被取消的节点。 */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 可以看到它是现将头节点的状态更新为0，然后再唤醒下一个节点，如果下一个节点为空则直接返回不唤醒任何节点，如果下一个节点被取消了，那么它会从尾节点往前进行遍历，遍历与头节点最近的没有被取消的节点进行唤醒操作，在唤醒前看一下队列状态： 然后唤醒节点后他会进入到parkAndCheckInterrupt方法里面，再次去执行下面的方法： 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; //取消节点标志位 try &#123; boolean interrupted = false; //中断标志位 for (;;) &#123; final Node p = node.predecessor(); //获取前节点 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //这里的逻辑是如果前节点为头结点并且获取到锁则进行头结点变换 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; //设置waitStatus状态 parkAndCheckInterrupt()) //挂起线程 interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); //取消操作 &#125;&#125; 此时获取p==head成立，并且可以正抢到所资源，所以它会进入到循环体内，进行设置头结点为当前节点，前节点的下一个节点设置为null，返回中断标志，看一下此时队列情况，如下图所示： AbstractQueuedSynchronizer的独占模式其实提供了三种不同的形式进行获取锁操作，看一下下表所示： 方法名称 方法描述 对应调用的内部方法 acquire 以独占模式进行不间断的获取锁 tryAcquire，acquireQueued acquireInterruptibly 以独占模式相应中断的方式获取锁，发生中断抛出异常 tryAcquire，doAcquireInterruptibly tryAcquireNanos 以独占模式相应中断的方式并且在指定时间内获取锁，会阻塞一段时间，如果还未获得锁直接返回，发生中断抛出异常 tryAcquire，doAcquireNanos 通过上面图可以发现，他都会调用图表一中需要用户实现的方法，ReentrantLock实现了独占模式则内部实现的是tryAcquire和tryRelease方法，用来尝试获取锁和尝试释放锁的操作，其实上面内容我们用的是ReentrantLock中的lock方法作为同步器，细心的朋友会发现，这个lock，方法是ReentrantLock实现的，它内部调用了acquire方法，实现了不间断的获取锁机制，ReentrantLock中还有一个lockInterruptibly方法，它内部直接调用的是AbstractQueuedSynchronizer的acquireInterruptibly方法，两个之间的区别在于，两者都会相应中断信息，前者不会做任何处理还会进入等待状态，而后者则抛出异常终止操作， 这里为了详细看清楚它内部关系我这里用张图来进行阐述，如下所示： 左侧代表的事ReentrantLock，右侧代表的AQS 左侧内部黄色区域代表NonfairSync 图中1和2代表AQS调用其他方法的过程 接下来我们来看一下源码信息： 123public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1);&#125; 发现他调用的Sync类中的acquireInterruptibly方法，但其实这个方法是AQS中的方法，源码如下所示： 1234567public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) //判断线程是否被中断 throw new InterruptedException(); //中断则抛出异常 if (!tryAcquire(arg)) //尝试获取锁 doAcquireInterruptibly(arg); //进行添加队列，并且修改前置节点状态，且响应中断抛出异常&#125; 通过上面的源码，它也调用了子类实现的tryAcquire方法，这个方法和我们上文提到的tryAcquire是一样，ReentrantLock下的NonfairSync下的tryAcquire方法，这里这个方法就不多说了详细请看上文内容，这里主要讲一下doAcquireInterruptibly这个方法： 12345678910111213141516171819202122private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); //将节点添加到队列尾部 boolean failed = true; //失败匹配机制 try &#123; for (;;) &#123; final Node p = node.predecessor(); //获取前节点 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //如果前节点为头节点并且获得了锁 setHead(node); //设置当前节点为头节点 p.next = null; // help GC //头节点的下一个节点设置为null failed = false; //匹配失败变为false return; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; //将前节点设置为-1，如果前节点为取消节点则往前一直寻找直到修改为-1为止。 parkAndCheckInterrupt()) //挂起线程返回是否中断 throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 其实这个方法和acquireQueued区别在于以下几点： acquireQueued是在方法内部添加节点到队列尾部，而doAcquireInterruptibly是在方法内部进行添加节点到尾部，这个区别点并不是很重要 重点是acquireQueued响应中断，但是他不会抛出异常，而后者会抛出异常throw new InterruptedException() 分析到这里我们来用前面的例子来进行模拟一下中中断的操作，详细代码如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041public class ReentrantLockDemo &#123; public static void main(String[] args) throws Exception &#123; AddDemo runnalbeDemo = new AddDemo(); Thread thread = new Thread(runnalbeDemo::add); thread.start(); Thread.sleep(500); Thread thread1 = new Thread(runnalbeDemo::add); thread1.start(); Thread.sleep(500); Thread thread2 = new Thread(runnalbeDemo::add); thread2.start(); Thread.sleep(500); Thread thread3 = new Thread(runnalbeDemo::add); thread3.start(); Thread.sleep(10000); thread1.interrupt(); System.out.println(runnalbeDemo.getCount()); &#125; private static class AddDemo &#123; private final AtomicInteger count = new AtomicInteger(); private final ReentrantLock reentrantLock = new ReentrantLock(); private final Condition condition = reentrantLock.newCondition(); private void add() &#123; try &#123; reentrantLock.lockInterruptibly(); count.getAndIncrement(); &#125; catch (Exception ex) &#123; System.out.println(\"线程被中断了\"); &#125; finally &#123;// reentrantLock.unlock(); &#125; &#125; int getCount() &#123; return count.get(); &#125; &#125;&#125; 上面的例子其实和前面提到的例子没有什么太大的差别主要的差别是将lock替换为lockInterruptibly，其次就是在三个线程后面讲线程1进行中断操作，这里入队的操作不在多说，因为操作内容和上面大致相同，下面是四个个线程操作完成的状态信息： 如果线程等待的过程中抛出异常，则当前线程进入到finally中的时候failed为true，因为修改该字段只有获取到锁的时候才会修改为false，进来之后它会运行cancelAcquire来进行取消当前节点，下面我们先来分析下源码内容： 12345678910111213141516171819202122232425262728293031323334353637383940private void cancelAcquire(Node node) &#123; // 如果节点为空直接返回，节点不存在直接返回 if (node == null) return; // 设置节点所在的线程为空，清除线程操作 node.thread = null; // 获取当前节点的前节点 Node pred = node.prev; // 如果前节点是取消节点则跳过前节点，一直寻找一个不是取消节点为止 while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // 获取头节点下一个节点 Node predNext = pred.next; // 这里直接设置为取消节点状态，没有使用CAS原因是因为直接设置只有其他线程可以跳过取消的节点 node.waitStatus = Node.CANCELLED; // 如果当前节点为尾节点，并且设置尾节点为找到的合适的前节点时，修改前节点的下一个节点为null if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123; // 如果不是尾节点，则说明是中间节点，则需要通知后续节点，嘿，伙计你被唤醒了。 int ws; if (pred != head &amp;&amp; //前节点不是头结点 ((ws = pred.waitStatus) == Node.SIGNAL || // 前节点的状态为SIGNAL (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) //或者前节点状态小于0而且修改前节点状态为SIGNAL成功 &amp;&amp; pred.thread != null) &#123; //前节点线程不为空 Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); &#125; else &#123; //唤醒下一个不是取消的节点 unparkSuccessor(node); &#125; node.next = node; // help GC &#125;&#125; 首先找到当前节点的前节点，如果前节点为取消节点则一直往前寻找一个节点。 取消的是尾节点，则直接将前节点的下一个节点设置为null 如果取消的是头节点的下一个节点，且不是尾节点的情况时，它是唤醒下一个节点，唤醒之前并没有将其移除队列，而是在唤醒下一个节点的时候，shouldParkAfterFailedAcquire里面将取消的节点移除队列，唤醒之后，当前节点的下一个节点也设置成自己，帮助GC回收它。 如果取消节点是中间的节点，则直接将其前节点的下一个节点设置为取消节点的下下个节点即可。 第一种情况如果我们取消的节点是前节点是头节点，此时线程1的节点应该是被中断操作，此时进入到cancelAcquire之后会进入else语句中，然后进去到unparkSuccessor方法，当进入到这个方法之前我们看一下状态变化： 我们发现线程1的Node节点的waitStatus变为1也就是Node.CANCELLED节点，然后运行unparkSuccessor方法，该方法上面就已经讲述了其中的源码，这里就不在贴源码了，就是要唤醒下一个没有被取消的节点，这里是Ref-695这个线程，当Ref-695被唤醒之后它会继续运行下面的内容： 12345678910111213141516171819202122private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; //再一次循环发现还是没有争抢到锁 setHead(node); p.next = null; // help GC failed = false; return; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; //再一次循环之后有运行到这里了 parkAndCheckInterrupt()) //这里被唤醒了，又要进行循环操作了 throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 发现再一次循环操作后，还是没有正抢到锁，这时候还是会运行shouldParkAfterFailedAcquire方法，这个方法内部发现前节点的状态是Node.CANCELLED这时候它会在内部先将节点给干掉，也就是这个代码： 12345678910if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node;&#125; 最后还是会被挂起状态，因为没有释放锁操作，最后移除的节点如下所示： 如果取消的事尾节点，也就是线程3被中断操作，这个是比较简单的直接将尾节点删除即可，其中会走如下代码： 123if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null);&#125; 如果取消的节点是中间的节点，通过上例子中则是取消线程2，其实它内部只是将线程取消线程的前节点的下一个节点指向了取消节点的下节点，如下图所示： 结束语这章节分析的主要是ReentrantLock的内部原理，本来公平模式和非公平模式想放在一起来写，无奈发现篇幅有点长了，所以就分开进行写，这样读取来不会那么费劲，内部还有条件内容等待下章节分析，如果有分析不到位的请大家指正。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://www.battleheart.cn/tags/并发编程/"},{"name":"多线程","slug":"多线程","permalink":"https://www.battleheart.cn/tags/多线程/"}],"author":"BattleHeart"},{"title":"SynchronousQueue原理详解-非公平模式","slug":"synchronousqueue-principle-unfair-pattern","date":"2019-05-18T13:35:05.000Z","updated":"2019-05-28T01:03:52.976Z","comments":true,"path":"2019/05/18/synchronousqueue-principle-unfair-pattern/","link":"","permalink":"https://www.battleheart.cn/2019/05/18/synchronousqueue-principle-unfair-pattern/","excerpt":"","text":"SynchronousQueue原理详解-非公平模式开篇 说明：本文分析采用的是jdk1.8 约定：下面内容中Ref-xxx代表的是引用地址，引用对应的节点 前面已经讲解了公平模式的内容，今天来讲解下关于非公平模式下的SynchronousQueue是如何进行工作的，在源码分析的时候，先来简单看一下非公平模式的简单原理，它采用的栈这种FILO先进后出的方式进行非公平处理，它内部有三种状态，分别是REQUEST，DATA，FULFILLING，其中REQUEST代表的数据请求的操作也就是take操作，而DATA表示的是数据也就是Put操作将数据存放到栈中，用于消费者进行获取操作，而FULFILLING代表的是可以进行互补操作的状态，其实和前面讲的公平模式也很类似。 当有相同模式情况下进行入栈操作，相同操作指的是REQUEST和DATA两种类型中任意一种进行操作时，模式相同则进行入栈操作，如下图所示： 同REQUEST进行获取数据时的入栈情况： 同样的put的操作，进行数据操作时为DATA类型的操作，此时队列情况为： 不同模式下又是如何进行操作的？当有不同模式进来的时候，他不是将当前的模式压入栈顶，而是将FullFill模式和当前模式进行按位或之后压入栈顶，也就是压入一个进行FullFill请求的模式进入栈顶，请求配对操作，如下图所示： 通过上图可见，本来栈中有一个DATA模式的数据等待消费者进行消费，这时候来了一个REQUEST模式的请求操作来进行消费数据，这时候并没有将REQUEST模式直接压入栈顶，而是将其转换为FULLFILLING模式，并且保留了原有的类型，这是进行FULLFILLING的请求，请求和栈顶下方元素进行匹配，当匹配成功后将栈顶和匹配元素同时进行出栈操作，详细请见下文分析： TransferStack字段信息12345678/** 消费者模式 */static final int REQUEST = 0;/** 提供者模式 */static final int DATA = 1;/** 互补模式 */static final int FULFILLING = 2;/** 栈顶指针 */volatile SNode head; 方法 方法名 描述 isFulfilling 判断指定类型是否是互补模式 casHead 替换当前头结点 snode 生成SNode节点对象 transfer 主要处理逻辑 awaitFulfill 等待fulfill操作 shouldSpin 判断节点s是头结点或是fulfill节点则返回true SNode内容字段信息12345volatile SNode next; // 栈下一个元素volatile SNode match; // 匹配的节点volatile Thread waiter; // 控制park/unpark的线程Object item; // 数据或请求int mode; // 模式，上面介绍的三种模式 方法 方法名 描述 casNext 判断指定类型是否是互补模式 tryMatch 尝试匹配节点，如果存在匹配节点则判断是否是当前节点，直接返回判断结果，如果没有则替换match内容并且唤醒线程 tryCancel 取消当前节点，将当前节点的match节点设置为当前节点(this) isCancelled 判断match节点是不是等于当前节点 经过上面内容的分析，接下来就进入正题，让我们整体先看一下下transfer都为我们做了些什么内容，下面是transfer源码内容: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576E transfer(E e, boolean timed, long nanos) &#123; /* * Basic algorithm is to loop trying one of three actions: * * 1. If apparently empty or already containing nodes of same * mode, try to push node on stack and wait for a match, * returning it, or null if cancelled. * * 2. If apparently containing node of complementary mode, * try to push a fulfilling node on to stack, match * with corresponding waiting node, pop both from * stack, and return matched item. The matching or * unlinking might not actually be necessary because of * other threads performing action 3: * * 3. If top of stack already holds another fulfilling node, * help it out by doing its match and/or pop * operations, and then continue. The code for helping * is essentially the same as for fulfilling, except * that it doesn't return the item. */ SNode s = null; // constructed/reused as needed int mode = (e == null) ? REQUEST : DATA; for (;;) &#123; SNode h = head; if (h == null || h.mode == mode) &#123; // 栈顶指针为空或者是模式相同 if (timed &amp;&amp; nanos &lt;= 0) &#123; // 制定了timed并且时间小于等于0则取消操作。 if (h != null &amp;&amp; h.isCancelled()) casHead(h, h.next); // 判断头结点是否被取消了取消了就弹出队列，将头结点指向下一个节点 else return null; &#125; else if (casHead(h, s = snode(s, e, h, mode))) &#123;// 初始化新节点并且修改栈顶指针 SNode m = awaitFulfill(s, timed, nanos); // 进行等待操作 if (m == s) &#123; // 返回内容是本身则进行清理操作 clean(s); return null; &#125; if ((h = head) != null &amp;&amp; h.next == s) casHead(h, s.next); // help s's fulfiller return (E) ((mode == REQUEST) ? m.item : s.item); &#125; &#125; else if (!isFulfilling(h.mode)) &#123; // 尝试去匹配 if (h.isCancelled()) // 判断是否已经被取消了 casHead(h, h.next); // 弹出取消的节点并且从新进入主循环 else if (casHead(h, s=snode(s, e, h, FULFILLING|mode))) &#123;//新建一个Full节点压入栈顶 for (;;) &#123; // 循环直到匹配 SNode m = s.next; // s的下一个节点为匹配节点 if (m == null) &#123; // 代表没有等待内容了 casHead(s, null); // 弹出full节点 s = null; // 设置为null用于下次生成新的节点 break; // 退回到主循环中 &#125; SNode mn = m.next; if (m.tryMatch(s)) &#123; casHead(s, mn); // 弹出s节点和m节点两个节点 return (E) ((mode == REQUEST) ? m.item : s.item); &#125; else // 如果失去了匹配 s.casNext(m, mn); // 帮助取消连接 &#125; &#125; &#125; else &#123; // 这里是帮助进行fillull SNode m = h.next; // m是头结点的匹配节点 if (m == null) // 如果m不存在则直接将头节点赋值为nll casHead(h, null); // 弹出fulfill节点 else &#123; SNode mn = m.next; if (m.tryMatch(h)) // h节点尝试匹配m节点 casHead(h, mn); // 弹出h和m节点 else // 丢失匹配则直接将头结点的下一个节点赋值为头结点的下下节点 h.casNext(m, mn); &#125; &#125; &#125;&#125; 模式相同的时候则进行等待操作，入队等待操作 当模式不相同时，首先判断头结点是否是fulfill节点如果不是则进行匹配操作，如果是fulfill节点先帮助头结点的fulfill节点进行匹配操作 接下来再来看一下awaitFulfill方法内容 123456789101112131415161718192021222324252627282930SNode awaitFulfill(SNode s, boolean timed, long nanos) &#123; final long deadline = timed ? System.nanoTime() + nanos : 0L; // 等待线程 Thread w = Thread.currentThread(); // 等待时间设置 int spins = (shouldSpin(s) ? (timed ? maxTimedSpins : maxUntimedSpins) : 0); for (;;) &#123; if (w.isInterrupted()) // 判断当前线程是否被中断 s.tryCancel(); // 尝试取消操作 SNode m = s.match; // 获取当前节点的匹配节点，如果节点不为null代表匹配或取消操作，则返回 if (m != null) return m; if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; s.tryCancel(); continue; &#125; &#125; if (spins &gt; 0) spins = shouldSpin(s) ? (spins-1) : 0; else if (s.waiter == null) s.waiter = w; // establish waiter so can park next iter else if (!timed) LockSupport.park(this); else if (nanos &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanos); &#125;&#125; 通过上面的源码，其实我们之前分析同步模式的时候差不太多，变化的地方其中包括返回内容判断这里判断的是match节点是否为null，还有就是spins时间设置这里发现了shoudSpin用来判断是否进行轮训，来看一下shouldSpin方法： 1234567/** * 判断节点是否是fulfill节点，或者是头结点为空再或者是头结点和当前节点相等时则不需要进行轮训操作 */boolean shouldSpin(SNode s) &#123; SNode h = head; return (h == s || h == null || isFulfilling(h.mode));&#125; 实际上就是判断节点是否是fulfill节点，或者是头结点为空再或者是头结点和当前节点相等时则不需要进行轮训操作，如果满足上述条件就不小进行轮训等到操作了直接进行等待就行了。 接下来我们来用例子一点点解析原理： 首先先进行一个put操作，这样可以简单分析下内部信息。 12345678910111213141516171819/** * SynchronousQueue原理内容 * * @author battleheart */public class SynchronousQueueDemo1 &#123; public static void main(String[] args) throws Exception &#123; SynchronousQueue&lt;Integer&gt; queue = new SynchronousQueue&lt;&gt;(); Thread thread1 = new Thread(() -&gt; &#123; try &#123; queue.put(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); thread1.start(); &#125;&#125; 首先它会进入到transfer方法中，进行第一步的判断他的类型信息，如下所示： 12SNode s = null; // constructed/reused as neededint mode = (e == null) ? REQUEST : DATA; 通过上面代码可以看到e=1所以是DATA类型，接下来进行判断是如何进行操作，当前堆栈是空的，如何判断堆栈为空呢？上面也讲到了head节点为空时则代表堆栈为空，接下来就要判断如果head节点为空或head指向的节点和当前操作内容模式相同，则进行等待操作，如下代码所示： 123456789101112131415161718SNode h = head;if (h == null || h.mode == mode) &#123; // empty or same-mode if (timed &amp;&amp; nanos &lt;= 0) &#123; // can't wait if (h != null &amp;&amp; h.isCancelled()) casHead(h, h.next); // pop cancelled node else return null; &#125; else if (casHead(h, s = snode(s, e, h, mode))) &#123; SNode m = awaitFulfill(s, timed, nanos); if (m == s) &#123; // wait was cancelled clean(s); return null; &#125; if ((h = head) != null &amp;&amp; h.next == s) casHead(h, s.next); // help s's fulfiller return (E) ((mode == REQUEST) ? m.item : s.item); &#125;&#125; 显然头结点是空的，所以进入到第一个fi语句中执行等待操作，如果指定了timed则判断时间是否小于0，如果小于0则直接null，反之判断当前节点是否不是头结点以及头结点是否取消，潘祖条件弹出头结点，并将下一个节点设置为头结点，上述条件在当前例子中都不满足，所以要进入到下面这段代码中，首先进行对s进行初始化值，并且进行入栈操作，casHead(h, s = snode(s, e, h, mode))，下面看一下栈中的情况如下图所示： 当执行完了入栈操作之后接下来要执行awaitFulfill这里的操作就是轮训以及将当前节点的线程赋值，并且挂起当前线程。此时的栈的情况如下图所示： 当有同样的模式进行操作时候也是重复上述的操作内容，我们这里模拟两次put操作，让让我们看一下栈中的情况如下图所示： 通过上图可以看到，其实就是将头结点移动到了新的节点上，然后新节点的next节点维护这下一个节点的引用，好了，上述内容分析是同模式的操作，接下来我们试着进行take操作时，这时候会发什么内容呢？ 1234567891011121314151617181920212223242526272829303132333435363738/** * SynchronousQueue例子二进行两次put操作和一次take操作 * * @author battleheart */public class SynchronousQueueDemo1 &#123; public static void main(String[] args) throws Exception &#123; SynchronousQueue&lt;Integer&gt; queue = new SynchronousQueue&lt;&gt;(); Thread thread1 = new Thread(() -&gt; &#123; try &#123; queue.put(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); thread1.start(); Thread.sleep(2000); Thread thread2 = new Thread(() -&gt; &#123; try &#123; queue.put(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); thread2.start(); Thread.sleep(2000); Thread thread6 = new Thread(() -&gt; &#123; try &#123; queue.take(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); thread6.start(); &#125;&#125; 上面例子正好符合上面例子两次put操作的截图，进行两次put操作过后再进行take操作，接下来我们来看一下take操作是如何进行操作的，换句话说当有不同模式的操作时又是如何进行处理呢？上面分析的内容是同种操作模式下的，当有不同操作则会走下面内容： 12345678910111213141516171819202122232425262728293031 else if (!isFulfilling(h.mode)) &#123; // try to fulfill if (h.isCancelled()) // already cancelled casHead(h, h.next); // pop and retry else if (casHead(h, s=snode(s, e, h, FULFILLING|mode))) &#123; for (;;) &#123; // loop until matched or waiters disappear SNode m = s.next; // m is s's match if (m == null) &#123; // all waiters are gone casHead(s, null); // pop fulfill node s = null; // use new node next time break; // restart main loop &#125; SNode mn = m.next; if (m.tryMatch(s)) &#123; casHead(s, mn); // pop both s and m return (E) ((mode == REQUEST) ? m.item : s.item); &#125; else // lost match s.casNext(m, mn); // help unlink &#125; &#125;&#125; else &#123; // help a fulfiller SNode m = h.next; // m is h's match if (m == null) // waiter is gone casHead(h, null); // pop fulfilling node else &#123; SNode mn = m.next; if (m.tryMatch(h)) // help match casHead(h, mn); // pop both h and m else // lost match h.casNext(m, mn); // help unlink &#125;&#125; 最下面的else我们等会来进行分析，我们看到如果不是同模式的话，则会先判断是否是fulfill模式，如果不是fulfill模式，则进入到第一个if语句中，显然通过图示6可以得出，头结点head模式并不是fillfull模式，则进入到该if语句中，上来首先判断当前头结点是否被取消了，如果被取消则将头结点移动到栈顶下一个节点，反之则将s节点赋值为fulfill模式按位或当前节点模式，个人认为目的是既保留了原有模式也变成了fulfill模式，我们开篇就讲到了，REQUEST=0，二进制则是00，而DATA=1，其二进制为01，而FULFILLING=2，其二进制表示10，也就是说如果当前节点是REQUEST的话那么节点的内容值时00|10=10，如果节点是DATA模式则s节点的模式时01|10=11，这样的话11既保留了原有模式也是FULFILLING模式，然后将头节点移动到当前s节点，也就是将FULFILLING模式节点入栈操作，目前分析到这里时casHead(h, s=snode(s, e, h, FULFILLING|mode)，栈的情况如下图所示： 接下来运行for循环里面内容，先运行如下内容： 123456SNode m = s.next; // m is s's matchif (m == null) &#123; // all waiters are gone casHead(s, null); // pop fulfill node s = null; // use new node next time break; // restart main loop&#125; 先判断当前节点也就是头结点s的下一个节点上图中head=s节点，所以s.next节点代表的是Ref-750，判断当前节点是否为空，如果为空的话代表没有可匹配的节点，先对head进行替换为null代表堆栈为空，然后将当前s节点设置为null，退出fulfill匹配模式进入到主循环中，会重新进行对当前节点进行操作，是消费还是匹配，显然本例子中m节点是不为空的，所以这里不会运行，跳过之后运行下面内容： 123456SNode mn = m.next;if (m.tryMatch(s)) &#123; casHead(s, mn); // pop both s and m return (E) ((mode == REQUEST) ? m.item : s.item);&#125; else // lost match s.casNext(m, mn); // help unlink mn节点在上图中对应的是Ref-681，这里是重点，m.tryMatch(s)，m节点尝试匹配s节点，进入到方法里，到这一步是我们再来看一下头结点的元素的内容： 并且唤醒m节点的，告诉m节点，你现在有匹配的对象了你可以被唤醒了，这里唤醒之后就会进入到awaitFulfill下面的操作 12345678SNode m = awaitFulfill(s, timed, nanos);if (m == s) &#123; // wait was cancelled clean(s); return null;&#125;if ((h = head) != null &amp;&amp; h.next == s) casHead(h, s.next); // help s's fulfillerreturn (E) ((mode == REQUEST) ? m.item : s.item); 运行这里的线程显然是上图中的m节点，因为m节点被唤醒了，m==s代表的是取消了节点，显然没有进行该操作，然后就是帮助头结点进行fulfill操作，这里重点说一下这段代码： 12if ((h = head) != null &amp;&amp; h.next == s) casHead(h, s.next); 获取当前头结点，也就是上图中的头结点如果不为空而且h.next节点为m节点正好是m节点进行操作时的s节点，也就是说这个语句是成立的，直接将头节点指向了上图的mn节点，这里的操作和take中的下面操作是一样的，也就是帮助fulfill操作弹出栈顶和栈顶匹配的节点内容，下面代码： 123456SNode mn = m.next;if (m.tryMatch(s)) &#123; casHead(s, mn); // pop both s and m return (E) ((mode == REQUEST) ? m.item : s.item);&#125; else // lost match s.casNext(m, mn); // help unlink 重点是casHead的代码，弹出s和m两个节点，此时栈中内容如下图所示： 主要的流程分析完毕了，但是细心的朋友会发现，最后面还有一个帮助fulfill的操作，（transfer中）代码如下所示： 123456789101112else &#123; // help a fulfiller SNode m = h.next; // m is h's match if (m == null) // waiter is gone casHead(h, null); // pop fulfilling node else &#123; SNode mn = m.next; if (m.tryMatch(h)) // help match casHead(h, mn); // pop both h and m else // lost match h.casNext(m, mn); // help unlink &#125;&#125; 个人理解是这样的，我们上面也分析到了如果模式是相同模式情况和如果是不同模式且模式不为匹配模式的情况，但是还会有另外一种情况就是如果是不同模式并且头结点是匹配模式的就会进入到帮助去fullfill的情况，我来画图说明一下该情况： 如上图所示，上一个匹配操作没有进行完然后又来了一个请求操作，他就会帮助head进行匹配操作，也就是运行上面的代码逻辑，逻辑和匹配内容是一样的。 接下来让我们看一下取消的clean方法内容: 12345678910111213141516171819202122void clean(SNode s) &#123; s.item = null; // 将item值设置为null s.waiter = null; // 将线程设置为null SNode past = s.next; // s节点下一个节点如果不为空，并且节点是取消节点则指向下下个节点，这里是结束的标识，代表没有了。 if (past != null &amp;&amp; past.isCancelled()) past = past.next; // 如果取消的是头节点则运行下面的清理操作，操作逻辑很简单就是判断头结点是不是取消节点，如果是则将节点一定到下一个节点 SNode p; while ((p = head) != null &amp;&amp; p != past &amp;&amp; p.isCancelled()) casHead(p, p.next); // 取消不是头结点的嵌套节点。 while (p != null &amp;&amp; p != past) &#123; SNode n = p.next; if (n != null &amp;&amp; n.isCancelled()) p.casNext(n, n.next); else p = n; &#125;&#125; 通过源码可以看到首先是先找到一个可以结束的标识past，也就说到这里就结束了，判断是否不是头节点被取消了，如果是头节点被取消了则进行第一个while语句，操作也很简单就是将头节点替换头结点的下一个节点，如果不是头节点被取消了则进行下面的while语句操作，其实就是将取消的上一个节点的下一个节点指定为被取消节点的下一个节点，到此分析完毕了。 结束语如果有分析不正确的请各位指正，我这边改正~","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://www.battleheart.cn/tags/并发编程/"},{"name":"多线程","slug":"多线程","permalink":"https://www.battleheart.cn/tags/多线程/"}]},{"title":"SynchronousQueue原理详解-公平模式","slug":"synchronousqueue-principle-fair-pattern","date":"2019-05-04T08:44:16.000Z","updated":"2019-05-11T03:22:50.954Z","comments":true,"path":"2019/05/04/synchronousqueue-principle-fair-pattern/","link":"","permalink":"https://www.battleheart.cn/2019/05/04/synchronousqueue-principle-fair-pattern/","excerpt":"","text":"SynchronousQueue原理详解-公平模式一、介绍SynchronousQueue是一个双栈双队列算法，无空间的队列或栈，任何一个对SynchronousQueue写需要等到一个对SynchronousQueue的读操作，反之亦然。一个读操作需要等待一个写操作，相当于是交换通道，提供者和消费者是需要组队完成工作，缺少一个将会阻塞线程，知道等到配对为止。 SynchronousQueue是一个队列和栈算法实现，在SynchronousQueue中双队列FIFO提供公平模式，而双栈LIFO提供的则是非公平模式。 对于SynchronousQueue来说，他的put方法和take方法都被抽象成统一方法来进行操作，通过抽象出内部类Transferer，来实现不同的操作。 注意事项：本文分析主要是针对jdk1.8的版本进行分析\u0011\u0011，下面的代码中的线程执行顺序可能并不能完全保证顺序性，执行时间比较短，所以暂且认定有序执行。 约定：图片中以Reference-开头的代表对象的引用地址，通过箭头方式进行引用对象。 Transferer.transfer方法主要介绍如下所示： 1234567891011121314abstract static class Transferer&lt;E&gt; &#123; /** * 执行put和take方法. * * @param e 非空时,表示这个元素要传递给消费者（提供者-put）; * 为空时, 则表示当前操作要请求消费一个数据（消费者-take）。 * offered by producer. * @param timed 决定是否存在timeout时间。 * @param nanos 超时时长。 * @return 如果返回非空, 代表数据已经被消费或者正常提供; 如果为空, * 则表示由于超时或中断导致失败。可通过Thread.interrupted来检查是那种。 */ abstract E transfer(E e, boolean timed, long nanos);&#125; 接下来看一下SynchronousQueue的字段信息： 12345678910111213141516171819/** CPU数量 */static final int NCPUS = Runtime.getRuntime().availableProcessors();/** * 自旋次数，如果transfer指定了timeout时间，则使用maxTimeSpins,如果CPU数量小于2则自旋次数为0，否则为32 * 此值为经验值，不随CPU数量增加而变化，这里只是个常量。 */static final int maxTimedSpins = (NCPUS &lt; 2) ? 0 : 32;/** * 自旋次数，如果没有指定时间设置，则使用maxUntimedSpins。如果NCPUS数量大于等于2则设定为为32*16，否则为0； */static final int maxUntimedSpins = maxTimedSpins * 16;/** * The number of nanoseconds for which it is faster to spin * rather than to use timed park. A rough estimate suffices. */static final long spinForTimeoutThreshold = 1000L; NCPUS：代表CPU的数量 maxTimedSpins：自旋次数，如果transfer指定了timeout时间，则使用maxTimeSpins,如果CPU数量小于2则自旋次数为0，否则为32，此值为经验值，不随CPU数量增加而变化，这里只是个常量。 maxUntimedSpins：自旋次数，如果没有指定时间设置，则使用maxUntimedSpins。如果NCPUS数量大于等于2则设定为为32*16，否则为0； spinForTimeoutThreshold：为了防止自定义的时间限过长，而设置的，如果设置的时间限长于这个值则取这个spinForTimeoutThreshold 为时间限。这是为了优化而考虑的。这个的单位为纳秒。 公平模式-TransferQueueTransferQueue内部是如何进行工作的，这里先大致讲解下，队列采用了互补模式进行等待，QNode中有一个字段是isData，如果模式相同或空队列时进行等待操作，互补的情况下就进行消费操作。 入队操作相同模式 不同模式时进行出队列操作： 这时候来了一个isData=false的互补模式，队列就会变成如下状态： TransferQueue继承自Transferer抽象类，并且实现了transfer方法，它主要包含以下内容: QNode代表队列中的节点元素，它内部包含以下字段信息： 字段信息描述 字段 描述 类型 next 下一个节点 QNode item 元素信息 Object waiter 当前等待的线程 Thread isData 是否是数据 boolean 方法信息描述 方法 描述 casNext 替换当前节点的next节点 casItem 替换当前节点的item数据 tryCancel 取消当前操作，将当前item赋值为this(当前QNode节点) isCancelled 如果item是this(当前QNode节点)的话就返回true，反之返回false isOffList 如果已知此节点离队列，判断next节点是不是为this，则返回true，因为由于* advanceHead操作而忘记了其下一个指针。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899E transfer(E e, boolean timed, long nanos) &#123; /* Basic algorithm is to loop trying to take either of * two actions: * * 1. If queue apparently empty or holding same-mode nodes, * try to add node to queue of waiters, wait to be * fulfilled (or cancelled) and return matching item. * * 2. If queue apparently contains waiting items, and this * call is of complementary mode, try to fulfill by CAS'ing * item field of waiting node and dequeuing it, and then * returning matching item. * * In each case, along the way, check for and try to help * advance head and tail on behalf of other stalled/slow * threads. * * The loop starts off with a null check guarding against * seeing uninitialized head or tail values. This never * happens in current SynchronousQueue, but could if * callers held non-volatile/final ref to the * transferer. The check is here anyway because it places * null checks at top of loop, which is usually faster * than having them implicitly interspersed. */ QNode s = null; // constructed/reused as needed // 分为两种状态1.有数据=true 2.无数据=false boolean isData = (e != null); // 循环内容 for (;;) &#123; // 尾部节点。 QNode t = tail; // 头部节点。 QNode h = head; // 判断头部和尾部如果有一个为null则自旋转。 if (t == null || h == null) // 还未进行初始化的值。 continue; // 自旋 // 头结点和尾节点相同或者尾节点的模式和当前节点模式相同。 if (h == t || t.isData == isData) &#123; // 空或同模式。 // tn为尾节点的下一个节点信息。 QNode tn = t.next; // 这里我认为是阅读不一致，原因是当前线程还没有阻塞的时候其他线程已经修改了尾节点tail会导致当前线程的tail节点不一致。 if (t != tail) // inconsistent read continue; if (tn != null) &#123; // lagging tail advanceTail(t, tn); continue; &#125; if (timed &amp;&amp; nanos &lt;= 0) // 这里如果指定timed判断时间小于等于0直接返回。 return null; // 判断新增节点是否为null,为null直接构建新节点。 if (s == null) s = new QNode(e, isData); if (!t.casNext(null, s)) // 如果next节点不为null说明已经有其他线程进行tail操作 continue; // 将t节点替换为s节点 advanceTail(t, s); // 等待有消费者消费线程。 Object x = awaitFulfill(s, e, timed, nanos); // 如果返回的x，指的是s.item,如果s.item指向自己的话清除操作。 if (x == s) &#123; clean(t, s); return null; &#125; // 如果没有取消联系 if (!s.isOffList()) &#123; // 将当前节点替换头结点 advanceHead(t, s); // unlink if head if (x != null) // 取消item值，这里是take方法时会进行item赋值为this s.item = s; // 将等待线程设置为null s.waiter = null; &#125; return (x != null) ? (E)x : e; &#125; else &#123; // complementary-mode // 获取头结点下一个节点 QNode m = h.next; // node to fulfill // 如果当前线程尾节点和全局尾节点不一致,重新开始 // 头结点的next节点为空，代表无下一个节点，则重新开始， // 当前线程头结点和全局头结点不相等，则重新开始 if (t != tail || m == null || h != head) continue; // inconsistent read Object x = m.item; if (isData == (x != null) || // m already fulfilled x == m || // m cancelled !m.casItem(x, e)) &#123; // lost CAS advanceHead(h, m); // dequeue and retry continue; &#125; advanceHead(h, m); // successfully fulfilled LockSupport.unpark(m.waiter); return (x != null) ? (E)x : e; &#125; &#125;&#125; 我们来看一下awaitFulfill方法内容： 1234567891011121314151617181920212223242526272829303132333435363738Object awaitFulfill(QNode s, E e, boolean timed, long nanos) &#123; // 如果指定了timed则为System.nanoTime() + nanos，反之为0。 final long deadline = timed ? System.nanoTime() + nanos : 0L; // 获取当前线程。 Thread w = Thread.currentThread(); // 如果头节点下一个节点是当前s节点(以防止其他线程已经修改了head节点) // 则运算(timed ? maxTimedSpins : maxUntimedSpins)，否则直接返回。 // 指定了timed则使用maxTimedSpins，反之使用maxUntimedSpins int spins = ((head.next == s) ? (timed ? maxTimedSpins : maxUntimedSpins) : 0); // 自旋 for (;;) &#123; // 判断是否已经被中断。 if (w.isInterrupted()) //尝试取消，将当前节点的item修改为当前节点(this)。 s.tryCancel(e); // 获取当前节点内容。 Object x = s.item; // 判断当前值和节点值不相同是返回，因为弹出时会将item值赋值为null。 if (x != e) return x; if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; s.tryCancel(e); continue; &#125; &#125; if (spins &gt; 0) --spins; else if (s.waiter == null) s.waiter = w; else if (!timed) LockSupport.park(this); else if (nanos &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanos); &#125;&#125; 首先先判断有没有被中断，如果被中断则取消本次操作，将当前节点的item内容赋值为当前节点。 判断当前节点和节点值不相同是返回 将当前线程赋值给当前节点 自旋，如果指定了timed则使用LockSupport.parkNanos(this, nanos);，如果没有指定则使用LockSupport.park(this);。 中断相应是在下次才能被执行。 通过上面源码分析我们这里做出简单的示例代码演示一下put操作和take操作是如何进行运作的，首先看一下示例代码，如下所示： 12345678910111213141516171819202122232425262728293031323334353637/** * SynchronousQueue进行put和take操作。 * * @author battleheart */public class SynchronousQueueDemo &#123; public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newFixedThreadPool(3); SynchronousQueue&lt;Integer&gt; queue = new SynchronousQueue&lt;&gt;(true); Thread thread1 = new Thread(() -&gt; &#123; try &#123; queue.put(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); thread1.start(); Thread.sleep(2000); Thread thread2 = new Thread(() -&gt; &#123; try &#123; queue.put(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); thread2.start(); Thread.sleep(10000); Thread thread3 = new Thread(() -&gt; &#123; try &#123; System.out.println(queue.take()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); thread3.start(); &#125;&#125; 首先上来之后进行的是两次take操作，然后再put操作，默认队列上来会进行初始化，初始化的内容如下代码所示: 12345TransferQueue() &#123; QNode h = new QNode(null, false); // initialize to dummy node. head = h; tail = h;&#125; 初始化后队列的状态如下图所示： 当线程1执行put操作时，来分析下代码： 1234QNode t = tail;QNode h = head;if (t == null || h == null) // saw uninitialized value continue; 首先执行局部变量t代表队尾指针，h代表队头指针，判断队头和队尾不为空则进行下面的操作，接下来是if…else语句这里是分水岭，当相同模式操作的时候执行if语句，当进行不同模式操作时执行的是else语句，程序是如何控制这样的操作的呢？接下来我们慢慢分析一下： 12345678910111213141516171819202122232425262728293031if (h == t || t.isData == isData) &#123; // 队列为空或者模式相同时进行if语句 QNode tn = t.next; if (t != tail) // 判断t是否是队尾，不是则重新循环。 continue; if (tn != null) &#123; // tn是队尾的下个节点，如果tn有内容则将队尾更换为tn，并且重新循环操作。 advanceTail(t, tn); continue; &#125; if (timed &amp;&amp; nanos &lt;= 0) // 如果指定了timed并且延时时间用尽则直接返回空，这里操作主要是offer操作时，因为队列无存储空间的当offer时不允许插入。 return null; if (s == null) // 这里是新节点生成。 s = new QNode(e, isData); if (!t.casNext(null, s)) // 将尾节点的next节点修改为当前节点。 continue; advanceTail(t, s); // 队尾移动 Object x = awaitFulfill(s, e, timed, nanos); //自旋并且设置线程。 if (x == s) &#123; // wait was cancelled clean(t, s); return null; &#125; if (!s.isOffList()) &#123; // not already unlinked advanceHead(t, s); // unlink if head if (x != null) // and forget fields s.item = s; s.waiter = null; &#125; return (x != null) ? (E)x : e;&#125; 上面代码是if语句中的内容，进入到if语句中的判断是如果头结点和尾节点相等代表队列为空，并没有元素所有要进行插入队列的操作，或者是队尾的节点的isData标志和当前操作的节点的类型一样时，会进行入队操作，isData标识当前元素是否是数据，如果为true代表是数据，如果为false则代表不是数据，换句话说只有模式相同的时候才会往队列中存放，如果不是模式相同的时候则代表互补模式，就不走if语句了，而是走了else语句，上面代码中做有注释讲解，下面看一下这里： 1234if (s == null) // 这里是新节点生成。 s = new QNode(e, isData);if (!t.casNext(null, s)) // 将尾节点的next节点修改为当前节点。 continue 当执行上面代码后，队列的情况如下图所示：(这里视为插入第一个元素图，方便下面的引用) 接下来执行这段代码： 1advanceTail(t, s); // 队尾移动 修改了tail节点后，这时候就需要进行自旋操作，并且设置QNode的waiter等待线程，并且将线程等待，等到唤醒线程进行唤醒操作 1Object x = awaitFulfill(s, e, timed, nanos); //自旋并且设置线程。 方法内部分析局部内容，上面已经全部内容的分析： 12345678if (spins &gt; 0) --spins;else if (s.waiter == null) s.waiter = w;else if (!timed) LockSupport.park(this);else if (nanos &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanos); 如果自旋时间spins还有则进行循环递减操作，接下来判断如果当前节点的waiter是空则价格当前线程赋值给waiter，上图中显然是为空的所以会把当前线程进行赋值给我waiter，接下来就是等待操作了。 上面线程则处于等待状态，接下来是线程二进行操作，这里不进行重复进行，插入第二个元素队列的状况，此时线程二也处于等待状态。 上面的主要是put了两次操作后队列的情况，接下来分析一下take操作时又是如何进行操作的，当take操作时，isData为false，而队尾的isData为true两个不相等，所以不会进入到if语句，而是进入到了else语句 1234567891011121314151617&#125; else &#123; // 互补模式 QNode m = h.next; // 获取头结点的下一个节点，进行互补操作。 if (t != tail || m == null || h != head) continue; // 这里就是为了防止阅读不一致的问题 Object x = m.item; if (isData == (x != null) || // 如果x=null说明已经被读取了。 x == m || // x节点和m节点相等说明被中断操作，被取消操作了。 !m.casItem(x, e)) &#123; // 这里是将item值设置为null advanceHead(h, m); // 移动头结点到头结点的下一个节点 continue; &#125; advanceHead(h, m); // successfully fulfilled LockSupport.unpark(m.waiter); return (x != null) ? (E)x : e;&#125; 首先获取头结点的下一个节点用于互补操作，也就是take操作，接下来进行阅读不一致的判断，防止其他线程进行了阅读操作，接下来获取需要弹出内容x=1，首先进行判断节点内容是不是已经被消费了，节点内容为null时则代表被消费了，接下来判断节点的item值是不是和本身相等如果相等话说明节点被取消了或者被中断了，然后移动头结点到下一个节点上，然后将refenrence-715的item值修改为null，至于为什么修改为null这里留下一个悬念，这里还是比较重要的，大家看到这里的时候需要注意下，显然这些都不会成立，所以if语句中内容不会被执行，接下来的队列的状态是是这个样子的： OK，接下来就开始移动队头head了，将head移动到m节点上，执行代码如下所示： 1advanceHead(h, m); 此时队列的状态是这个样子的： 12LockSupport.unpark(m.waiter);return (x != null) ? (E)x : e; 接下来将执行唤醒被等待的线程，也就是thread-0，然后返回获取item值1，take方法结束，但是这里并没有结束，因为唤醒了put的线程，此时会切换到put方法中，这时候线程唤醒后会执行awaitFulfill方法，此时循环时，有与item值修改为null则直接返回内容。 123Object x = s.item;if (x != e) return x; 这里的代码我们可以对照插入第一个元素图，s节点也就是当前m节点，获取值得时候已经修改为null，但是当时插入的值时1，所以两个不想等了，则直接返回null值。 12345678910111213Object x = awaitFulfill(s, e, timed, nanos);if (x == s) &#123; // wait was cancelled clean(t, s); return null;&#125;if (!s.isOffList()) &#123; // not already unlinked advanceHead(t, s); // unlink if head if (x != null) // and forget fields s.item = s; s.waiter = null;&#125;return (x != null) ? (E)x : e; 又返回到了transfer方法的if语句中，此时x和s并不相等所以不用进行clean操作，首先判断s节点是否已经离队了，显然并没有进行离队操作，advanceHead(t, s);操作不会被执行因为上面已近将头节点修改了，但是第一次插入的时候头结点还是reference-716，此时已经是reference-715,而t节点的引用地址是reference-716，所以不会操作，接下来就是将waiter设置为null，也就是忘记掉等待的线程。 分析了正常的take和put操作，接下来分析下中断操作，由于中断相应后，会被执行if(w.isInterrupted())这段代码，它会执行s.tryCancel(e)方法，这个方法的作用的是将QNode节点的item节点赋值为当前QNode，这时候x和e值就不相等了（if (x != e)），x的值是s.item，则为当前QNode，而e的值是用户指定的值，这时候返回x(s.item)。返回到函数调用地方transfer中，这时候要执行下面语句： 1234if (x == s) &#123; clean(t, s); return null;&#125; 进入到clean方法执行清理当前节点，下面是方法clean代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * Gets rid of cancelled node s with original predecessor pred. */void clean(QNode pred, QNode s) &#123; s.waiter = null; // forget thread /* * At any given time, exactly one node on list cannot be * deleted -- the last inserted node. To accommodate this, * if we cannot delete s, we save its predecessor as * \"cleanMe\", deleting the previously saved version * first. At least one of node s or the node previously * saved can always be deleted, so this always terminates. */ while (pred.next == s) &#123; // Return early if already unlinked QNode h = head; QNode hn = h.next; // Absorb cancelled first node as head if (hn != null &amp;&amp; hn.isCancelled()) &#123; advanceHead(h, hn); continue; &#125; QNode t = tail; // Ensure consistent read for tail if (t == h) return; QNode tn = t.next; // 判断现在的t是不是末尾节点，可能其他线程插入了内容导致不是最后的节点。 if (t != tail) continue; // 如果不是最后节点的话将其现在t.next节点作为tail尾节点。 if (tn != null) &#123; advanceTail(t, tn); continue; &#125; // 如果当前节点不是尾节点进入到这里面。 if (s != t) &#123; // If not tail, try to unsplice // 获取当前节点（被取消的节点）的下一个节点。 QNode sn = s.next; // 修改上一个节点的next(下一个)元素为下下个节点。 if (sn == s || pred.casNext(s, sn)) //返回。 return; &#125; QNode dp = cleanMe; if (dp != null) &#123; // 尝试清除上一个标记为清除的节点。 QNode d = dp.next; //1.获取要被清除的节点 QNode dn; if (d == null || // 被清除节点不为空 d == dp || // 被清除节点已经离队 !d.isCancelled() || // 被清除节点是标记为Cancel状态的。 (d != t &amp;&amp; // 被清除节点不是尾节点 (dn = d.next) != null &amp;&amp; // 被清除节点下一个节点不为null dn != d &amp;&amp; // that is on list dp.casNext(d, dn))) // 将被清除的节点的前一个节点的下一个节点修改为被清除节点的下一个节点。 casCleanMe(dp, null); // 清空cleanMe节点。 if (dp == pred) return; // s is already saved node &#125; else if (casCleanMe(null, pred)) // 这里将上一个节点标记为被清除操作，但是其实要操作的是下一个节点。 return; // Postpone cleaning s &#125;&#125; 如果节点中取消的头结点的下一个节点，只需要移动当前head节点到下一个节点即可。 如果取消的是中间的节点，则将当前节点next节点修改为下下个节点。 如果修改为末尾的节点，则将当前节点放入到QNode的clearMe中，等待有内容进来之后下一次进行清除操作。 实例一：清除头结点下一个节点，下面是实例代码进行讲解： 12345678910111213141516171819202122232425262728293031323334/** * 清除头结点的下一个节点实例代码。 * * @author battleheart */public class SynchronousQueueDemo &#123; public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newFixedThreadPool(3); SynchronousQueue&lt;Integer&gt; queue = new SynchronousQueue&lt;&gt;(true); AtomicInteger atomicInteger = new AtomicInteger(0); Thread thread1 = new Thread(() -&gt; &#123; try &#123; queue.put(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); thread1.start(); Thread.sleep(200); Thread thread2 = new Thread(() -&gt; &#123; try &#123; queue.put(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); thread2.start(); Thread.sleep(2000); thread1.interrupt(); &#125;&#125; 上面例子说明我们启动了两个线程，分别向SynchronousQueue队列中添加了元素1和元素2，添加成功之后的，让主线程休眠一会，然后将第一个线程进行中断操作，添加两个元素后节点所处在的状态为下图所示： 当我们调用thread1.interrupt时，此时线程1等待的消费操作将被终止，会相应上面awaitFulfill方法，该方法会运行下面代码： 12345678if (w.isInterrupted()) //尝试取消，将当前节点的item修改为当前节点(this)。 s.tryCancel(e);// 获取当前节点内容。Object x = s.item;// 判断当前值和节点值不相同是返回，因为弹出时会将item值赋值为null。if (x != e) return x; 首先上来现将s节点(上图中的Reference-715引用对象)的item节点设置为当前节点引用(Reference-715引用对象)，所以s节点和e=1不相等则直接返回，此时节点的状态变化如下所示： 退出awaitFulfill并且返回的是s节点内容（实际上返回的就是s节点），接下来返回到调用awaitFulfill的方法transfer方法中 12345Object x = awaitFulfill(s, e, timed, nanos);if (x == s) &#123; // 是否是被取消了 clean(t, s); return null;&#125; 首先判断的事x节点和s节点是否相等，上面我们也说了明显是相等的所以这里会进入到clean方法中，clean(QNode pred, QNode s)clean方法一个是前节点，一个是当前被取消的节点，也就是当前s节点的前节点是head节点，接下来我们一步一步的分析代码： 1s.waiter = null; // 删除等待的线程。 进入到方法体之后首先先进行的是将当前节点的等待线程删除，如下图所示： 接下来进入while循环，循环内容时pred.next == s如果不是则表示已经移除了节点，反之还在队列中，则进行下面的操作： 123456QNode h = head;QNode hn = h.next; // 如果取消的是第一个节点则进入下面语句if (hn != null &amp;&amp; hn.isCancelled()) &#123; advanceHead(h, hn); continue;&#125; 可以看到首先h节点为head节点，hn为头结点的下一个节点，在进行判断头结点的下一个节点不为空并且头结点下一个节点是被中断的节点(取消的节点)，则进入到if语句中，if语句其实也很简单就是将头结点修改为头结点的下一个节点(s节点，别取消节点，并且将前节点的next节点修改为自己，也就是移除了之前的节点，我们看下advanceHead方法： 12345void advanceHead(QNode h, QNode nh) &#123; if (h == head &amp;&amp; UNSAFE.compareAndSwapObject(this, headOffset, h, nh)) h.next = h; // forget old next&#125; 首先上来先进行CAS移动头结点，再讲原来头结点h的next节点修改为自己(h)，为什么这样做呢？因为上面进行advanceHead之后并没有退出循环，是进行continue操作，也就是它并没有跳出while循环，他还会循环一次prev.next此时已经不能等于s所以退出循环，如下图所示： 实例二：清除中间的节点 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * SynchronousQueue实例二，清除中间的节点。 * * @author battleheart */public class SynchronousQueueDemo &#123; public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newFixedThreadPool(3); SynchronousQueue&lt;Integer&gt; queue = new SynchronousQueue&lt;&gt;(true); AtomicInteger atomicInteger = new AtomicInteger(0); Thread thread1 = new Thread(() -&gt; &#123; try &#123; queue.put(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); thread1.start(); //休眠一会。 Thread.sleep(200); Thread thread2 = new Thread(() -&gt; &#123; try &#123; queue.put(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); thread2.start(); //休眠一会。 Thread.sleep(200); Thread thread3 = new Thread(() -&gt; &#123; try &#123; queue.put(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); thread3.start(); //休眠一会。 Thread.sleep(10000); thread2.interrupt(); &#125;&#125; 看上面例子，首先先进行put操作三次，也就是入队3条数据，分别是整型值1，整型值2，整型值3，然后将当前线程休眠一下，对中间线程进行中断操作，通过让主线程休眠一会保证线程执行顺序性(当然上面线程不一定能保证执行顺序，因为put操作一下子就执行完了所以这点时间是可以的)，此时队列所处的状态来看一下下图： 当休眠一会之后，进入到threa2进行中断操作，目前上图中表示Reference-723被中断操作，此时也会进入到awaitFulfill方法中，将Reference-723的item节点修改为当前节点，如下图所示： 进入到clear方法中此时的prev节点为Reference-715，s节点是被清除节点，还是首先进入clear方法中先将waiter设置为null，取消当前线程内容，如下图所示： 接下来进入到循环中，进行下面处理 123456789101112131415161718192021QNode h = head;QNode hn = h.next; // Absorb cancelled first node as headif (hn != null &amp;&amp; hn.isCancelled()) &#123; advanceHead(h, hn); continue;&#125;QNode t = tail; // Ensure consistent read for tailif (t == h) return;QNode tn = t.next;if (t != tail) continue;if (tn != null) &#123; advanceTail(t, tn); continue;&#125;if (s != t) &#123; // If not tail, try to unsplice QNode sn = s.next; if (sn == s || pred.casNext(s, sn)) return;&#125; 第一个if语句已经分析过了所以说这里不会进入到里面去，接下来是进行尾节点t是否是等于head节点如果相等则代表没有元素，在判断当前方法的t尾节点是不是真正的尾节点tail如果不是则进行修改尾节点，先来看一下现在的状态： tn != null判断如果tn不是尾节点，则将tn作为尾节点处理，如果处理之后还不是尾节点还会进行处理直到tail是尾节点未知，我们现在这个是尾节点所以跳过这段代码。s != t通过上图可以看到s节点是被清除节点，并不是尾节点所以进入到循环中： 12345if (s != t) &#123; // If not tail, try to unsplice QNode sn = s.next; if (sn == s || pred.casNext(s, sn)) return;&#125; 首先获取的s节点的下一个节点，上图中表示Reference-725节点，判断sn是都等于当前节点显然这一条不成立，pred节点为Reference-715节点，将715节点的next节点变成Reference-725节点，这里就将原来的节点清理出去了，现在的状态如下所示： 实例三：删除的节点是尾节点 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * SynchronousQueue实例三，删除的节点为尾节点 * * @author battleheart */public class SynchronousQueueDemo &#123; public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newFixedThreadPool(3); SynchronousQueue&lt;Integer&gt; queue = new SynchronousQueue&lt;&gt;(true); AtomicInteger atomicInteger = new AtomicInteger(0); Thread thread1 = new Thread(() -&gt; &#123; try &#123; queue.put(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); thread1.start(); Thread thread2 = new Thread(() -&gt; &#123; try &#123; queue.put(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); thread2.start(); Thread.sleep(10000); thread2.interrupt(); Thread.sleep(10000); Thread thread3 = new Thread(() -&gt; &#123; try &#123; queue.put(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); thread3.start(); Thread.sleep(10000); thread3.interrupt(); &#125;&#125; 该例子主要说明一个问题就是删除的节点如果是末尾节点的话，clear方法又是如何处理的，首先启动了三个线程其中主线程休眠了一会，为了能让插入的顺序保持线程1，线程2，线程3这样子，启动第二个线程后，又将第二个线程中断，这是第二个线程插入的节点为尾节点，然后再启动第三个节点插入值，再中断了第三个节点末尾节点，说一下为啥这样操作，因为当清除尾节点时，并不是直接移除当前节点，而是将被清除的节点的前节点设置到QNode的CleanMe中，等待下次clear方法时进行清除上次保存在CleanMe的节点，然后再处理当前被中断节点，将新的被清理的节点prev设置为cleanMe当中，等待下次进行处理，接下来一步一步分析，首先我们先来看一下第二个线程启动后节点的状态。 此时运行thread2.interrupt();将第二个线程中断，这时候会进入到clear方法中，前面的代码都不会被返回，会执行下面的语句： 12345678910111213141516QNode dp = cleanMe;if (dp != null) &#123; // Try unlinking previous cancelled node QNode d = dp.next; QNode dn; if (d == null || // d is gone or d == dp || // d is off list or !d.isCancelled() || // d not cancelled or (d != t &amp;&amp; // d not tail and (dn = d.next) != null &amp;&amp; // has successor dn != d &amp;&amp; // that is on list dp.casNext(d, dn))) // d unspliced casCleanMe(dp, null); if (dp == pred) return; // s is already saved node&#125; else if (casCleanMe(null, pred)) return; 首先获得TransferQueue当中cleanMe节点，此时获取的为null，当判断dp!=null时就会被跳过，直接执行 casCleanMe(null, pred)此时pred传入的值时t节点指向的内容，也就是当前节点的上一个节点，它会被标记为清除操作节点(其实并不清楚它而是清除它下一个节点，也就是说item=this的节点)，此时看一下节点状态为下图所示： 接下来第三个线程启动了这时候又往队列中添加了元素3，此时队列的状况如下图所示： 此时thread3也被中断操作了，这时候还是运行上面的代码，但是这次不同的点在于cleanMe已经不是空值，是有内容的，首先获取的是cleanMe的下一个节点（d），然我来把变量标记在图上然后看起来好分析一些，如下图所示： dp表示d节点的前一个pred节点，dn表示d节点的next节点，主要逻辑在这里： 12345678910if (d == null || // d is gone or d == dp || // d is off list or !d.isCancelled() || // d not cancelled or (d != t &amp;&amp; // d not tail and (dn = d.next) != null &amp;&amp; // has successor dn != d &amp;&amp; // that is on list dp.casNext(d, dn))) // d unspliced casCleanMe(dp, null);if (dp == pred) return; // s 首先判断d节点是不是为null，如果d节点为null代表已经清除掉了，如果cleanMe节点的下一个节点和自己相等，说明需要清除的节点已经离队了，判断下个节点是不是需要被清除的节点，目前看d节点是被清除的节点，然后就将被清除的节点的下一个节点赋值给dn并且判断d节点是不是末尾节点，如果不是末尾节点则进行dp.casNext方法，这个地方是关键点，它将被清除节点d的前节点的next节点修改为被清除节点d的后面节点dn，然后调用caseCleanMe将TransferQueue中的cleanMe节点清空，此时节点的内容如下所示： 可以看出将上一次标记为清除的节点清除了队列中，清除完了就完事儿？那这次的怎么弄呢?因为现在运行的是thread3的中断程序，所以上面并没有退出，而是再次进入循环，循环之后发现dp为null则会运行casCleanMe(null, pred)，此时当前节点s的前一个节点已经被清除队列，但是并不影响后续的清除操作，因为前节点的next节点还在维护中，也是前节点的next指向还是reference-725,如下图所示： 就此分析完毕如果有不正确的地方请指正。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://www.battleheart.cn/tags/并发编程/"},{"name":"多线程","slug":"多线程","permalink":"https://www.battleheart.cn/tags/多线程/"}]},{"title":"系统栈的工作原理","slug":"stack-working-principle","date":"2019-04-11T08:28:56.000Z","updated":"2019-04-11T08:36:10.613Z","comments":true,"path":"2019/04/11/stack-working-principle/","link":"","permalink":"https://www.battleheart.cn/2019/04/11/stack-working-principle/","excerpt":"","text":"开篇本篇文章着重写的是系统中栈的工作原理，以及函数调用过程中栈帧的产生与释放的过程，有可能名字过大，如果不合适我可以换一个名字，希望大家能够指正，小丁虚心求教！如果有哪里写的不清楚的或者错误的地方请及时更正，小丁再次谢过了。文章里面有错别字，也可能会有好友说寄存器的32、16位的区别其实我感觉这里主要讲的还是些原理性的东西，后续会将文章图片错别字进行调整.（图片里面的posh改为push） 内存的不同用途根据不同的操作系统，一个进程可能被分配到不同的内存区域去执行。但是不管什么样的操作系统、什么样的计算机架构，进程使用的内存都可以按照功能大致分为以下4个部分： 代码区：这个区域存储着被装入执行的二进制机器代码，处理器会到这个区域取指并执行。 数据区：用于存储全局变量等。 堆区：进程可以在堆区动态地请求一定大小的内存，并在用完之后归还给堆区。动态分配和回收是堆区的特点。 栈区：用于动态地存储函数之间的关系，以保证被调用函数在返回时恢复到母函数中继续执行。 在Windows平台下，高级语言写出的程序经过编译链接，最终会变成PE文件。当PE文件被装载运行后，就成了所谓的进程。 PE文件代码段中包含的二进制级别的机器代码会被装入内存的代码区(.text)，处理器将到内存的这个区域一条一条地取出指令和操作数，并送入运算逻辑单元进行运算；如果代码中请求开辟动态内存，则会在内存的堆区分配一块大小合适的区域返回给代码区的代码使用；当函数调用发生时，函数的调用关系等信息会动态地保存在内存的栈区，以供处理器在执行完被调用函数的代码时，返回母函数。 如果把计算机看成一个有条不紊的工厂，我们可以得到如下类比： &lt; CPU是完成工作的工人。 &lt; 数据区、堆区、栈区等则是用来存放原料、半成品、成品等各种东西的场所。 &lt; 存放在代码区的指令则告诉CPU要做什么，怎么做，到哪里去领原材料，用什么工具来做，做完以后把成品放到哪个货仓去。 &lt; 值得一提的是，栈除了扮演存放原料、半成品的仓库之外，它还是车间调度主任的办公室。 栈与系统栈从计算机科学的角度来看，栈指的是一种数据结构，是一种先进后出的数据表。栈的最常见操作有两种：压栈(PUSH)、弹栈(POP)； 用于标识栈的属性也有两个：栈顶(TOP)、栈底(BASE)。 栈在内存中的存放是高地址是栈底（Base），低地址是栈顶（Top）。 下面来演示下栈的工作原理： 首先我们先以这段汇编指令来进行操作： 1234567891011mov ax,0123Hpush axmov bx 2244Hpush bxpop axpop bx 首先我们先将10000H-1000FH这段内存空间来当做栈来使用，首先执行的操作是push ax，会将0123H压入到栈中，SP=SP-2，SS：SP指向当前栈顶当前的单元，以当前的单元为新的栈顶，将ax的数据送到SS：SP指向的内存单元中，SS：SP此时指向新的栈顶。此时ax的数值是0123H；详细请见下图 接来下进行第二部操作：push bx，操作同上: 接下来我们要演示的是pop操作，请注意pop操作的细节，比如到了栈底的时候指针是在哪里？这些都是要进行关注的。 CPU执行pop ax时，SP=SP+2,SS:SP指向1000EH,pop操作栈顶元素，1000CH处的2266H依然存在，但是它在栈中不存在了，当再次push等入栈指令后，SS：SP移至1000CH，并在里面写入新的数据，将其覆盖。详细看下图操作： 当再次进行pop给bx时，这是SP=SP+2,这时候指针就超出了栈底，就变成了SP=10H，所以我们得出一个结论就是当栈为空时，SS=1000H，SP=10H。详细看下面操作： 内存的栈区实际上指的就是系统栈。系统栈由系统自动维护，它用于实现高级语言中函数的调用。对于类似C语言这样的高级语言，系统栈的PUSH、POP等堆栈平衡细节是透明的。一般说来，只有在使用汇编语言开发程序的时候，才需要和它直接打交道。 函数调用约定与相关指令函数调用约定描述了函数传递参数方式和栈帧同工作的技术细节。不同的操作系统、不同的语言、不同的编译器在实现函数调用时的原理虽然基本相同，但具体的调用约定还是有差别的。这包括参数传递方式，参数入栈顺序是从右向左还是从左向右，函数返回时恢复堆栈平衡的操作在子函数中进行还是在母函数中进行。调用方式之间的差异 具体的，对于Visual C++来说，可支持以下3种函数调用约定： 如果要明确使用某一种调用约定，只需要在函数前加上调用约定的声明即可，否则默认情况下，VC会使用_stdcall的调用方式。 除了参数入栈方向和恢复栈平衡操作位置的不同之外，参数传递有时也会有所不同。例如，每一个C++类成员函数都有一个this指针，在Windows平台中，这个指针一般是用ECX寄存器来传递的，但如果用GCC编译器来编译，这个指针会作为最后一个参数压入栈中。 注意：同一段代码用不同的编译选项、不同的编译器编译链接后，得到的可执行文件会有很多不同。 函数调用大概包括以下几个步骤： 参数入栈：将参数从右向左依次压入系统栈中。 返回地址入栈：将当前代码区调用指令的下一条指令地址压入栈中，供函数返回时继续执行。 代码区跳转：处理器从当前代码区跳转到被调用函数的入口处。 栈帧调整：具体包括： &lt;1&gt;保存当前栈帧状态值，已备后面恢复本栈帧时使用(EBP入栈)。 &lt;2&gt;将当前栈帧切换到新栈帧(将ESP值装入EBP，更新栈帧底部)。 &lt;3&gt;给新栈帧分配空间(把ESP减去所需空间的大小，抬高栈顶)。 &lt;4&gt;对于_stdcall调用约定，函数调用时用到的指令序列大致如下： push 参数3 ;假设该函数有3个参数，将从右向做依次入栈 push 参数2 push 参数1 call 函数地址 ;call指令将同时完成两项工作：a)向栈中压入当前指令地址的下一个指令地址，即保存返回地址。 b)跳转到所调用函数的入口处。 push ebp ;保存旧栈帧的底部 mov ebp,esp ;设置新栈帧的底部 (栈帧切换) sub esp,xxx ;设置新栈帧的顶部 (抬高栈顶，为新栈帧开辟空间) 函数返回的步骤如下： &lt;1&gt;保存返回值，通常将函数的返回值保存在寄存器EAX中。 &lt;2&gt;弹出当前帧，恢复上一个栈帧。具体包括： (1)在堆栈平衡的基础上，给ESP加上栈帧的大小，降低栈顶，回收当前栈帧的空间。 (2)将当前栈帧底部保存的前栈帧EBP值弹入EBP寄存器，恢复出上一个栈帧。 (3)将函数返回地址弹给EIP寄存器。 &lt;3&gt;跳转：按照函数返回地址跳回母函数中继续执行。 还是以C语言和Win32平台为例，函数返回时的相关的指令序列如下： add esp,xxx ;降低栈顶，回收当前的栈帧 pop ebp ;将上一个栈帧底部位置恢复到ebp retn ;a)弹出当前栈顶元素，即弹出栈帧中的返回地址，至此，栈帧恢复到上一个栈帧工作完成。b)让处理器跳转到弹出的返回地址，恢复调用前代码区 寄存器与函数栈帧每一个函数独占自己的栈帧空间。当前正在运行的函数的栈帧总是在栈顶。Win32系统提供两个特殊的寄存器用于标识位于系统栈顶端的栈帧。 (1)ESP：栈指针寄存器(extended stack pointer)，其内存放着一个指针，该指针永远指向系统栈最上面一个栈帧的栈顶。 (2)EBP：基址指针寄存器(extended base pointer)，其内存放着一个指针，该指针永远指向系统栈最上面一个栈帧的底部。 【寄存器对栈的标识作用见(图1)】 函数栈帧：ESP和EBP之间的内存空间为当前栈帧,EBP标识了当前栈帧的底部，ESP标识了当前栈帧的顶部。 在函数栈帧中，一般包含以下几类重要信息。 (1)局部变量：为函数局部变量开辟的内存空间。 (2)栈帧状态值：保存前栈帧的顶部和底部(实际上只保存前栈帧的底部，前栈帧的顶部可以通过栈帧平衡计算得到)，用于在本栈被弹出后恢复出上一个栈帧。 (3)函数返回地址：保存当前函数调用前的“断点”信息，也就是函数调用前的指令位置，以便在函数返回时能够恢复到函数被调用前的代码区中继续执行指令。 注：函数栈帧的大小并不固定，一般与其对应函数的局部变量多少有关。函数运行过程中，其栈帧大小也是在不停变化的。除了与栈相关的寄存器外，我们还需要记住另一个至关重要的寄存器。 EIP：指令寄存器(extended instruction pointer)，其内存放着一个指针，该指针永远指向下一条等待执行的指令地址。 可以说如果控制了EIP寄存器的内容，就控制了进程——我们让EIP指向哪里，CPU就会去执行哪里的指令。这里不多说EIP的作用，我个人认为王爽老是的汇编里面讲EIP讲的已经是挺好的了~这里不想多写关于EIP的事情。 结束语本文是针对上面两篇文章的一个基础性的补充希望大家能够喜欢和指正其中的不足之处，小丁虚心学习于请教不知道名字叫啥~ 内容参考：0day安全:软件漏洞分析技术(第2版)","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://www.battleheart.cn/tags/C/"},{"name":"Assembly","slug":"Assembly","permalink":"https://www.battleheart.cn/tags/Assembly/"},{"name":"栈","slug":"栈","permalink":"https://www.battleheart.cn/tags/栈/"}],"author":"BattleHeart"},{"title":"git仓库迁移","slug":"git-server-transfer","date":"2019-04-09T08:44:19.000Z","updated":"2019-04-10T02:33:51.439Z","comments":true,"path":"2019/04/09/git-server-transfer/","link":"","permalink":"https://www.battleheart.cn/2019/04/09/git-server-transfer/","excerpt":"","text":"Git仓库迁移 首先查看当前仓库的远程信息 git remote -v 会出现如下内容： 12origin https://gitee.com/xxxx/xxxxx.git (fetch)origin https://gitee.com/xxxx/xxxxx.git (push) 移除远程分支 git remote rm origin 添加远程仓库 git remote add origin https://gitee.com/xxxx/xxxxx.git 将代码提交到分支 git push origin master:master 提交其他的分支到对应的远程分支 git push origin V0.1:V0.1 其中前面分支代表本地分支，后面的代表远程分支。 简化分支使用git push直接推送 git push –set-upstream origin V0.1 删除远程分支 git push origin –delete V.4 迁移所有tag到服务器上 git push origin –tags","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.battleheart.cn/tags/Git/"}]},{"title":"LinkedBlockingQueue原理解析","slug":"LinkedBlockingQueue-Principle","date":"2019-04-07T08:30:49.000Z","updated":"2019-04-07T08:33:33.137Z","comments":true,"path":"2019/04/07/LinkedBlockingQueue-Principle/","link":"","permalink":"https://www.battleheart.cn/2019/04/07/LinkedBlockingQueue-Principle/","excerpt":"","text":"LinkedBlockingQueue原理详解简述前面已经介绍过关于ArrayBlockingQueue相关原理性内容，我们前面讲过ArrayBlockingQueue是基于数组的方式实现的，那么LinkedBlockingQueue是基于链表的形式实现。先来看一下LinkedBlockingQueue的UML，如下所示： 通过上面的UML可以看到，他也是BlockingQueue的实现，也就是他的核心在于Blocking（阻塞）这个上面，在讲解ArrayBlockingQueue的时候，可以清晰的得出ArrayBlockingQueue是使用了独占锁的方式，要求两个操作进行时获得当先队列的独占锁，那么take()和put()操作就不可能真正的并发。它们会彼此等待对方释放资源，在这种情况下所竞争会比较激励，从而会影响到高并发的效率，而LinkedBlockingQueue为了解决这一问题，采用锁分离的方式进行实现，take()函数和put()函数分别实现了从队列中取得数据和往队列天价收的功能，换句话说就会说take()方法有专门的锁进行控制，而put()方法也有专门的锁进行控制，由于take()方法是操作队尾，put()方法操作队首，又因为LinkedBlockingQueue是基于链表的方式实现，因此两个操作不受影响。 源码解析首先看一下LinkedBlockingQueue中的字段信息： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 链表的Node节点 */static class Node&lt;E&gt; &#123; E item; /** * 下一个节点，如果节点为Null代表最后一个节点 * - the real successor Node * - this Node, meaning the successor is head.next * - null, meaning there is no successor (this is the last node) */ Node&lt;E&gt; next; Node(E x) &#123; item = x; &#125;&#125;/** 容量限制,如果没有指定则为Integer.MAX_VALUE */private final int capacity;/** 当前队列的元素个数，原子操作 */private final AtomicInteger count = new AtomicInteger();/** * 头结点 * Invariant: head.item == null */transient Node&lt;E&gt; head;/** * 尾节点 * Invariant: last.next == null */private transient Node&lt;E&gt; last;/**take, poll的重入锁 */private final ReentrantLock takeLock = new ReentrantLock();/** 不为空的条件 */private final Condition notEmpty = takeLock.newCondition();/** put, offer的重入锁 */private final ReentrantLock putLock = new ReentrantLock();/** 队满条件 */private final Condition notFull = putLock.newCondition(); Node节点维护链表的信息。 最大容量限制，用户可自己指定，如果没有指定则代表Integer的最大值。 包含了head头结点，tail尾节点。 takeLock代表的是take，poll等出队列操作的锁。 putLock代表是put，offer等入队列的操作的锁。 接下来看一下put方法是如何进行入队操作： 12345678910111213141516171819202122232425262728293031323334353637/** * 将指定元素插入此队列的尾部, 等待队列空间可用。 * * @throws InterruptedException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public void put(E e) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); // Note: convention in all put/take/etc is to preset local var // 保持计数为负，表示失败，除非设定。 int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); // putLock锁。 final ReentrantLock putLock = this.putLock; // 链表长度，原子操作。 final AtomicInteger count = this.count; // 获得锁，并且响应中断，put操作只有一个线程操作。 putLock.lockInterruptibly(); try &#123; // 如果链表长度等着capacity，代表队列已满，则等待队列为空。 while (count.get() == capacity) &#123; notFull.await(); &#125; // 将元素插入队列末尾。 enqueue(node); // c为count加1前的值，这里是原子操作，它会进行CAS，因为现在是两个线程进行操作，有可能put的时候也进行take操作，所以要保证原子性。 c = count.getAndIncrement(); // 当c+1不是最大值时，通知notFull，队列未满可继续添加元素，通知其他线程。 if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; // c代表插入前的的值，所以队列为空的时候c=0，此时已经插入了数据所以c本来应该不为0，所以需要通知队列元素插入成功。 if (c == 0) signalNotEmpty();&#125; 通过源码可以清晰得到put方法是如何进行操作的，首先获取putLock锁，获取队列的原子类型的长度，如果当前队列的长度与队列最大长度相等说明队列未满，则等待队列为空的时候插入数据，当队列未满时，可直接插入数据到队尾，c存放的事count元素加1前的值，也就是谁队列为空的时候c的长度是为0，当执行完了put方法后，实际的count为1，但是这里因为存放的是加1前的值，所有c=0，代表队列中有数据通知notEmpty可以进行take了。 enqueue方法源码很简单，就是将node节点插入到队尾，将last节点指向当前队尾。 12345private void enqueue(Node&lt;E&gt; node) &#123; // assert putLock.isHeldByCurrentThread(); // assert last.next == null; last = last.next = node;&#125; 接下来说一下take方法的源码是如何实现的，如下所示： 123456789101112131415161718192021222324252627282930313233/** * 从队头获取元素，等待队列有数据可读。 */public E take() throws InterruptedException &#123; E x; // 本地保存变量。 int c = -1; // 队列长度。 final AtomicInteger count = this.count; // 获取take重入锁。 final ReentrantLock takeLock = this.takeLock; // 获得锁，并且响应中断操作，并且只有一个线程进入take方法。 takeLock.lockInterruptibly(); try &#123; // 如果队列为空则等待队列不为空时进行获取操作。 while (count.get() == 0) &#123; notEmpty.await(); &#125; // 出队列操作。 x = dequeue(); // c保存减1前的值。 c = count.getAndDecrement(); // 如果队列还有元素则可通知其他线程进行take操作。 if (c &gt; 1) notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125; // c如果是capacity的时候代表之前队列存在过满的情况，进行take方法后则表示队列有空间可用可进行put操作，通知notFull进行put操作。 if (c == capacity) signalNotFull(); return x;&#125; 通过上面的源码可以看到，take方法获取的是takeLock重入锁，并且当前线程进入到take方法后，其他线程是不允许同时进入到take方法中，首先判断队列的长度是不是为0，如果队列为0则代表队列中无数据可消费，则进行等待，等待队列中有元素时进行take后的操作，如果队列长度不为0，则进行dequeue方法，出队列操作，将head节点指向下一个节点，将当前head值返回，当c大于1时，代表还有元素可以take，通知其他线程进行take操作，c如果是capacity的时候，代表之前队列存在过满的情况，进行这次take方法后队列有空间可用，所以可以通知notFull进行put操作。 1234567891011private E dequeue() &#123; // assert takeLock.isHeldByCurrentThread(); // assert head.item == null; Node&lt;E&gt; h = head; Node&lt;E&gt; first = h.next; h.next = h; // 帮助GC进行垃圾回收。 head = first; E x = first.item; first.item = null; return x;&#125; 总结 LinkedBlockingQueue是通过锁分离的方式进行控制，减少了take和put之间的锁竞争。 LinkedBlockingQueue是通过链表的方式实现，所以进行锁分离时不会冲突，因为入队和出队分别作用于队尾和队首。 内部采用了原子操作类（CAS）进行控制链表长度。 入队后，如果之前队列为空时，会通知take方法，队列已有数据可进行take，反之，出队后，队列之前已满，则通知put方法，队列已有空闲位置可进行put操作。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://www.battleheart.cn/tags/并发编程/"},{"name":"多线程","slug":"多线程","permalink":"https://www.battleheart.cn/tags/多线程/"}]},{"title":"ArrayBlockingQueue原理详解","slug":"arrayblockingqueue-principle","date":"2019-04-06T06:16:31.000Z","updated":"2019-04-06T06:18:42.069Z","comments":true,"path":"2019/04/06/arrayblockingqueue-principle/","link":"","permalink":"https://www.battleheart.cn/2019/04/06/arrayblockingqueue-principle/","excerpt":"","text":"ArrayBlockingQueue原理详解介绍ArrayBlockingQueue是基于数组实现的共享通道，为什么说是共享通道，假说线程A希望给线程B发一个消息，用什么方式来告知线程B是比较合适的呢？可以使用BlockingQueue来实现。 通过上图中的继承关系我们可以清晰的发现ArrayBlockingQueue是BlockingQueue接口的实现，通过名称可以得出它是基于数组实现的，所以更适合做有界的队列。 ​ 刚才也提到过它是作为数据共享来进行的线程间数据的传递，那么问题来了，当队列中为空的时候消费队列的线程如何知道队列中有新的元素添加进去，队列满的时候又如何进行处理？我们带着上面的疑问来进行下面的分析。 主要的队列的入队、出队操作如下表所示： 插入队列方法 方法名称 参数描述 返回值 异常信息 add 插入对象 ture代表插入成功，如果队列已满，抛出异常 IllegalStateException(“Queue full”)异常——AbstractQueue offer 插入对象 true代表插入成功，队列已满直接返回false 无 offer 插入对象，等待时间 true代表插入成功，队列已满等待一段时间后仍没有空间则返回false 无 put 插入对象 true代表插入成功，如果队列已满则阻塞线程等待队列为空的时候插入 获取队列内容 方法名称 参数描述 返回值 异常信息 remove 无 返回队首数据并移除，队列已空则抛出异常信息 NoSuchElementException()异常——AbstractQueue poll 无 列不为空时返回队首值并移除；队列为空时返回null。非阻塞立即返回。 poll 等待时间 设定等待的时间，如果在指定时间内队列还未孔则返回null，不为空则返回队首值 take 无 队列不为空返回队首值并移除；当队列为空时会阻塞等待，一直等到队列不为空时再返回队首值。 简单实例上面的方法中重点的内容在于put和take方法，我们以一个实例来看一下这个队列的作用。 1234567891011121314151617181920212223242526272829303132333435363738/** * ArrayBlockingQueue内容测试demo * * @author &lt;a href=\"mailto:dwlsxj@126.com\"&gt;battleheart&lt;/a&gt; */public class BlockQueueDemo &#123; public static final ArrayBlockingQueue&lt;Integer&gt; arr = new ArrayBlockingQueue&lt;&gt;(10); private static int sum = 0; public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new Thread(() -&gt; &#123; for (int i = 0; i &lt; 20; i++) &#123; try &#123; System.out.println(i + \"预备入队\"); Thread.sleep(100); arr.put(i); System.out.println(i + \"入队成功\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); thread1.start(); Thread thread = new Thread(() -&gt; &#123; try &#123; for (; ; ) &#123; System.out.println(\"进入消费队列\"); System.out.println(arr.take()); Thread.sleep(1000); &#125; &#125; catch (InterruptedException ex) &#123; ex.printStackTrace(); &#125; &#125;); thread.start(); &#125;&#125; 开启了两个线程，一个是提供数据的线程，一个是消费数据的线程 入队操作之前进行了睡眠，目的是先让消费线程进行消费队列，然后队列数据提供线程再往线程中提供数据。 出队的操作中添加了sleep方法，目的是为了能让入队的内容多一些。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081进入消费队列0预备入队0入队成功1预备入队1入队成功2预备入队02入队成功3预备入队3入队成功4预备入队4入队成功5预备入队5入队成功6预备入队6入队成功7预备入队7入队成功8预备入队8入队成功9预备入队9入队成功10预备入队10入队成功11预备入队进入消费队列111入队成功12预备入队进入消费队列212入队成功13预备入队进入消费队列313入队成功14预备入队进入消费队列414入队成功15预备入队进入消费队列515入队成功16预备入队进入消费队列616入队成功17预备入队进入消费队列717入队成功18预备入队进入消费队列818入队成功19预备入队进入消费队列919入队成功进入消费队列10进入消费队列11进入消费队列12进入消费队列13进入消费队列14进入消费队列15进入消费队列16进入消费队列17进入消费队列18进入消费队列19进入消费队列 分析上述输出内容： 进入消费队列文字输出出来说明数据提供者线程在休眠状态，而消费者线程在执行任务，在等待100ms后，0入队成功，1入队成功，当2准备入队时，这时候消费者线程获得了锁，消费了队列中的0,以此类推，最有一个进入消费队列说明队列为空等待队列不为空时，take方法进行消费。 通过输出结果可以得出以下内容： 消费线程先进入，但是并没有执行完，也就是说消费线程一直等待的状态。 入队和出队只能同步进行一项，也就是入队操作会阻止出队操作，出队操作也会阻止入队操作。 内部原理解析ArrayBlockingQueue内部定义了以下的字段信息： 1234567891011121314151617181920/** 队列元素数组 */final Object[] items;/** 下一个被take，poll，peek，remove的元素位置 */int takeIndex;/** 插入位置包含put，offer，add */int putIndex;/** 队列元素的数量 */int count;/** 重入锁 */final ReentrantLock lock;/** 队列不为空的条件 */private final Condition notEmpty;/** 队列满时的条件 */private final Condition notFull; 当执行take()操作的时候，如果队列为空，则在notEmpty出等待，同时也会进行notFull的通知，通知notFull队列已经有位置可以进行入队操作了。新元素入队时，调用put方法时，如果队列满了，则当前线程暂停在notFull上，同时会进行一次notEmpty的通知，通知notEmpty队列已经有内容可，可以进行下面的内容了。 put方法源码： 1234567891011121314151617181920212223/** * 将元素插入到队尾, 并且当队列中满的进行等待操作。 * * @throws InterruptedException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */public void put(E e) throws InterruptedException &#123; checkNotNull(e); //获得重入锁。 final ReentrantLock lock = this.lock; //这里可以相应中断操作。 lock.lockInterruptibly(); try &#123; //判断队列是否已经满了。 while (count == items.length) //如果满了就在这里等待，等待通知队列为空时，进行相应。 notFull.await(); //入队操作。 enqueue(e); &#125; finally &#123; lock.unlock(); &#125;&#125; 通过上面源代码可以得到以下内容： 获得重入锁进行入队同步操作，这也说明入队和出队只能同时进行一种操作的原因。 判断队列元素是否已经达到了队列的长度，也就是队列是否已经装满，如果装满则进行等待队列中有空余位置为止。 入队操作。 接下来详细看一下入队操作是如何进行的,enqueue源码如下所示： 12345678910111213141516171819/** * 在当前putIndex位置插入元素, 并且通知notEmpty队列已经有内容. * 只有在获得锁的情况下执行. */private void enqueue(E x) &#123; // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; // 队列数组。 final Object[] items = this.items; // 在putIndex的位置插入x。 items[putIndex] = x; // 进行循环操作，如果putIndex到了队尾则将putIndex索引指向队头。 if (++putIndex == items.length) putIndex = 0; // 队列数量加1 count++; // 通知notEmpty队列已经有内容可以进行消费。 notEmpty.signal();&#125; 接下来看一下take方法的源码： 123456789101112131415161718/** * take方法从队列中获取元素，并且如果队列为空时进行notEmpty等待。 */public E take() throws InterruptedException &#123; // 获得重入锁。 final ReentrantLock lock = this.lock; // 响应中断请求。 lock.lockInterruptibly(); try &#123; // 如果队列为空，则进行notEmpty等待。 while (count == 0) notEmpty.await(); // 出队操作。 return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125; 通过上面源码我们也可以看到如下内容： 出队前必须先获得锁，才能进行操作。 队列为空时，进行notEmpty等待。 dequeue方法源码如下所示： 1234567891011121314151617181920212223242526/** * 出takeIndex元素信息,并且通知notFull队列已经有空余位置。 * 执行必须先获得锁。 */private E dequeue() &#123; // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; // 队列元素。 final Object[] items = this.items; @SuppressWarnings(\"unchecked\") // 获取takeIndex索引信息。 E x = (E) items[takeIndex]; // 将takeIndex标记为null，方便GC进行回收。 items[takeIndex] = null; // 循环进行操作。 if (++takeIndex == items.length) takeIndex = 0; // 队列元素数量减1 count--; // 迭代器进行take if (itrs != null) itrs.elementDequeued(); // 通知notFull队列已经不再满，可进行put操作。 notFull.signal(); return x;&#125; 总结通过对源码put和take 的分析总结一下几点： ArrayBlockingQueue是采用数组进行实现队列，通过putIndex和takeIndex来控制队列的队头和队尾。 内部使用ReentrantLock进行同步操作，并配合Condition处理等待操作。 总结成下面的图片内容： \u0015\u0015 下面来用图示法讲解下ArrayBlockingQueue的工作原理 首先将元素1进行入队操作，如下图所示： \u0015 putIndex和takeIndex在同一个位置，因为他只有一个元素，当再依次入队8个元素后内容如下所示 此时putIndex就到了最后一个数组的元素的索引上，当再向数组元素中添加元素时，就会进行notFull的等待操作 当调用take方法后，队列中出现了空余位置，并且通知了notFull，嘿，伙计你可以将你的东西添加到队列中了。 可以清晰的看到putIndex变到了数组索引0的位置，就是下面的代码导致的： 12if (++putIndex == items.length) putIndex = 0; 并且此时的takeIndex便到了数组索引1的位置，持续进行take方法，队列内容全部出队列： 当take方法走到数组的末尾时，它会将takeIndex值设置为0，进行从新开始take。 12if (++takeIndex == items.length) takeIndex = 0; 并且当队列为空时，会进行notEmpty等待，等待队列中存在元素，当调用put方法后，它会通知notEmpty，兄弟你可以取队列消息了。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://www.battleheart.cn/tags/并发编程/"},{"name":"多线程","slug":"多线程","permalink":"https://www.battleheart.cn/tags/多线程/"}]},{"title":"阻塞算法和非阻塞算法","slug":"block-and-lock-free","date":"2019-03-28T08:39:45.000Z","updated":"2019-03-28T08:48:51.056Z","comments":true,"path":"2019/03/28/block-and-lock-free/","link":"","permalink":"https://www.battleheart.cn/2019/03/28/block-and-lock-free/","excerpt":"","text":"阻塞算法和非阻塞算法阻塞算法阻塞算法步骤： 执行线程请求的操作。 阻塞争抢资源的线程，直到线程资源被释放，才有机会执行线程请求操作。 ​ 上图表明了阻塞算法的流程，线程A和线程B同时争抢临界区资源，线程A优先争抢到资源，这时候线程B争抢资源时，发现临界区资源已经被其他线程占用，线程B只能等待线程A释放资源后才能获取资源，阻塞线程B执行，阻塞的线程不会执行任何内容，等待线程A执行结束，当线程A执行结束释放资源后，线程B争抢到资源执行下面的流程。 非阻塞算法非阻塞算法步骤 执行线程请求参数。 其他线程可以进入临界区，并且通知请求不能被执行，一直请求执行操作，直到执行线程操作。 ​ 线程A和线程B申请临界区资源，线程A优先申请到资源，线程A正常执行，线程B申请临界区资源时，发现线程B正在执行操作，线程B直接被驳回申请，线程B进入下一轮的申请操作，直到申请成功。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://www.battleheart.cn/tags/并发编程/"},{"name":"多线程","slug":"多线程","permalink":"https://www.battleheart.cn/tags/多线程/"}]},{"title":"你必须知道的多线程几个概念","slug":"you-have-to-know-the-concept-of-multithreading","date":"2019-03-28T06:42:14.000Z","updated":"2019-03-28T06:47:24.154Z","comments":true,"path":"2019/03/28/you-have-to-know-the-concept-of-multithreading/","link":"","permalink":"https://www.battleheart.cn/2019/03/28/you-have-to-know-the-concept-of-multithreading/","excerpt":"","text":"你必须知道多线程几个概念同步（Synchronous）、异步（Asynchronous） 同步方法调用一旦开始，就必须等待方法执行完之后，才能继续后续的行为。 异步方法更像是消息传递，一旦开始，方法调用就会返回结果，调用者就可以继续后续的行为。 并发（Concurrency）和并行 并发：指的是多个任务交替执行，而多个任务之间有可能还是串行的。 并行：并行多个任务之间是真实同时执行。 临界区临界区用来表示一种公共资源或者说是共享数据，可以被多个线程使用。但是每一次，只能有一个线程使用它，一旦临界区资源被占用，其他线程必须等待。 阻塞（Blocking）和非阻塞（Non-Blocking）阻塞和非阻塞用来形容多线程之间的相互影响。 阻塞：指的是资源占用的情况下，其他线程想要获取资源，此时必须阻塞其他线程访问。 非阻塞：强调没有一个线程可以妨碍其他线程执行。 死锁、饥饿、活锁死锁：谁都不愿意释放自己，这个状态一直维持下去，谁都别想争抢到资源。 饥饿：指某一个或者多个线程因为种种原因无法或得所需要的资源，导致一直无法执行。（比如线程优先级低，每次要执行时，都被线程优先级高的先执行，一直执行不了） 活锁：指的是线程都秉承“谦让”的原则，主动将资源释放给他人使用，那么就会出现资源不断在两个线程中跳动，而没有一个线程可以同时拿到所有资源而正常执行。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://www.battleheart.cn/tags/并发编程/"},{"name":"多线程","slug":"多线程","permalink":"https://www.battleheart.cn/tags/多线程/"}]},{"title":"SpringBoot快速整合dubbo","slug":"spring-boot-and-dubbo-starter","date":"2019-02-25T06:19:14.000Z","updated":"2019-02-25T06:56:30.462Z","comments":true,"path":"2019/02/25/spring-boot-and-dubbo-starter/","link":"","permalink":"https://www.battleheart.cn/2019/02/25/spring-boot-and-dubbo-starter/","excerpt":"","text":"Spring Boot与Dubbo进行整合添加引用12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.1.RELEASE&lt;/version&gt;&lt;/dependency&gt; 服务提供端-provider服务端代码1234567891011121314@SpringBootApplicationpublic class DubboProviderApplication &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder(DubboProviderApplication.class) .web(WebApplicationType.SERVLET) .listeners((ApplicationListener&lt;ApplicationEnvironmentPreparedEvent&gt;) event -&gt; &#123; Environment environment = event.getEnvironment(); int port = environment.getProperty(\"embedded.zookeeper.port\", int.class); new EmbeddedZooKeeper(port, false).start(); &#125;) .run(args); &#125;&#125; ApplicationEnvironmentPreparedEvent监听环境变量预处理事件 通过事件方式连接Zk 12345678910111213/** * Demo Service实现层。 * * @author battleheart */@Service(version = \"$&#123;demo.service.version&#125;\", loadbalance = \"roundrobin\")public class DemoServiceImpl implements DemoService &#123; @Override public String sayHello(String name) &#123; return \"Hello \" + name; &#125;&#125; 服务提供端通过dubbo的@Service注解进行服务的提供 服务端配置文件1234567891011121314# SpringBoot应用名称spring.application.name=dubbo-registry-zookeeper-provider-sample# 扫描的Service包地址dubbo.scan.base-packages=com.battleheart.dubboprovider# Zookeeper的端口号embedded.zookeeper.port=2181# Dubbo Protocoldubbo.protocol.name=dubbo## Dubbo注册地址dubbo.registry.address=zookeeper://127.0.0.1:$&#123;embedded.zookeeper.port&#125;## dubbo服务版本号demo.service.version=1.0.0# 服务端口server.port=8081 服务消费端-customer客户端代码12345678910@Componentpublic class Demo &#123; @Reference(version = \"1.0.0\") private DemoService demoService; public String sayHello(String name) &#123; return demoService.sayHello(name); &#125;&#125; 配置文件1234spring.application.name=annotation-consumerembedded.zookeeper.port=2181dubbo.registry.address=zookeeper://127.0.0.1:$&#123;embedded.zookeeper.port&#125;dubbo.consumer.timeout=3000 EmbeddedZooKeeperEmbeddedZooKeeper代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207public class EmbeddedZooKeeper implements SmartLifecycle &#123; /** * Logger. */ private static final Logger logger = LoggerFactory.getLogger(EmbeddedZooKeeper.class); /** * ZooKeeper client port. This will be determined dynamically upon startup. */ private final int clientPort; /** * Whether to auto-start. Default is true. */ private boolean autoStartup = true; /** * Lifecycle phase. Default is 0. */ private int phase = 0; /** * Thread for running the ZooKeeper server. */ private volatile Thread zkServerThread; /** * ZooKeeper server. */ private volatile ZooKeeperServerMain zkServer; /** * &#123;@link ErrorHandler&#125; to be invoked if an Exception is thrown from the ZooKeeper server thread. */ private ErrorHandler errorHandler; private boolean daemon = true; /** * Construct an EmbeddedZooKeeper with a random port. */ public EmbeddedZooKeeper() &#123; clientPort = SocketUtils.findAvailableTcpPort(); &#125; /** * Construct an EmbeddedZooKeeper with the provided port. * * @param clientPort port for ZooKeeper server to bind to */ public EmbeddedZooKeeper(int clientPort, boolean daemon) &#123; this.clientPort = clientPort; this.daemon = daemon; &#125; /** * Returns the port that clients should use to connect to this embedded server. * * @return dynamically determined client port */ public int getClientPort() &#123; return this.clientPort; &#125; /** * Specify whether to start automatically. Default is true. * * @param autoStartup whether to start automatically */ public void setAutoStartup(boolean autoStartup) &#123; this.autoStartup = autoStartup; &#125; /** * &#123;@inheritDoc&#125; */ @Override public boolean isAutoStartup() &#123; return this.autoStartup; &#125; /** * Specify the lifecycle phase for the embedded server. * * @param phase the lifecycle phase */ public void setPhase(int phase) &#123; this.phase = phase; &#125; /** * &#123;@inheritDoc&#125; */ @Override public int getPhase() &#123; return this.phase; &#125; /** * &#123;@inheritDoc&#125; */ @Override public boolean isRunning() &#123; return (zkServerThread != null); &#125; /** * Start the ZooKeeper server in a background thread. * &lt;p&gt; * Register an error handler via &#123;@link #setErrorHandler&#125; in order to handle * any exceptions thrown during startup or execution. */ @Override public synchronized void start() &#123; if (zkServerThread == null) &#123; zkServerThread = new Thread(new ServerRunnable(), \"ZooKeeper Server Starter\"); zkServerThread.setDaemon(daemon); zkServerThread.start(); &#125; &#125; /** * Shutdown the ZooKeeper server. */ @Override public synchronized void stop() &#123; if (zkServerThread != null) &#123; // The shutdown method is protected...thus this hack to invoke it. // This will log an exception on shutdown; see // https://issues.apache.org/jira/browse/ZOOKEEPER-1873 for details. try &#123; Method shutdown = ZooKeeperServerMain.class.getDeclaredMethod(\"shutdown\"); shutdown.setAccessible(true); shutdown.invoke(zkServer); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; // It is expected that the thread will exit after // the server is shutdown; this will block until // the shutdown is complete. try &#123; zkServerThread.join(5000); zkServerThread = null; &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); logger.warn(\"Interrupted while waiting for embedded ZooKeeper to exit\"); // abandoning zk thread zkServerThread = null; &#125; &#125; &#125; /** * Stop the server if running and invoke the callback when complete. */ @Override public void stop(Runnable callback) &#123; stop(); callback.run(); &#125; /** * Provide an &#123;@link ErrorHandler&#125; to be invoked if an Exception is thrown from the ZooKeeper server thread. If none * is provided, only error-level logging will occur. * * @param errorHandler the &#123;@link ErrorHandler&#125; to be invoked */ public void setErrorHandler(ErrorHandler errorHandler) &#123; this.errorHandler = errorHandler; &#125; /** * Runnable implementation that starts the ZooKeeper server. */ private class ServerRunnable implements Runnable &#123; @Override public void run() &#123; try &#123; Properties properties = new Properties(); File file = new File(System.getProperty(\"java.io.tmpdir\") + File.separator + UUID.randomUUID()); file.deleteOnExit(); properties.setProperty(\"dataDir\", file.getAbsolutePath()); properties.setProperty(\"clientPort\", String.valueOf(clientPort)); QuorumPeerConfig quorumPeerConfig = new QuorumPeerConfig(); quorumPeerConfig.parseProperties(properties); zkServer = new ZooKeeperServerMain(); ServerConfig configuration = new ServerConfig(); configuration.readFrom(quorumPeerConfig); zkServer.runFromConfig(configuration); &#125; catch (Exception e) &#123; if (errorHandler != null) &#123; errorHandler.handleError(e); &#125; else &#123; logger.error(\"Exception running embedded ZooKeeper\", e); &#125; &#125; &#125; &#125;&#125;","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://www.battleheart.cn/tags/Spring-Boot/"},{"name":"dubbo","slug":"dubbo","permalink":"https://www.battleheart.cn/tags/dubbo/"}]},{"title":"深入理解synchronized","slug":"how-use-synchronized","date":"2019-02-22T08:46:37.000Z","updated":"2019-02-22T08:52:43.172Z","comments":true,"path":"2019/02/22/how-use-synchronized/","link":"","permalink":"https://www.battleheart.cn/2019/02/22/how-use-synchronized/","excerpt":"","text":"深入理解synchronizedsynchronized介绍synchronized是java的关键字，用于修饰方法、代码块，能够保证同一时刻最多只有一个线程执行这段代码，通过上述描述可以清晰告诉我们synchronized的作用，也就是同步操作，同步是围绕称为内部锁或监视器锁的内部实体构建的。内部锁在同步的两个方面都发挥作用：强制对对象状态进行独占访问，并建立对可见性至关重要的先发生关系。 基本用法代码段在方法内部使用synchronized来进行代码块的同步操作。 1234567public void addName(String name) &#123; synchronized(this) &#123; lastName = name; nameCount++; &#125; nameList.add(name);&#125; 方法直接在方法上使用synchronized进行修饰即可。 123456789101112131415public class SynchronizedCounter &#123; private int c = 0; public synchronized void increment() &#123; c++; &#125; public synchronized void decrement() &#123; c--; &#125; public synchronized int value() &#123; return c; &#125;&#125; 当线程调用synchronized方法时，它会自动获取该方法对象的内部锁，并在方法返回时释放它。即使返回是由未捕获的异常引起的，也会发生锁定释放，可能想知道在调用静态同步方法时会发生什么，因为静态方法与类关联，而不是与对象关联。在这种情况下，线程获取Class与类关联的对象的内部锁。因此，对类的静态字段的访问由与该类的任何实例的锁不同的锁控制。 内部锁或监视器锁同步是围绕称为内部锁或监视器锁的内部实体构建的。内部锁在同步的两个方面都发挥作用：强制对对象状态进行独占访问，并建立对可见性至关重要的先发生关系。每个对象都有一个与之关联的内在锁，按照惯例，需要对对象字段进行独占和一致访问的线程必须在访问对象之前获取对象的内部锁，然后在完成它们时释放内部锁。据说一个线程在获得锁定和释放锁定之间拥有内在锁定。只要一个线程拥有一个内部锁，没有其他线程可以获得相同的锁。另一个线程在尝试获取锁时将阻塞。当线程释放内部锁时，在该操作与同一锁的任何后续获取之间建立先发生关系。 当使用synchronized修饰非静态方法是，内置锁就是对象本身（this） 当使用synchronized修饰静态方法是，内置锁就是该方法的所在的类对象的内置锁 通过一张图来描述一下synchronized的运行过程： 当线程1获取到拥有一个内部锁，没有其他线程可以获得相同的锁。 线程2只能等到线程1释放内部锁，线程2处于Blocked阻塞状态，被阻塞的线程将等待。 当线程1方法执行完释放内部锁之后，线程2获取内部锁，执行相应的方法。 内部锁可重入重入性指的是同一线程中，线程不需要再次获取同一把锁，内部锁是基于每个线程而不是基于每个方法的调用获取的。一旦线程获得了锁，它就可以在内部调用其他方法而无需重新获取锁。只有在使用entry方法调用完成线程时才会释放Lock。 下面结合例子进行分析锁的重入性： 123456789101112131415161718192021222324252627282930public class ReentrantDemo &#123; public static void main (String[] args) throws InterruptedException &#123; ReentrantDemo demo = new ReentrantDemo(); Thread thread1 = new Thread(() -&gt; &#123; System.out.println(\"线程1调用前 \"+ LocalDateTime.now()); demo.syncMethod1(\"执行线程1的方法\"); System.out.println(\"线程1调用后 \"+LocalDateTime.now()); &#125;); Thread thread2 = new Thread(() -&gt; &#123; System.out.println(\"线程2调用前 \"+LocalDateTime.now()); demo.syncMethod2(\"执行线程2的方法\"); System.out.println(\"线程2调用后 \"+LocalDateTime.now()); &#125;); thread1.start(); thread2.start(); &#125; private synchronized void syncMethod1 (String msg) &#123; System.out.println(\"进入同步方法1syncMethod1 \"+msg+\" \"+LocalDateTime.now()); syncMethod2(\"重入同步方法syncMethod2\"); &#125; private synchronized void syncMethod2 (String msg) &#123; System.out.println(\"进入到同步方法2syncMethod2 \"+msg+\" \"+LocalDateTime.now()); try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 运行结果： 123456线程2调用前 2019-02-22T15:33:43.963进入同步方法1syncMethod1 执行线程1的方法 2019-02-22T15:33:43.964进入到同步方法2syncMethod2 重入同步方法syncMethod2 2019-02-22T15:33:43.964线程1调用后 2019-02-22T15:33:46.969进入到同步方法2syncMethod2 执行线程2的方法 2019-02-22T15:33:46.969线程2调用后 2019-02-22T15:33:49.973 代码解析： syncMethod1和syncMethod2都用synchronized进行修饰。 syncMethod1调用了syncMethod2方法，这时候会产生重入的问题 线程1当调用syncMethod1时，获取当前对象的内部锁 线程1调用syncMethod2时，发现当前线程拥有当前对象的内部锁，直接重入syncMethod2中 每个对象拥有一个计数器，当线程获取该对象锁后，计数器就会加一，释放锁后就会将计数器减一 核心原理我们当使用synchronized修饰代码块或者方法时内部实现了什么操作？我们通过下面例子来进行揭露真面目 实例代码： 12345678910public class Test &#123; private synchronized void syncMethod() &#123; System.out.println(\"testing\"); &#125; public static void main(String[] args) &#123; Test test = new Test(); test.syncMethod(); &#125;&#125; 通过javap -v Test.class查看字节码文件: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253 public com.example.demo.Test(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 3: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcom/example/demo/Test; public synchronized void syncMethod(); descriptor: ()V flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=2, locals=1, args_size=1 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #3 // String testing 5: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return LineNumberTable: line 6: 0 line 7: 8 LocalVariableTable: Start Length Slot Name Signature 0 9 0 this Lcom/example/demo/Test; public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=2, args_size=1 0: new #5 // class com/example/demo/Test 3: dup 4: invokespecial #6 // Method &quot;&lt;init&gt;&quot;:()V 7: astore_1 8: aload_1 9: invokevirtual #7 // Method syncMethod:()V 12: return LineNumberTable: line 10: 0 line 11: 8 line 12: 12 LocalVariableTable: Start Length Slot Name Signature 0 13 0 args [Ljava/lang/String; 8 5 1 test Lcom/example/demo/Test; MethodParameters: Name Flags args&#125; syncMethod的synchronized修饰在方法上 syncMethod的flag中存在ACC_SYNCHRONIZED进行修饰，标识是否为synchronized 实例二： 通过synchronized方法修饰代码块 12345678910111213141516/** * @author battleheart */public class Test &#123; public static void syncMethod() &#123; System.out.println(\"testing\"); &#125; public static void main(String[] args) throws Exception &#123; synchronized (Test.class) &#123; syncMethod(); &#125; &#125;&#125; 通过javap -v Test.class查看字节码文件: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&#123; public com.example.demo.Test(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 3: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcom/example/demo/Test; public static void syncMethod(); descriptor: ()V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=0, args_size=0 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #3 // String testing 5: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return LineNumberTable: line 6: 0 line 7: 8 public static void main(java.lang.String[]) throws java.lang.Exception; descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=3, args_size=1 0: ldc #5 // class com/example/demo/Test 2: dup 3: astore_1 4: monitorenter 5: invokestatic #6 // Method syncMethod:()V 8: aload_1 9: monitorexit 10: goto 18 13: astore_2 14: aload_1 15: monitorexit 16: aload_2 17: athrow 18: return Exception table: from to target type 5 10 13 any 13 16 13 any LineNumberTable: line 11: 0 line 12: 5 line 13: 8 line 14: 18 LocalVariableTable: Start Length Slot Name Signature 0 19 0 args [Ljava/lang/String; StackMapTable: number_of_entries = 2 frame_type = 255 /* full_frame */ offset_delta = 13 locals = [ class &quot;[Ljava/lang/String;&quot;, class java/lang/Object ] stack = [ class java/lang/Throwable ] frame_type = 250 /* chop */ offset_delta = 4 Exceptions: throws java.lang.Exception MethodParameters: Name Flags args&#125; 执行同步代码块首先执行monitorenter指令，退出时候执行monitorexit指令 同步时必须要获取对象的监视器monitor，获取monitor后才能执行下面逻辑，否则只能等待。 经过monitorenter指令和monitorexit指令修饰的部分代码是互斥的，仅有一个线程持有内部锁。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.battleheart.cn/tags/Java/"}]},{"title":"SpringBoot自动装配详解","slug":"spring-boot-autoconfiguration-fashion","date":"2019-01-24T06:25:08.000Z","updated":"2019-02-22T06:02:30.793Z","comments":true,"path":"2019/01/24/spring-boot-autoconfiguration-fashion/","link":"","permalink":"https://www.battleheart.cn/2019/01/24/spring-boot-autoconfiguration-fashion/","excerpt":"","text":"Spring Boot自动装配开篇 @Import注解如果我们在项目中不同的模块提供多个spring bean配置，则@Import注释将非常有用。在这种情况下，最好将所有这些配置导入到单个配置类中，以便通过引用多个配置类来创建bean时不会产生任何混淆。Spring中的@Import注释允许从另一个配置类加载bean定义，将多个配置类导入单个应用程序配置非常容易，这里不过多篇幅讲解@Import。 @Enable注解驱动，对配置进行自动配置。 通过ConfigurationClassParser类对标记为@Configuration注解的类进行解析。 然后通过解析@Import注解进行自动导入配置，@Import支持以下三种方式解析。 直接解析配置类@Configuraion ImportSelector接口（Spring 4.0后增加了DeferredImportSelector继承自ImportSelector，两者的区别是ImportSelector在DeferredImportSelector先执行解析） ImportBeanDefinitionRegistrar动态注册Bean的方式 @Conditional条件注解，以及常见的Spring Boot常见条件注解 源码分析 引用例子抛出问题@SpringBootApplication中包括@EnableAutoConfiguration注解，@Enable驱动，此时我们可能会想以下几个问题： @Enbale的主要作用是什么？ 配置类是如何导入的？ 配置类又是如何被解析的？ 配置类导入方式是以什么方式进行导入的？ 接下来我们带着问题看以下内容 @Enable 模块驱动通过观察这些@Enable*的源码，我们发现所有注解都有一个@Import注解，@Import是用来导入配置类的，这就意味着这些自动开启的实现其实是导入一些自动配置的Bean。 直接导入配置类1234567@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Import(SchedulingConfiguration.class)@Documentedpublic @interface EnableScheduling &#123;&#125; 直接导入配置类SchedulingConfiguration，这个类注解了@Configuration注解，且注册了一个scheduledAnnotationProcessor的Bean，源码如下： 123456789@Configuration@Role(BeanDefinition.ROLE_INFRASTRUCTURE)public class SchedulingConfiguration &#123; @Bean(name = TaskManagementConfigUtils.SCHEDULED_ANNOTATION_PROCESSOR_BEAN_NAME) @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public ScheduledAnnotationBeanPostProcessor scheduledAnnotationProcessor() &#123; return new ScheduledAnnotationBeanPostProcessor(); &#125;&#125; ImportSelector接口，实现该接口。 根据条件选择配置类，通过选择的方式进行选择配置类。 12345678910@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(AsyncConfigurationSelector.class)public @interface EnableAsync &#123; Class&lt;? extends Annotation&gt; annotation() default Annotation.class; boolean proxyTargetClass() default false; AdviceMode mode() default AdviceMode.PROXY; int order() default Ordered.LOWEST_PRECEDENCE;&#125; AsyncConfigurationSelector通过条件来选择需要导入的配置类，AsyncConfigurationSelector实现了ImportSelector，这个接口需要重写selectImports方法，在此方法内进行事先条件判断。此例中，若adviceMode为PROXY，则返回ProxyAsyncConfiguration这个配置类；若为ASPECTJ则返回AspectJAsyncConfiguration配置类。 1234567891011121314151617public class AsyncConfigurationSelector extends AdviceModeImportSelector&lt;EnableAsync&gt; &#123; private static final String ASYNC_EXECUTION_ASPECT_CONFIGURATION_CLASS_NAME = \"org.springframework.scheduling.aspectj.AspectJAsyncConfiguration\"; @Override @Nullable public String[] selectImports(AdviceMode adviceMode) &#123; switch (adviceMode) &#123; case PROXY: return new String[] &#123;ProxyAsyncConfiguration.class.getName()&#125;; case ASPECTJ: return new String[] &#123;ASYNC_EXECUTION_ASPECT_CONFIGURATION_CLASS_NAME&#125;; default: return null; &#125; &#125;&#125; ImportBeanDefinitionRegistrar接口,动态注册Bean12345678@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(AspectJAutoProxyRegistrar.class)public @interface EnableAspectJAutoProxy &#123; boolean proxyTargetClass() default false; boolean exposeProxy() default false;&#125; AspectJAutoProxyRegistrar实现了ImportBeanDefinitionRegistrar接口，ImportBeanDefinitionRegistrar接口的作用是在运行时自动添加Bean到已有的配置类，通过重写方法： 12public void registerBeanDefinitions( AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) 其中，AnnotationMetadata参数用来获取当前配置类上的注解，BeanDefinitionRegister参数用来注册Bean。 12345678910111213141516171819class AspectJAutoProxyRegistrar implements ImportBeanDefinitionRegistrar &#123; @Override public void registerBeanDefinitions( AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry); AnnotationAttributes enableAspectJAutoProxy = AnnotationConfigUtils.attributesFor(importingClassMetadata, EnableAspectJAutoProxy.class); if (enableAspectJAutoProxy != null) &#123; if (enableAspectJAutoProxy.getBoolean(\"proxyTargetClass\")) &#123; AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); &#125; if (enableAspectJAutoProxy.getBoolean(\"exposeProxy\")) &#123; AopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry); &#125; &#125; &#125;&#125; 总结：通过上述内容的描述可以清晰的看到@Enable注解回答了以下两个问题 @Enable主要作用是导入配置 @Enable导入配置的方式 直接导入配置类，通过@Configuraion注解加持的配置类 继承ImportSelector接口 继承ImportBeanDefinitionRegistrar接口 配置类是通过上述三种方式进行导入 直接导入配置类的方式很容易理解 ImportSelector接口方式程序又是如何进行解析的呢？请看下文内容。 ImportBeanDefinitionRegistrar接口又是如何进行解析？ Spring Boot条件注解讲解 常用相关条件注解 1234567891011@ConditionalOnBean // 配置了某个特定Bean@ConditionalOnMissingBean // 没有配置特定Bean@ConditionalOnClass // classpath有指定类@ConditionalOnMissingClass // classpath没有指定类@ConditionalOnExpression // 给定的Spring Expression Language（SpEL）表达式计算结果为true@ConditionalOnJava // Java的版本匹配特定值或某一个范围值@ConditionalOnJndi // 参数中给定的JNDI位置必须存在一个，如果没有给参数，则要有JNDI InitialContext@ConditionalOnProperty // 指定的配置属性要有一个明确的值@ConditionalOnResource // Classpath里有指定资源@ConditionalOnWebApplication // 这是个Web应用程序@ConditionalOnNotWebApplication // 这不是个Web应用程序 条件注解@Conditional @Conditional是Spring4新提供的注解，它的作用是按照一定的条件进行判断，满足条件给容器注册bean。通过一个源码我可以清晰的看到上面Spring Boot的源码都是采用条件注解。 123456789101112@Target(&#123; ElementType.TYPE, ElementType.METHOD &#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Conditional(OnBeanCondition.class)public @interface ConditionalOnBean &#123; Class&lt;?&gt;[] value() default &#123;&#125;; String[] type() default &#123;&#125;; Class&lt;? extends Annotation&gt;[] annotation() default &#123;&#125;; String[] name() default &#123;&#125;; SearchStrategy search() default SearchStrategy.ALL; Class&lt;?&gt;[] parameterizedContainer() default &#123;&#125;;&#125; @Conditional中有一个OnBeanCondition的条件类，条件类最终继承关系如下图所示：可以清晰的看到他最后继承自Condition接口 1234@FunctionalInterfacepublic interface Condition &#123; boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata);&#125; 接口中包含一个matches方法，有两个参数一个是ConditionContext包含了获取环境变量信息，Bean信息，类加载器的贵相关信息，AnnotatedTypeMetadata获取注解的信息。通过该方法返回true和false来表明是否加载当前Bean信息。 Spring Boot添加了很多注解，主要分类以下六大类内容： Class条件 Bean条件 Property条件 Resource条件 Web应用程序条件 SpEL表达式条件 自动化配置 resource下添加META-INF文件，文件下添加spring.factories文件，如下图所示： 以Mybatis自动配置为主进行讲解，里面内容如下所示： 123# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration 我们可以看到里面是通过EnableAutoConfiguration这个注解来进行\b自动装配，也就是说添加了当前注解的类它会扫面spring.factorie文件下所有关于EnableAutoConfiguration指定类的全名称，然后进行自动化配置。 EnableAutoConfiguration注解12345678910111213@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = \"spring.boot.enableautoconfiguration\"; //排除Class类对象。 Class&lt;?&gt;[] exclude() default &#123;&#125;; //排除类名称。 String[] excludeName() default &#123;&#125;; &#125; \bEnableAutoConfiguration中添加了@Import注解，注解中包含AutoConfigurationImportSelector类，这个类继承自DeferredImportSelector接口,而它又继承自Import\bSelector接口，这就说明他是通过\bImportSelector的方式来完成自动化配置。 ConfigurationClassParser类解析@Configuration\b标记的类 主要作用：首先为什么要先说ConfigurationClassParser类，\b因为Spring的工具类ConfigurationClassParser用于分析@Configuration注解的配置类，产生一组ConfigurationClass对象。 分析过程： ConfigurationClassParser类的调用是由ConfigurationClassPostProcessor，而ConfigurationClassPostProcessor是继承自BeanDefinitionRegistryPostProcessor接口，它又继承自BeanFactoryPostProcessor接口，它会在容器启动过程中，应用上下文执行各个BeanFactoryPostProcessor时被执行。 BeanFactoryPostProcessor调用过程：Spring Boot 应用中在ApplicationContext对象创建时，会调用 AnnotationConfigUtils.registerAnnotationConfigProcessors() 注册这个BeanFactoryPostProcessor。执行时会调用postProcessBeanDefinitionRegistry方法，该方法中调用了该类中的processConfigBeanDefinitions方法来调用ConfigurationClassPostProcessor类的parse方法来进行解析@Configuration注解加载的类信息,以及调用BeanFactoryPostProcessor的postProcessBeanFactory()方法。 分析过程会接受一组配置类(调用者已知其是配置类，通常就一个)，从它开始分析所有关联的配置类 分析过程主要是递归分析配置类的注解@Import，配置类内部嵌套类，找出其中所有的配置类，然后返回这组配置类 ConfigurationClassPostProcessor继承关系： ConfigurationClassPostProcessor类的postProcessBeanDefinitionRegistry方法： 123456789101112131415@Overridepublic void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) &#123; int registryId = System.identityHashCode(registry); if (this.registriesPostProcessed.contains(registryId)) &#123; throw new IllegalStateException( \"postProcessBeanDefinitionRegistry already called on this post-processor against \" + registry); &#125; if (this.factoriesPostProcessed.contains(registryId)) &#123; throw new IllegalStateException( \"postProcessBeanFactory already called on this post-processor against \" + registry); &#125; this.registriesPostProcessed.add(registryId); //处理Config配置Bean。 processConfigBeanDefinitions(registry);&#125; processConfigBeanDefinitions方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117public void processConfigBeanDefinitions(BeanDefinitionRegistry registry) &#123; //标记为@Configuration候选类 List&lt;BeanDefinitionHolder&gt; configCandidates = new ArrayList&lt;&gt;(); //从容器中获取已经标记为Bean的候选配置类名称。 String[] candidateNames = registry.getBeanDefinitionNames(); for (String beanName : candidateNames) &#123; BeanDefinition beanDef = registry.getBeanDefinition(beanName); if (ConfigurationClassUtils.isFullConfigurationClass(beanDef) || ConfigurationClassUtils.isLiteConfigurationClass(beanDef)) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Bean definition has already been processed as a configuration class: \" + beanDef); &#125; &#125; else if (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, this.metadataReaderFactory)) &#123; //如果当前类标记为@Configuration注解添加到候选类集合中。 configCandidates.add(new BeanDefinitionHolder(beanDef, beanName)); &#125; &#125; // 没有@Configuration注解的类直接返回。 if (configCandidates.isEmpty()) &#123; return; &#125; // 根据@Order的value来进行排序。 configCandidates.sort((bd1, bd2) -&gt; &#123; int i1 = ConfigurationClassUtils.getOrder(bd1.getBeanDefinition()); int i2 = ConfigurationClassUtils.getOrder(bd2.getBeanDefinition()); return Integer.compare(i1, i2); &#125;); //获取生成策略包括@ComponentScan和@Import的范围。 SingletonBeanRegistry sbr = null; if (registry instanceof SingletonBeanRegistry) &#123; sbr = (SingletonBeanRegistry) registry; if (!this.localBeanNameGeneratorSet) &#123; BeanNameGenerator generator = (BeanNameGenerator) sbr.getSingleton(CONFIGURATION_BEAN_NAME_GENERATOR); if (generator != null) &#123; this.componentScanBeanNameGenerator = generator; this.importBeanNameGenerator = generator; &#125; &#125; &#125; if (this.environment == null) &#123; this.environment = new StandardEnvironment(); &#125; //解析每一个标记@Configuration注解的类。 //首先构造ConfigurationClassParser类。 ConfigurationClassParser parser = new ConfigurationClassParser( this.metadataReaderFactory, this.problemReporter, this.environment, this.resourceLoader, this.componentScanBeanNameGenerator, registry); // 因为不清楚候选是否确实是配置类，所以使用BeanDefinitionHolder类型记录 // 这里初始化为方法开始时容器中注解了@Configuration的Bean定义的集合 Set&lt;BeanDefinitionHolder&gt; candidates = new LinkedHashSet&lt;&gt;(configCandidates); // 这里记录已经解析的类。 Set&lt;ConfigurationClass&gt; alreadyParsed = new HashSet&lt;&gt;(configCandidates.size()); do &#123; //解析配置文件，如果是标记为@Component注解的直接解析成bean，如果标记为@Import注解的将解析三种类型的类文件进行循环解析，解析成ConfigurationClass类添加到ConfigurationClassParser属性configurationClasses中。 parser.parse(candidates); //验证 parser.validate(); // 获取ConfigurationClassParser中的ConfigurationClass对象集合。 Set&lt;ConfigurationClass&gt; configClasses = new LinkedHashSet&lt;&gt;(parser.getConfigurationClasses()); // 去除已经解析的Bean对象。 configClasses.removeAll(alreadyParsed); // 读取模型并根据其上下文创建bean定义 if (this.reader == null) &#123; this.reader = new ConfigurationClassBeanDefinitionReader( registry, this.sourceExtractor, this.resourceLoader, this.environment, this.importBeanNameGenerator, parser.getImportRegistry()); &#125; // 使用 ConfigurationClassBeanDefinitionReader reader 从 configClasses 中加载Bean定义并加载到容器中。 this.reader.loadBeanDefinitions(configClasses); //处理完的添加到已处理类中。 alreadyParsed.addAll(configClasses); // 清空候选配置类集合，为下一轮do循环做初始化准备 candidates.clear(); if (registry.getBeanDefinitionCount() &gt; candidateNames.length) &#123; // 经过一轮do循环,现在容器中Bean定义数量超过了该次循环开始时的容器内Bean定义数量， // 说明在该次循环中发现并注册了更多的Bean定义到容器中去，这些新注册的Bean定义 // 也有可能是候选配置类，它们也要被处理用来发现和注册Bean定义 String[] newCandidateNames = registry.getBeanDefinitionNames(); Set&lt;String&gt; oldCandidateNames = new HashSet&lt;&gt;(Arrays.asList(candidateNames)); Set&lt;String&gt; alreadyParsedClasses = new HashSet&lt;&gt;(); for (ConfigurationClass configurationClass : alreadyParsed) &#123; alreadyParsedClasses.add(configurationClass.getMetadata().getClassName()); &#125; for (String candidateName : newCandidateNames) &#123; if (!oldCandidateNames.contains(candidateName)) &#123; BeanDefinition bd = registry.getBeanDefinition(candidateName); if (ConfigurationClassUtils.checkConfigurationClassCandidate(bd, this.metadataReaderFactory) &amp;&amp;!alreadyParsedClasses.contains(bd.getBeanClassName())) &#123; candidates.add(new BeanDefinitionHolder(bd, candidateName)); &#125; &#125; &#125; candidateNames = newCandidateNames; &#125; &#125; while (!candidates.isEmpty()); //循环到没有配置类为止。 // Register the ImportRegistry as a bean in order to support ImportAware @Configuration classes if (sbr != null &amp;&amp; !sbr.containsSingleton(IMPORT_REGISTRY_BEAN_NAME)) &#123; sbr.registerSingleton(IMPORT_REGISTRY_BEAN_NAME, parser.getImportRegistry()); &#125; if (this.metadataReaderFactory instanceof CachingMetadataReaderFactory) &#123; // Clear cache in externally provided MetadataReaderFactory; this is a no-op // for a shared cache since it'll be cleared by the ApplicationContext. ((CachingMetadataReaderFactory) this.metadataReaderFactory).clearCache(); &#125;&#125; ConfigurationClassParser的parse方法： 1234567891011121314151617181920212223242526272829303132public void parse(Set&lt;BeanDefinitionHolder&gt; configCandidates) &#123; for (BeanDefinitionHolder holder : configCandidates) &#123; BeanDefinition bd = holder.getBeanDefinition(); try &#123; //根据不同的类型来进行解析。 if (bd instanceof AnnotatedBeanDefinition) &#123; //bd是AnnotateBeanDefinition parse(((AnnotatedBeanDefinition) bd).getMetadata(), holder.getBeanName()); &#125; else if (bd instanceof AbstractBeanDefinition &amp;&amp; ((AbstractBeanDefinition) bd).hasBeanClass()) &#123; //bd是AbstractBeanDefinition,并且指定 beanClass 属性 parse(((AbstractBeanDefinition) bd).getBeanClass(), holder.getBeanName()); &#125; else &#123; // 其他情况 parse(bd.getBeanClassName(), holder.getBeanName()); &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException( \"Failed to parse configuration class [\" + bd.getBeanClassName() + \"]\", ex); &#125; &#125; // 最后处理DeferredImportSelector\b接口内容。 // DeferredImportSelector继承自ImportSelector接口。 // ImportSelector 被设计成其实和@Import注解的类同样的导入效果，但是实现 ImportSelector的类可以条件性地决定导入哪些配置。 // DeferredImportSelector的设计目的是在所有其他的配置类被处理后才处理。这也正是该语句被放到本函数最后一行的原因。 this.deferredImportSelectorHandler.process();&#125; 这里我们看一下第一种情况，其实不管是三个中的任何情况，最后都会调用processConfigurationClass方法来进行处理。 123protected final void parse(AnnotationMetadata metadata, String beanName) throws IOException &#123; processConfigurationClass(new ConfigurationClass(metadata, beanName));&#125; processConfigurationClass方法，主要是对解析的ConfigurationClass进行处理，如果已经处理过则合并importBy属性，反之，循环解析配置类\b并且向上沿着类的接口逐层执行doProcessConfigurationClass方法，直到java提供的类结束循环。 123456789101112131415161718192021222324252627282930313233protected void processConfigurationClass(ConfigurationClass configClass) throws IOException &#123; if (this.conditionEvaluator.shouldSkip(configClass.getMetadata(), ConfigurationPhase.PARSE_CONFIGURATION)) &#123; return; &#125; // 首先获取当前ConfigurationClass，检测是否已经被解析了。 ConfigurationClass existingClass = this.configurationClasses.get(configClass); if (existingClass != null) &#123; if (configClass.isImported()) &#123; if (existingClass.isImported()) &#123; //如果已经解析\b了，合并二者的importedBy属性 existingClass.mergeImportedBy(configClass); &#125; // Otherwise ignore new imported config class; existing non-imported class overrides it. return; &#125; else &#123; // Explicit bean definition found, probably replacing an import. // Let's remove the old one and go with the new one. this.configurationClasses.remove(configClass); this.knownSuperclasses.values().removeIf(configClass::equals); &#125; &#125; // 从当前配置类configClass开始向上沿着类继承结构逐层执行doProcessConfigurationClass, // 直到遇到的父类是由Java提供的类结束循环 // 将类封装成SourceClass类 SourceClass sourceClass = asSourceClass(configClass); do &#123; sourceClass = doProcessConfigurationClass(configClass, sourceClass); &#125; while (sourceClass != null); // 设置configurationClasses属性添加当前\bconfiguClass对象，用于上一步中的获取当前属性来注册到上下文中。 this.configurationClasses.put(configClass, configClass);&#125; doProcessConfigurationClass方法内部实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172protected final SourceClass doProcessConfigurationClass(ConfigurationClass configClass, SourceClass sourceClass) throws IOException &#123; //如果是@Component注解优先处理内部类/内部成员。 if (configClass.getMetadata().isAnnotated(Component.class.getName())) &#123; // Recursively process any member (nested) classes first processMemberClasses(configClass, sourceClass); &#125; //处理@PropertySource注解 for (AnnotationAttributes propertySource : AnnotationConfigUtils.attributesForRepeatable(sourceClass.getMetadata(), PropertySources.class, org.springframework.context.annotation.PropertySource.class)) &#123; if (this.environment instanceof ConfigurableEnvironment) &#123; processPropertySource(propertySource); &#125; else &#123; logger.info(\"Ignoring @PropertySource annotation on [\" + sourceClass.getMetadata().getClassName() + \"]. Reason: Environment must implement ConfigurableEnvironment\"); &#125; &#125; // 处理@ComponentScan注解 Set&lt;AnnotationAttributes&gt; componentScans = AnnotationConfigUtils.attributesForRepeatable(sourceClass.getMetadata(), ComponentScans.class, ComponentScan.class); if (!componentScans.isEmpty() &amp;&amp;!this.conditionEvaluator.shouldSkip(sourceClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN)) &#123; for (AnnotationAttributes componentScan : componentScans) &#123; // The config class is annotated with @ComponentScan -&gt; perform the scan immediately Set&lt;BeanDefinitionHolder&gt; scannedBeanDefinitions = this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName()); // Check the set of scanned definitions for any further config classes and parse recursively if needed for (BeanDefinitionHolder holder : scannedBeanDefinitions) &#123; BeanDefinition bdCand = holder.getBeanDefinition().getOriginatingBeanDefinition(); if (bdCand == null) &#123; bdCand = holder.getBeanDefinition(); &#125; if (ConfigurationClassUtils.checkConfigurationClassCandidate(bdCand, this.metadataReaderFactory)) &#123; parse(bdCand.getBeanClassName(), holder.getBeanName()); &#125; &#125; &#125; &#125; //处理@Import注解，这里才是真正的主题。 processImports(configClass, sourceClass, getImports(sourceClass), true); //处理@ImportResource注解 AnnotationAttributes importResource = AnnotationConfigUtils.attributesFor(sourceClass.getMetadata(), ImportResource.class); if (importResource != null) &#123; String[] resources = importResource.getStringArray(\"locations\"); Class&lt;? extends BeanDefinitionReader&gt; readerClass = importResource.getClass(\"reader\"); for (String resource : resources) &#123; String resolvedResource = this.environment.resolveRequiredPlaceholders(resource); configClass.addImportedResource(resolvedResource, readerClass); &#125; &#125; //处理Bean@Bean的方法。 Set&lt;MethodMetadata&gt; beanMethods = retrieveBeanMethodMetadata(sourceClass); for (MethodMetadata methodMetadata : beanMethods) &#123; configClass.addBeanMethod(new BeanMethod(methodMetadata, configClass)); &#125; // Process default methods on interfaces processInterfaces(configClass, sourceClass); //如果有父类处理父类。 if (sourceClass.getMetadata().hasSuperClass()) &#123; String superclass = sourceClass.getMetadata().getSuperClassName(); if (superclass != null &amp;&amp; !superclass.startsWith(\"java\") &amp;&amp; !this.knownSuperclasses.containsKey(superclass)) &#123; this.knownSuperclasses.put(superclass, configClass); // Superclass found, return its annotation metadata and recurse return sourceClass.getSuperClass(); &#125; &#125; //如果没有父类则代表处理完成。 return null;&#125; 来看一下processImports方法，看一下是如何处理@Import注解的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566private void processImports(ConfigurationClass configClass, SourceClass currentSourceClass,Collection&lt;SourceClass&gt; importCandidates, boolean checkForCircularImports) &#123; // 需要处理的SourceClass是否为空，如果为空直接返回。 if (importCandidates.isEmpty()) &#123; return; &#125; //检测循环引用问题。 if (checkForCircularImports &amp;&amp; isChainedImportOnStack(configClass)) &#123; this.problemReporter.error(new CircularImportProblem(configClass, this.importStack)); &#125; else &#123; this.importStack.push(configClass); try &#123; for (SourceClass candidate : importCandidates) &#123; //1.检测是否继承自ImportSelector接口。 if (candidate.isAssignable(ImportSelector.class)) &#123; // Candidate class is an ImportSelector -&gt; delegate to it to determine imports Class&lt;?&gt; candidateClass = candidate.loadClass(); //创建ImportSelectord对象。 ImportSelector selector = BeanUtils.instantiateClass(candidateClass, ImportSelector.class); ParserStrategyUtils.invokeAwareMethods(selector, this.environment, this.resourceLoader, this.registry); //这里判断selector是否是DeferredImportSelector实现。 if (selector instanceof DeferredImportSelector) &#123; //将调用ConfigurationClassParser内部类DeferredImportSelectorHandler的handle方法，将该类添加到DeferredImportSelectorHandler的属性 //deferredImportSelectors等到后面的最后ConfigurationClassParser类的parse方法的最后执行的方法this.deferredImportSelectorHandler.process()。 this.deferredImportSelectorHandler.handle(configClass, (DeferredImportSelector) selector); &#125; else &#123; //这里是直接继承ImportSelector接口,并且执行selector的selectImports方法,获取需要解析的类， String[] importClassNames = selector.selectImports(currentSourceClass.getMetadata()); Collection&lt;SourceClass&gt; importSourceClasses = asSourceClasses(importClassNames); // 这里会循环解决配置中内容。 processImports(configClass, currentSourceClass, importSourceClasses, false); &#125; &#125; // 这里是动态注册Bean。 else if (candidate.isAssignable(ImportBeanDefinitionRegistrar.class)) &#123; // Candidate class is an ImportBeanDefinitionRegistrar -&gt; // delegate to it to register additional bean definitions Class&lt;?&gt; candidateClass = candidate.loadClass(); ImportBeanDefinitionRegistrar registrar = BeanUtils.instantiateClass(candidateClass, ImportBeanDefinitionRegistrar.class); ParserStrategyUtils.invokeAwareMethods( registrar, this.environment, this.resourceLoader, this.registry); configClass.addImportBeanDefinitionRegistrar(registrar, currentSourceClass.getMetadata()); &#125; else &#123; //直接处理@Configuration注解的类。 this.importStack.registerImport(currentSourceClass.getMetadata(), candidate.getMetadata().getClassName()); // 从新开始又来处理ConfigurationClass，详细可以看上面的介绍该方法的地方。 processConfigurationClass(candidate.asConfigClass(configClass)); &#125; &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException( \"Failed to process import candidates for configuration class [\" + configClass.getMetadata().getClassName() + \"]\", ex); &#125; finally &#123; this.importStack.pop(); &#125; &#125;&#125; 整个Spring Boot的运行调用过程如下所示： 1234567891011--SpringApplication.run()----refreshContext(context);------SpringApplication.refresh(context);--------ServletWebServerApplicationContext.refresh();----------AbstractApplicationContext.refresh()------------invokeBeanFactoryPostProcessors(beanFactory); //这里就会继承自BeanFactoryPostProcessor接口的方法。--------------PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors());//第二个参数传递的就是BeanFactoryPostProcessor的list集合。----------------invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);//处理BeanDefinitionRegistryPostProcessors,继承自BeanFactoryPostProcessor接口------------------postProcessor.postProcessBeanDefinitionRegistry(registry);//这里会调用ConfigurationClassPostProcessor的postProcessBeanDefinitionRegistry方法来进行处理Bean内容。--------------------ConfigurationClassPostProcessor.processConfigBeanDefinitions(registry);//解析待处理的Bean。----------------------ConfigurationClassParser.parse(candidates);//这里就是正式的将待处理的holder解析成ConfigurationClass。 到上面最后一步其实就是已经到了我们上面源码分析的内容位置。 整体流程图大致如下图所示： 参考内容JavaEE开发的颠覆者: Spring Boot实战书籍,其中@Enable*驱动的三种方式摘抄本书","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://www.battleheart.cn/tags/Spring-Boot/"}]},{"title":"spring-boot与thymeleaf模板整合shiro标签内容","slug":"spring-boot-thymeleaf-and-shiro","date":"2019-01-24T02:49:45.000Z","updated":"2019-01-25T08:42:50.531Z","comments":true,"path":"2019/01/24/spring-boot-thymeleaf-and-shiro/","link":"","permalink":"https://www.battleheart.cn/2019/01/24/spring-boot-thymeleaf-and-shiro/","excerpt":"","text":"添加依赖项12345&lt;dependency&gt; &lt;groupId&gt;com.github.theborakompanioni&lt;/groupId&gt; &lt;artifactId&gt;thymeleaf-extras-shiro&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt; 添加Bean对象123456789/** * shiro 标签的Bean。 * * @return */@Beanpublic ShiroDialect shiroDialect() &#123; return new ShiroDialect();&#125; 页面添加对标签的引用\b，添加方式如下：1&lt;html lang=&quot;zh_CN&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot; xmlns:shiro=&quot;http://www.pollix.at/thymeleaf/shiro&quot;&gt; 上述配置成功后即可使用shiro相关的标签 直接对代码块进行控制 12345&lt;shiro:hasPermission name=&quot;P0101&quot;&gt; &lt;li&gt; &lt;a data-href=&quot;/ticket/spot/view/list&quot; data-title=&quot;景点&quot; href=&quot;javascript:void(0)&quot;&gt;景点&lt;/a&gt; &lt;/li&gt;&lt;/shiro:hasPermission&gt; 通过html属性方式进行控制 1&lt;a data-href=&quot;/ticket/spot/view/list&quot; data-title=&quot;景点&quot; href=&quot;javascript:void(0)&quot; shiro:hasPermission name=&quot;P0101&quot;&gt;景点&lt;/a&gt;","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://www.battleheart.cn/tags/Spring-Boot/"},{"name":"Shiro","slug":"Shiro","permalink":"https://www.battleheart.cn/tags/Shiro/"}],"author":"BattleHeart"},{"title":"使用Hexo搭建博客","slug":"use-hexo-to-build-a-blog","date":"2018-10-26T07:41:38.000Z","updated":"2018-10-26T07:43:36.024Z","comments":true,"path":"2018/10/26/use-hexo-to-build-a-blog/","link":"","permalink":"https://www.battleheart.cn/2018/10/26/use-hexo-to-build-a-blog/","excerpt":"","text":"环境搭建需要安装的内容如下： git \b仓库（Git官网）下载并安装 node.js（Node官网）下载并安装 hexo安装 输入以下命令安装hexo: 1npm install -g hexo 安装成功后，新建一个喜欢的文件夹，进入文件夹中执行如下命令： 12hexo initnpm install（用于安装依赖包） 执行完成后，输入以下命令，然后通过访问:http://localhost:4000，来访问，一个本地博客就搭建完了。 12hexo ghexo s 常用命令如下 hexo g #完整命令为hexo generate,生成静态文件hexo s #完整命令为hexo server,启动服务器,本地可以测试hexo d #完整命令为hexo deploy,将本地编译好的静态文件发布到github上hexo n #完整命令为hexo new,新建一篇文章hexo clean #清除当前项目的静态文件 主题切换博主可根据自己的需求去hexo主题中找寻自己喜欢的主题，并且将主题的仓库内容复制到themes目录下。例如： 1git clone xxx.git themes/xxx 我们到themes目录下查看后可清楚看到我们download下的xxx文件夹内的主题信息，修改根目录的_config.yml（注意不是主题下的config.yml，而是hexo根目录下的配置文件） 1234# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: yilia SSH配置 github仓库中新建一个git仓库，仓库的名字叫做github账户名.github.io(必须这样起名字)，例如我的账户名为dwlsxj，则仓库的名称是dwlsxj.github.io 接下来\b配置SSH，自己的邮箱地址， 在git bash 中执行命令，连续回车三次不需要输入任何内容。 1ssh-keygen -t rsa -C &quot;xxxx@126.com&quot; 从图中我们可以清晰的看到生成到了C盘Users/BattleHeart/.ssh/下，打开id_rsa.pub文件，copy文件中的内容。3. 将复制的key设置到github中，\b用户-&gt;setting-SSH and GPG keys 打开hexo目录下的_config.yml,找到deploy，添加git地址，保存后使用deploy d进行上传私服。 12345deploy: type: git #repository: https://github.com:xxxx/xxxx.github.io.git repo: github: git@github.com:xxx/xxxx.github.io.git,master 个人域名绑定 在\bsource文件下新建一个CNAME文件（）没有后缀 将个人域名www.battleheart.cn添加到CNAME文件中 修改域名解析，添加两天CNAME的解析，解析到\bdwlsxj.github.io,也就是自己的\b仓库下。 4. 将\bCNAME文件deploy到github仓库中即可访问。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.battleheart.cn/tags/Hexo/"}],"author":"BattleHeart"},{"title":"Spring Boot Admin监控系统搭建","slug":"spring-boot-admin-monitor","date":"2018-10-01T09:41:23.000Z","updated":"2018-10-01T13:23:15.918Z","comments":true,"path":"2018/10/01/spring-boot-admin-monitor/","link":"","permalink":"https://www.battleheart.cn/2018/10/01/spring-boot-admin-monitor/","excerpt":"","text":"Spring Boot Admin监控系统搭建介绍Spring Boot Admin是对Spring Boot的管理和监控的一个开源框架，支持Eureka服务注册列表状态监控，JMX监控，日志监控，JVM信息，垃圾信息，内存情况的监控，还可以设置日志的level级别。Spring Boot Admin UI 采用AngularJs将数据展示在前端。Spring Boot Admin分为服务端和客户端。 Spring Boot Admin Server端搭建 添加依赖项，依赖项内容如下： 12345678&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-server-ui&lt;/artifactId&gt;&lt;/dependency&gt; 在Spring Boot主类上添加对Spring Boot Admin Server启动的注解@EnableAdminServer 1234567891011121314151617181920212223242526@SpringBootApplication@EnableDiscoveryClient # 开启服务注册。@EnableTurbineStream # 开启Turbine服务监控。@EnableAdminServer # 开启Spring Boot Admin Server功能。public class SpringCloudMonitorApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudMonitorApplication.class, args); &#125; @Configuration public static class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; // 具有登录表单的页面作为/login.html提供，并在/ login上执行POST。 http.formLogin().loginPage(\"/login.html\").loginProcessingUrl(\"/login\").permitAll(); // 设置登出页面地址。 http.logout().logoutUrl(\"/logout\"); // 设置目前不支持csrf。 http.csrf().disable(); // 允许静态页面，静态数据的访问。 http.authorizeRequests().antMatchers(\"/login.html\", \"/**/*.css\", \"/img/**\", \"/third-party/**\").permitAll(); // 除了授权的页面所有内容都要进行授权访问。 http.authorizeRequests().antMatchers(\"/**\").authenticated(); // 启用安全认证，以便客户端可以通过HTTP basic进行身份验证以进行注册。 http.httpBasic(); &#125; &#125;&#125; 我们看到上面其实还添加对Eureka的注解以及对Turbine Stream的注解功能，需要添加Turbine Stream注解相关与Spring boot Admin Server ui相关依赖项，为了安全起见导入了安全相关依赖项。依赖项内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!—spring boot admin server ui支持登录页面依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-server-ui-login&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--Spring Boot 后台管理系统集成Hystrix监控--&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-server-ui-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Spring Boot 后台管理系统集成turbine--&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-server-ui-turbine&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--对Turbine Stream支持，使用RabbitMQ的方式对Hystrix数据进行收集分析。--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-turbine-stream&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;netty-transport-native-epoll&lt;/artifactId&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;netty-codec-http&lt;/artifactId&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- Eureka支持--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!—安全支持--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 其实Spring Boot Admin Server依赖中包含对Zuul和Hystrix以及Eureka核心包的依赖整合，所以我们看到上面只是整合了UI相关的依赖项。而针对Eureka和Turbine Stream以及安全方面的依赖需要额外导入进去，依赖项也导入进去后需要对端点进行权限安全控制，我们可以看到上面内部类中对安全进行控制，通过继承WebSecurityConfigurerAdapter对安全进行配置。 1234567891011121314// 具有登录表单的页面作为/login.html提供，并在/ login上执行POST。http.formLogin().loginPage(\"/login.html\").loginProcessingUrl(\"/login\").permitAll();// 设置登出页面地址。http.logout().logoutUrl(\"/logout\");// 设置目前不支持csrf。http.csrf().disable();// 允许静态页面，静态数据的访问。http.authorizeRequests() .antMatchers(\"/login.html\", \"/**/*.css\", \"/img/**\", \"/third-party/**\") .permitAll();// 除了授权的页面所有内容都要进行授权访问。http.authorizeRequests().antMatchers(\"/**\").authenticated();// 启用安全认证，以便客户端可以通过HTTP basic进行身份验证以进行注册。http.httpBasic(); 也就是说对那些内容页面进行授权访问，那些页面是可以直接访问，对安全的开启等等一系列操作。3. 修改配置文件信息，配置文件信息如下所示： 12345678910111213141516171819202122232425262728293031323334logging: level: org.springframework.cloud.netflix.zuul.filters.post.SendErrorFilter: errorserver: port: 8040turbine: stream: port: 8041 # 收集地址。eureka: # 注册为eureka服务。 instance: prefer-ip-address: true metadata-map: user.name: $&#123;security.user.name&#125; user.password: $&#123;security.user.password&#125; client: service-url: defaultZone: http://admin:$&#123;REGISTRY_SERVER_PASSWORD:password&#125;@localhost:8761/eureka/spring: rabbitmq: host: localhost username: guest password: guest port: 5672boot: admin: routes: endpoints: env,metrics,trace,dump,jolokia,info,configprops,trace,logfile,refresh,flyway,liquibase,heapdump,loggers,auditevents,hystrix.stream turbine: clusters: default location: http://localhost:$&#123;turbine.stream.port&#125;security: user: name: admin password: $&#123;MONITOR_SERVER_PASSWORD:admin&#125; 主要配置信息讲解： turbine.stream.port: 对Turbine支持，turbine服务端口号。 boot.admin.routes.endpoints: Spring Boot Admin暴露的EndPoint端点 spring.boot.admin.routes.turbine.clusters: 集群的名称 spring.boot.admin.routes.turbine.location: 集成Turbine服务数据收集的地址。 这里的地址就是为了收集是需要访问地址，我们之前在Turbine章节中说过这里不在多阐述。Eureka中的metadataMap是专门用来存放一些自定义的数据，当注册中心或者其他服务需要此服务的某些配置时可以在metadataMap里取。实际上，每个instance都有各自的metadataMap，map中存放着需要用到的属性。例如，上面配置中的eureka.instance.metadata-map.user.name，当这个服务成功注册到Eureka上，SpringBootAdmin就会取拿到这个instance，进而拿到metadataMap里的属性，然后放入请求头，向此服务发送请求，访问此服务的actuator开放的端点。 客户端 需要添加对安全保护的依赖项，以及对Turbine Stream注解。12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-hystrix-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 或者添加如下依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-hystrix-stream&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt;&lt;/dependency&gt; 以上对Turbine Stream的支持请参考Spring Cloud Turbine相关文章内容。2. 修改配置文件信息，添加对Turbine Stream 消息队列的支持。 123456789101112131415161718192021222324252627282930313233server: port: 8889 eureka: instance: hostname: localhost prefer-ip-address: true metadata-map: user.name: $&#123;security.user.name&#125; user.password: $&#123;security.user.password&#125; client: service-url: defaultZone: http://admin:$&#123;REGISTRY_SERVER_PASSWORD:password&#125;@$&#123;eureka.instance.hostname&#125;:8761/eureka/ healthcheck: enabled: true# Hystrix超时时间。hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 5000spring: abbitmq: port: 5672 username: guest password: guest host: localhost# Spring Boot Admin配置相关 # SpringBoot 1.5以后的版本都默认开启端点保护management: security: enabled: false 最主要的是management.security.enabled：关闭管理安全。下面是Spring Boot Admin相关监控信息。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.battleheart.cn/tags/SpringCloud/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://www.battleheart.cn/tags/Spring-Boot/"}],"author":"BattleHeart"},{"title":"使用Logback输出日志到ELK","slug":"logback-with-elk","date":"2018-10-01T08:34:26.000Z","updated":"2018-10-01T13:22:38.763Z","comments":true,"path":"2018/10/01/logback-with-elk/","link":"","permalink":"https://www.battleheart.cn/2018/10/01/logback-with-elk/","excerpt":"","text":"使用Logback输出日志到ELK背景介绍前两篇文章中我们介绍了windows上如何搭建ELK日志收集系统，那么问题来了，日志系统搭建完成后如何使用java代码直接输出日志到ELK系统中？ logback支持ELK我们带着背景中的问题进行下面的开始思路整理，其实在ELK文章中我们已经说了两种方案，其实ELK中logstash支持的日志收集的方式有很多种，下面说一下logstash收集其中方法： 使用logstash对文件进行检测 使用TCP协议，logstash开放对TCP协议端口的监听。 使用UDP协议，logstash开放对UDP协议端口的监听。 我们本章节中使用的是TCP协议的方式进行日志输出，下面看一下logback的配置文件。 引入依赖项logstash-logback-encoder 123456&lt;!-- logback和logstash结合 --&gt;&lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt; &lt;version&gt;5.2&lt;/version&gt;&lt;/dependency&gt; 修改logback的配置文件信息。 12345678&lt;appender name=\"LOGSTASH\" class=\"net.logstash.logback.appender.LogstashTcpSocketAppender\"&gt; &lt;destination&gt;192.168.1.107:9250&lt;/destination&gt; &lt;!-- encoder必须配置,有多种可选 --&gt; &lt;encoder charset=\"UTF-8\" class=\"net.logstash.logback.encoder.LogstashEncoder\"/&gt;&lt;/appender&gt;&lt;root level=\"ERROR\"&gt; &lt;appender-ref ref=\"LOGSTASH\"/&gt;&lt;/root&gt; appender的name属性使用的是net.logstash.logback.appender.LogstashTcpSocketAppenderdestination属性：tcp的IP地址和端口号encoder：编码格式","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.battleheart.cn/tags/ELK/"},{"name":"Java","slug":"Java","permalink":"https://www.battleheart.cn/tags/Java/"}],"author":"BattleHeart"},{"title":"Windows环境下搭建ELK环境","slug":"elk-environment-construction-in-windows","date":"2018-10-01T08:14:13.000Z","updated":"2018-10-01T14:29:50.685Z","comments":true,"path":"2018/10/01/elk-environment-construction-in-windows/","link":"","permalink":"https://www.battleheart.cn/2018/10/01/elk-environment-construction-in-windows/","excerpt":"","text":"Windows环境下搭建ELK环境搭建Elastic Stack环境 通过官网下载相关包，网址：https://www.elastic.co/cn/downloads/elasticsearch 运行bin/elasticsearch (or bin\\elasticsearch.bat on Windows) 在浏览器上访问http://localhost:9200，出现如下截图内容代表ES部署成功。 搭建Logstash环境 下载logstash文件，网址：https://www.elastic.co/cn/downloads/logstash下载Zip将Zip解压到本地。 新建Logstash.conf文件，将logstash.conf文件复制到bin文件夹下。 通过检测文件的方式输出日志： 123456789101112131415161718192021input &#123; file &#123; path =&gt; [&quot;D:/Log/*.log&quot;] 检测文件，通过检测文件变化输出到ES中。 start_position =&gt; &quot;beginning&quot; &#125;&#125;filter &#123; date &#123; match =&gt; [ &quot;timestamp&quot; , &quot;YYYY-MM-dd HH:mm:ss&quot; ] &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;localhost:9200&quot;] ES地址 &#125; stdout &#123; codec =&gt; rubydebug &#125;&#125; 通过TCP方式进行监听日志信息。 12345678910111213141516171819202122input &#123; tcp &#123; port =&gt; 9250 TCP端口号 codec =&gt; json_lines &#125;&#125;filter &#123; date &#123; match =&gt; [ &quot;timestamp&quot; , &quot;YYYY-MM-dd HH:mm:ss&quot; ] &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;localhost:9200&quot;] &#125; stdout &#123; codec =&gt; rubydebug &#125;&#125; 运行bin/logstash -f logstash.conf –t -t代表检测文件语法格式是否有误。通过访问9600可以得到如下内容：12345678910&#123; \"host\": \"DESKTOP-AVNGAHE\", \"version\": \"6.4.1\", \"http_address\": \"127.0.0.1:9600\", \"id\": \"bbb75ede-2654-4312-a80b-77d2c431ee73\", \"name\": \"DESKTOP-AVNGAHE\", \"build_date\": \"2018-09-13T23:17:51Z\", \"build_sha\": \"cee0d74663380e80c2a38cf5a9ccffb9a0cfa215\", \"build_snapshot\": false &#125; 搭建Kibana环境 下载Kibana，选择Windows版本。地址：https://www.elastic.co/cn/downloads/kibana 打开config/kibana.yml文件，设置elasticsearch.url 为http://localhost:9200 运行bin/kibana或者bin/kiana.bat（在windows下运行）。 访问地址localhost://5601 配置日志打开Discover菜单，创建索引 创建筛选器–根据时间筛选 再次返回到 Discover","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.battleheart.cn/tags/ELK/"}],"author":"BattleHeart"},{"title":"分布式服务跟踪之Spring Cloud Sleuth快速入门","slug":"quick-start-spring-cloud-sleuth","date":"2018-10-01T08:03:53.000Z","updated":"2018-10-01T13:23:06.482Z","comments":true,"path":"2018/10/01/quick-start-spring-cloud-sleuth/","link":"","permalink":"https://www.battleheart.cn/2018/10/01/quick-start-spring-cloud-sleuth/","excerpt":"","text":"背景随着业务的发展，系统规模也会变得越来越大，微服务之前的关系也会变得越来越复杂，客户端发起请求后通过一些列的微服务返回的结果，则会形成一个复杂的链路，在每个链路中如果有一个以来服务出现延迟或错误都会引发请求最后的失败，这时候对于整个链路的跟踪极为重要，通过实现队请求调用的跟踪可以帮助我们快速发现错误根源以及监控分析每条请求链路上的性能瓶颈等。接下来我们要使用Spring Cloud Sleuth与Zipkin进行整合。 Spring Cloud Sleuth使用。 需要准备两个服务，service1与service2，service1调用service2的方法。 添加依赖项spring-cloud-starter-sleuth。1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;&lt;/dependency&gt; spring-cloud-starter-sleuth它会自动为当前应用构建起各通信通道跟踪机制。比如： 通过诸如RabbitMQ、Kafaka（或者其他任何Spring Cloud Stream绑定器实现的消息中间件）传递的请求。 通过Zuul代理传递的请求。 通过RestTemplate发起的请求。 通过上面的配置即可对链路数据的监控，当我们访问service1和service2接口时会在控制台中输出相应的信息，例如： INFO [servce1,f410a57afd5c145,a9f2118fa201984,false]25028—call servce1INFO [servce1,f410a57afd5c145,e9a377dc2268bc29,false]25028—call servce2 中括号中的元素是实现分布式服务跟踪的重要组成部分，主要是：第一个值：service1代表的是应用的名称，也就是spring.application.name参数属性值。第二个值：Spring Cloud Sleuth生成的一个ID，称之为Trace ID，它用来标识是一条链路。一个请求链路中包含一个Trace ID，多个Span ID。第三个值：也是Spring Cloud Sleuth生成的一个ID，代表的是Span ID,他表示一个基本的工作单位，比如发送一个Http请求。也就是说同一个TranceID代表是一条链路，而不同的SpanID代表不同的Http请求和业务访问操作。 整合Zipkin 添加依赖项123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-sleuth-zipkin-stream&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-autoconfigure-ui&lt;/artifactId&gt;&lt;/dependency&gt; 其中包括：spring-cloud-sleuth-zipkin-stream、spring-cloud-stream-binder-rabbit表示使用RabbitMQ的方式对链路进行传递请求。zipkin-autoconfigure-ui依赖是通过页面的展示链路的情况。客户端中需要添加对RabbitMQ注解的支持，主要是spring-cloud-stream-binder-rabbit或者spring-cloud-starter-stream-rabbit，我可以清晰的发现前后两者内容其实是一样后者内容如下： 12345678910111213141516171819202122&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-rabbit-parent&lt;/artifactId&gt; &lt;version&gt;1.2.1.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;description&gt;Spring Cloud Starter Stream Rabbit&lt;/description&gt; &lt;url&gt;http://projects.spring.io/spring-cloud&lt;/url&gt; &lt;organization&gt; &lt;name&gt;Pivotal Software, Inc.&lt;/name&gt; &lt;url&gt;http://www.spring.io&lt;/url&gt; &lt;/organization&gt; &lt;properties&gt; &lt;main.basedir&gt;$&#123;basedir&#125;/../..&lt;/main.basedir&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 在Spring Boot主类上添加@EnableZipkinStreamServer注解开启Zipkin功能。 1234567@SpringBootApplication@EnableZipkinStreamServerpublic class SpringCloudSluethZipkinApplication &#123;public static void main(String[] args) &#123; SpringApplication.run(SpringCloudSluethZipkinApplication.class, args); &#125;&#125; 修改配置信息 1234567891011121314spring: application: name: springcloudsluethzipkinrabbitmq: host: localhost port: 5672 username: guest password: guestserver: port: 9411security: user: name: admin password: $&#123;ZIPKIN_SERVER_PASSWORD:admin&#125; 通过RabbitMQ对消息进行传递，将链路信息传递给RabbitMQ，Zipkin对消息队列消息进行收集分析得出实际的访问链路。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.battleheart.cn/tags/SpringCloud/"}],"author":"BattleHeart"},{"title":"集群监控Spring Cloud Turbine消息队列篇","slug":"quick-start-spring-cloud-turbine-rabbitmq","date":"2018-10-01T07:54:41.000Z","updated":"2018-10-01T13:23:28.642Z","comments":true,"path":"2018/10/01/quick-start-spring-cloud-turbine-rabbitmq/","link":"","permalink":"https://www.battleheart.cn/2018/10/01/quick-start-spring-cloud-turbine-rabbitmq/","excerpt":"","text":"介绍上一篇文章中我们介绍了Turbine简单的通过服务名称的方式构建监控聚合服务，这一章中我们将要讲一下使用消息队列的方式对集群信息进行收集，监控，我们可以将所有需要收集的监控信息都输出到消息代理中，然后turbine订阅消息代理中的消息，通过异步的方式读取消息，最后将读取出来的监控指标输出到Hystrix Dashboard中。 Turbine与消息代理结合 首先需要一个重要的东西就是消息代理，这里我们使用的是RabbitMQ来进行消息的传递与收集。（环境搭建省略） 添加依赖项12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-turbine-amqp&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 或者是 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-turbine-stream&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit &lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 因为我们可以看到spring-cloud-starter-turbine-amqp实际上是包装了spring-cloud-starter-turbine-stream和spring-cloud-starter-turbine-stream依赖。3. 在Spring Boot主类上添加@EnableTurbineStream注解来启用Turbine Stream的配置。 12345678@EnableTurbineStream@EnableDiscoveryClient@SpringBootApplicationpublic class TurbineApplication()&#123; public static void main(String[] args)&#123; SpringApplication.run(TurbineApplication.class,args); &#125;&#125; 配置文件信息中添加RabbitMq的配置信息。123456789101112131415161718192021spring: application: name: springCloudMonitorserver: port: 8040 eureka: # 注册为eureka服务。 instance: hostname: registry prefer-ip-address: true metadata-map: user.name: $&#123;security.user.name&#125; user.password: $&#123;security.user.password&#125; client: service-url: defaultZone: http://admin:$&#123;REGISTRY_SERVER_PASSWORD:password&#125;@localhost:8761/eureka/spring: rabbitmq: host: localhost username: guest password: guest port: 5672 对于Turbine的配置已经完成，还需要对服务消费者做一些修改，修改如下： 添加对RabbitMQ支持依赖项。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-hystrix-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 或者添加如下依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-hystrix-stream&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt;&lt;/dependency&gt; 因为第一个依赖项是对下面两个依赖项的整合，所以下面的和上面的效果是以昂的。2. 添加对RabbitMQ配置信息的支持。 123456spring: rabbitmq: port: 5672 username: guest password: guest host: localhost 这样就可以通过消息队列的方式进行系统监控。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.battleheart.cn/tags/SpringCloud/"}],"author":"BattleHeart"},{"title":"集群监控之Spring Cloud Turbine快速入门","slug":"quick-start-spring-cloud-turbine","date":"2018-10-01T07:41:23.000Z","updated":"2018-10-01T13:23:24.549Z","comments":true,"path":"2018/10/01/quick-start-spring-cloud-turbine/","link":"","permalink":"https://www.battleheart.cn/2018/10/01/quick-start-spring-cloud-turbine/","excerpt":"","text":"介绍Spring Cloud Turbine是对集群中微服务信息的统一监控收集监控信息，我们在每个微服务中添加了对Hystrix熔断器功能的支持，可以通过/hystrix.stream对每个微服务的运行状况进行监控，如果在集群中去对每一个微服务去进行单个访问是行不通的，这时候turbine就发挥了它的优势，他可以将多个微服务的hystrix.stream聚合到一起使用turbine.stream进行聚合监控。 Spring Cloud Turbine快速入门 添加依赖项，spring-cloud-starter-turbine，使用HystrixDashboard对Hystrix熔断进行图形化监控。 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-turbine&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt; 在Spring Boot的主类上添加@EnableTurbine注解开启Turbine功能。 12345678@SpringBootApplication@EnableTurbine@EnableHystrixDashboardpublic class SpringCloudHystrixTurbineApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudHystrixTurbineApplication.class, args); &#125;&#125; 修改配置文件信息，修改如下： 12345678910111213141516171819server: port: 8031spring: application: name: springhystrixturbineeureka: client: serviceUrl: defaultZone: http://admin:password@localhost:8761/eureka instance: prefer-ip-address: trueturbine: aggregator: clusterConfig: default #turbine.app-config指定了要收集监控信息的服务名 appConfig: spring-cloud-user,spring-cloud-service #turbine.cluster-name-expression 指定集群名称 clusterNameExpression: \"'default'\" combine-host-port: true #使同一主机上的多个服务实例可以通过主机名和端口号的组合来进行区分 配置信息参数描述： turbine.appConfig：制定要收集监控信息的服务名，意思就是代表这些服务的hystrix.stream由turbine来进行收集监控。 turbine.cluster-name-expression：指定集群的名称。 combine-host-port：默认是true，代表同一台主机上多个服务实例可通过主机名和端口号组合来进行区分，因为同一个服务器可能部署多台微服务实例。 集群监控，可以通过访问http://localhost:8031/hystrix 对单个服务进行监控可以清晰的看到下面的需要进行turbine监控的url的写法http://localhost:8031/turbine.stream?cluster=default，其中cluster是我们在指定集群的名称。可以看到如下页面进行集群监控：这说明我们集群监控配置成功。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.battleheart.cn/tags/SpringCloud/"}],"author":"BattleHeart"},{"title":"API网关服务-Spring Cloud Zuul快速入门","slug":"quick-start-spring-cloud-zuul","date":"2018-09-27T15:18:38.000Z","updated":"2018-10-01T13:23:20.146Z","comments":true,"path":"2018/09/27/quick-start-spring-cloud-zuul/","link":"","permalink":"https://www.battleheart.cn/2018/09/27/quick-start-spring-cloud-zuul/","excerpt":"","text":"目录 简介 Spring Cloud Zuul使用 简介Api网关是一个更为只能的应用服务器，他的定义类似面向对象设计模式中的Façade模式，它的存在就像是整个微服务架构系统的门面一样，所有的外部客户端访问都需要经过它来进行调度和过滤。他除了要实现请求路由、负载均衡、校验过滤等功能外，还需要更多的能力，比如与服务治理框架的结合，请求转发是的熔断机制，服务的聚合等一些列高级功能。 Spring Cloud Zuul使用 添加依赖项spring-cloud-starter-zuul1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt;&lt;/dependency&gt; spring-cloud-starter-zuul包下不仅仅包含zuul-core包，还包含了spring-cloud-starter-hystrix、spring-cloud-starter-ribbon、spring-boot-starter-autuator，提供了负载均衡以及熔断器的支持。2. Spring Boot主类添加@EnableZuulProxy注解开启Zuul的API网关功能。 12345678910/*** 网关。*/@SpringBootApplication@EnableZuulProxypublic class SpringCloudZuulApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudZuulApplication.class, args); &#125;&#125; 我们可以看到@EnableZuulProxy注解其实是一个组合注解，它包含了开启Hystrix熔断技术的功能以及对Eureka注册中心的功能的开启。 1234567@EnableCircuitBreaker # 开启Hystrix熔断器功能。@EnableDiscoveryClient # 开启Eureka客户端功能。@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Import(&#123;ZuulProxyMarkerConfiguration.class&#125;)public @interface EnableZuulProxy &#123;&#125; 修改配置文件信息。123456789101112131415161718192021222324252627spring: application: name: springcloudzuulserver: port: 8050eureka: client: service-url: defaultZone: http://admin:password@localhost:8761/eureka instance: prefer-ip-address: truezuul: ignoredServices: springcloudservice # 取消对服务路由机制列表 routes: springclouduser: /user/** # 指定服务路径。# Hystrix超时等到时间。hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 20000# ribbon超时等待时间。ribbon: ReadTimeout: 10000 ConnectTimeout: 10000 理由规则配置讲解： zuul.ignoredServices：取消路由机制的服务名称列表。 zuul.routes.name: 我们可以看到name被标记为红色字体，代表的是注册到erueka服务中的服务名称，例如上面是springclouduser服务的路由规则是通过/user进行访问该服务的所有接口信息。 zuul.routes.xxx.path=/xxx/**zuul.routes.xxx.url=http://localhost:8080/该配置的表示所有符合/xxx/**规则的访问都将转发到http://localhost:8080 地址上，例如：访问服务中的http://localhost:8081/xxx/getUserList 接口时，API网关服务会将该请求路由到http://localhost:8080/getUserList 提供的服务接口上。其中红色部分为路由的名称，可以任意定义，但是一组path和url映射关系的路由名称要相同。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.battleheart.cn/tags/SpringCloud/"}],"author":"BattleHeart"},{"title":"配置管理中心Spring Cloud Config快速入门","slug":"quick-start-spring-cloud-config","date":"2018-09-27T14:57:02.000Z","updated":"2018-10-01T13:22:53.901Z","comments":true,"path":"2018/09/27/quick-start-spring-cloud-config/","link":"","permalink":"https://www.battleheart.cn/2018/09/27/quick-start-spring-cloud-config/","excerpt":"","text":"配置管理中心-Spring Cloud ConfigSpring Cloud Config简介Spring Cloud Config是用为分布式系统中的基础设施和服务应用提供集中化的外部配置支持，它分为服务端和客户端两个部分。服务端是一个独立的服务，用来连接配置仓库并为客户端提供获取配置信息、加密、解密信息等访问接口，客户端则是微服务架构中的各个微服务应用或基础设施，它们通过指定的配置中心来管理应用资源与业务相关配置内容，并在启动时候从配置中心获取和加载配置信息。Spring Cloud Config默认是git仓库进行存储配置信息，同时也支持其他方式进行存储，例如数据库，文件系统等。 Spring Cloud Config使用服务端 添加依赖项spring-cloud-stater-config-server 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 创建Spring boot的程序主类，并添加@EnableConfigServer注解，开启Spring Cloud Config的服务端功能。 1234567891011/** * 配置相关信息。*/@SpringBootApplication@EnableConfigServer # 开启Spring Cloud Config功能。@EnableEurekaClientpublic class SpringCloudConfigApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudConfigApplication.class, args); &#125;&#125; 修改配置文件信息，添加配置服务的基本信息以及git仓库相关信息。 1234567891011121314151617181920212223server: port: 8080spring: cloud: config: server: git: uri: https://github.com/dwlsxj/spring-cloud-test.git # 配置仓库地址。 search-paths: git-repo # 仓库文件夹地址。eureka: instance: prefer-ip-address: true metadata-map: user.name: $&#123;security.user.name&#125; user.password: $&#123;security.user.password&#125; client: service-url: defaultZone: http://admin:$&#123;REGISTRY_SERVER_PASSWORD:password@localhost:8761/eureka/# Eureka地址。# 安全验证。security: user: name: user password: $&#123;CONFIG_SERVER_PASSWORD:password&#125; 其中配置信息分别如下所示：spring.cloud.config.server.git.uri：git仓库的地址。spring.cloud.config.server.search-paths：对应仓库下相对所搜的位置，可以配置多个，其实就是存储配置信息的具体位置，例如如果仓库中存放了其他的内容并不是单纯存储配置信息，可通过该参数对配置信息进行搜索，定位。spring.cloud.config.server.git.username：访问git仓库的用户名。spring.cloud.config.server.git.password：访问git仓库的密码。4. 配置规则详解,我们可以通过浏览器、postman、curl等工具直接访问配置相关信息，访问配置信息的URL与配置文件的映射关系如下所示： /{application}/{profile}[/{label}] /{application}-{profile}.yml /{label}/{application}-{profile}.yml /{application}-{profile}.properties /{label}/{application}-{profile}.properties 访问地址：当我们通过URL访问配置信息时，我们发现控制台出现如下内容： 配置服务实际是从Git仓库获取配置信息后，会存储一份在config-server的文件系统中，实质上config-server是通过git clone命令将配置内容复制一份在本地存储，然后读取本地内容返回给客户端，通过本地仓库暂存，可以有效的放置当git仓库出现故障而引起的无法加载的问题。 客户端 添加依赖项spring-cloud-starter-config 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; 对配置文件进行添加配置中心服务地址，以及安全访问的用户名密码等信息。 12345678910111213141516spring: application: name: springclouduser cloud: config: uri: http://localhost:8080 fail-fast: true username: user password: $&#123;CONFIG_SERVER_PASSWORD:password&#125; profile: dev label: master retry: # 重试机制。 initial-interval: 2000 max-interval: 10000 multiplier: 2 max-attempts: 10 主要配置信息讲解：spring.application.name：服务名称，对应配置文件规则中的{application}部分。spring.cloud.config.uri:配置中心服务地址。spring.cloud.config.username:访问服务注册中心用户名。spring.cloud.config.password:访问注册中心密码。spring.cloud.config.profile:应用的环境信息，对应配置规则中的{profile}部分。spring.cloud.config.label:主要是分支，对应配置文件规则中的{label}部分。需要注意的是这些配置信息必须配置到bootstrap.yml或bootstrap.properties文件中，因为配置信息application.yml和bootstrap.yml是有加载顺序的，首先程序启动时先加载的是bootstrap.yml文件，其次是application.yml配置信息，因为jar包之外的配置信息优先于jar包之内的配置信息，所以需要首先加载外部的配置信息。3. 对配置信息的读取和使用，首先需要添加配置类，对配置信息通过EL表达式的方式进行注入。读取方式有两种方式： 通过@Value(“${profile}”)方式绑定参数到属性中。 123456789/** * 服务配置信息。*/@RefreshScope@Configurationpublic class ServiceConfig &#123;@Value(\"$&#123;profile&#125;\") private String profile;&#125; 通过Environment对象来获取配置属性。 12345678910111213/** * 服务配置信息。*/@RefreshScope@RestControllerpublic class TestController&#123; @Autowired private Environment env; @GetMapping(“/getProfile”) public String getProfile()&#123; return env.getProperty(“profile”,“null”); &#125;&#125;","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.battleheart.cn/tags/SpringCloud/"}],"author":"BattleHeart"},{"title":"服务容错保护Spring Cloud Hystrix之快速入门","slug":"quick-start-spring-cloud-hystrix","date":"2018-09-27T14:15:34.000Z","updated":"2018-10-01T13:22:58.314Z","comments":true,"path":"2018/09/27/quick-start-spring-cloud-hystrix/","link":"","permalink":"https://www.battleheart.cn/2018/09/27/quick-start-spring-cloud-hystrix/","excerpt":"","text":"目录 Spring Cloud Hystrix介绍 Spring Cloud Hystrix整合 常用配置 Spring Cloud Hystrix介绍Spring Cloud Hystrix实现了断路器、线程隔离等一系列服务保护功能。它是基于Netflix的开源框架Hystrix实现，该框架的目标在于通过控制那些访问远程系统，服务和第三方库的节点，从而对延迟和故障提供更强大的容错能力。Hystrix具备服务降级，服务熔断、线程和信号隔离、请求缓存、请求合并以及服务监控等功能。场景描述：如果我们在微服务中进行通信时，发现其中微服务宕机了，这时候另外一个服务调用了宕机的服务，如果在没有断路器机制的前提下访问，这时候会一直等待，一直等待到服务达到超时的点，会使得线程因调用故障服务被长时间占用不能释放，通过断路器的故障监控，如果发现故障时，会向调用者返回一个错误相应，这样就不用长时间等待。 Spring Cloud Hystrix整合 添加依赖项。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId &gt;&lt;/denpendecy&gt; 同时需要添加spring-boot-starter-actuator，这是Spring Boot对监控的依赖项，只有添加了这些东西后监控相关的endpoint才会被注册。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 添加注解@EnableCircuitBreaker，对Hystrix进行开启功能。 12345678@SpringBootApplication@EnableEurekaClient #开启Eureka客户端注册@EnableCircuitBreaker #开启Hystrix功能public class SpringCloudUserApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudUserApplication.class, args); &#125;&#125; 改造服务消费方式，通过添加@HystrixCommod注解对服务接口的熔断技术。 1234567891011121314151617181920212223@RestControllerpublic class TestController &#123; private static Logger logger = LoggerFactory.getLogger(TestController.class); @Autowired private RestTemplate restTemplate; /** * 调用Service来获取内容。 * * @return 返回hello world。 */ @GetMapping(value = \"getHelloWorld\") @HystrixCommand(fallbackMethod = \"fallback\") public String getHelloWorld() &#123; return restTemplate.getForObject(\"http://springcloudservice/getHelloWorld\", String.class); &#125; /** * getHelloWorld的熔断机制。 * * @return 熔断信息。 */ public String fallback() &#123; return \"error\"; &#125;&#125; 代码分析： 通过依赖注入RestTemplate，该Bean主要是对Rest Api进行访问，可以裂解调用服务接口的封装。 定义了getHelloWorld去访问另外一个服务springcloudservice的getHelloWorld方法 对该接口上添加了@HystrixCommod注解，通过制定fallbackMethod对出现问题接口进行错误转向 定义错误转向方法：fallback() 当springcloudservice服务宕机后，可以快速返回“error“字样。 1234567891011121314151617181920212223@HystrixCommodpublic @interface HystrixCommand &#123;// HystrixCommand 命令所属的组的名称：默认注解方法类的名称String groupKey() default \"\";// HystrixCommand 命令的key值，默认值为注解方法的名称String commandKey() default \"\";// 线程池名称，默认定义为groupKeyString threadPoolKey() default \"\";// 定义回退方法的名称, 此方法必须和hystrix的执行方法在相同类中String fallbackMethod() default \"\";// 配置hystrix命令的参数HystrixProperty[] commandProperties() default &#123;&#125;;// 配置hystrix依赖的线程池的参数HystrixProperty[] threadPoolProperties() default &#123;&#125;;// 如果hystrix方法抛出的异常包括RUNTIME_EXCEPTION，则会被封装HystrixRuntimeException异常。我们也可以通过此方法定义哪些需要忽略的异常Class&lt;? extends Throwable&gt;[] ignoreExceptions() default &#123;&#125;;// 定义执行hystrix observable的命令的模式，类型详细见ObservableExecutionMode ObservableExecutionMode observableExecutionMode() default ObservableExecutionMode.EAGER; // 如果hystrix方法抛出的异常包括RUNTIME_EXCEPTION，则会被封装HystrixRuntimeException异常。此方法定义需要抛出的异常HystrixException[] raiseHystrixExceptions() default &#123;&#125;;// 定义回调方法：但是defaultFallback不能传入参数，返回参数和hystrix的命令兼容String defaultFallback() default \"\";&#125; 常用配置12345678# Hystrix超时时间hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 5000","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.battleheart.cn/tags/SpringCloud/"}],"author":"BattleHeart"},{"title":"客户端负载均衡Spring Cloud Ribbon之快速入门","slug":"quick-start-spring-cloud-ribbon","date":"2018-09-27T11:15:34.000Z","updated":"2018-10-01T13:23:02.098Z","comments":true,"path":"2018/09/27/quick-start-spring-cloud-ribbon/","link":"","permalink":"https://www.battleheart.cn/2018/09/27/quick-start-spring-cloud-ribbon/","excerpt":"","text":"客户端负载均衡-Spring Cloud Ribbon目录 客户端负载均衡-Spring Cloud Ribbon Spring Cloud Ribbon介绍 Spring Cloud Ribbon使用 Spring Cloud Ribbon介绍Spring Cloud Ribbon是一个基于HTTP和TCP的客户端负载均衡工具，它是基于Netflix的Ribbon的实现。通过Spring Cloud的封装可以轻松的将面向服务的Rest模板请求自动转化成客户端负载均衡的服务调用。它是一个工具类框架，不能像服务注册中心、配置中心、API网关单独部署，但是可以存在每一个Spring Cloud构建的微服务和基础设施中。负载均衡模块都会维护一个可用的服务列表，通过心跳检测来剔除故障的服务端节点以保证清单中都是可以正常访问的服务端节点。客户端负载均衡和服务端负载均衡唯一的区别是客户端负载均衡中，所有客户端负载均衡都会自己维护服务清单，而这些服务清单是由服务注册中心获取得到。 Spring Cloud Ribbon使用1． 添加依赖项spring-cloud-starter-ribbon 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; 添加注解对负载均衡支持@LoadBalanced 1234567891011/*** 服务配置信息。*/@Configurationpublic class ServiceConfig &#123; @Bean @LoadBalanced public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125;&#125; 服务之间调用通过服务名称的方式进行调用而不是通过ip地址的方式。 123456789/** * 调用Service来获取内容。 * * @return 返回hello world。 */ @GetMapping(value = \"getHelloWorld\") public String getHelloWorld() &#123; return restTemplate.getForObject(\"http://springcloudservice/getHelloWorld\", String.class); &#125; 这里的springcloudservice是注册到Eureka的服务，服务名称为springcloudservice，可以通过加了@LoadBalanced修饰过的RestTemplate来实现面向服务的接口调用。之前调用方式如下代码所示：restTemplate.getForObject(“http://localhost:8888/getHelloWorld&quot;, String.class);","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.battleheart.cn/tags/SpringCloud/"}],"author":"BattleHeart"},{"title":"服务治理-Spring Cloud Eureka","slug":"spring-cloud-tutorial-eureka","date":"2018-09-26T08:01:31.000Z","updated":"2018-10-01T13:23:11.311Z","comments":true,"path":"2018/09/26/spring-cloud-tutorial-eureka/","link":"","permalink":"https://www.battleheart.cn/2018/09/26/spring-cloud-tutorial-eureka/","excerpt":"","text":"Eureka介绍Eureka是Spring Cloud Netflix的微服务套件的一部分，它是基于Netflix Eureka的二次开发，主要负责完成微服务架构中的服务治理功能。而且可以与Spring boot很容易的整合进行开发，使得开发变得简单，Eureka包含了服务器端和客户端组件。服务器端，也被称作是服务注册中心，用于提供服务的注册与发现。Eureka支持高可用的配置，当集群中有分片出现故障时，Eureka就会转入自动保护模式，它允许分片故障期间继续提供服务的发现和注册，当故障分片恢复正常时，集群中其他分片会把他们的状态再次同步回来。客户端，也被称为服务消费者与服务的生产者，服务启动时向服务注册中心（服务端）进行注册自己，并通过定时心跳检测的方式告诉服务端存活状态，更新服务续约，同时也可以将服务端的服务列表缓存到本地并周期性刷新服务列表的状态。 Eureka的使用服务端 在pom文件中添加依赖项。123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;!- - 处于安全考虑 - -&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 需要添加对Spring Cloud版本的控制，这里我们使用的事Dalston.SR4版本，要求Spring boot版本号低于2.0版本。 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt; Dalston.SR4&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 添加配置信息，在application.yml或application.properties中添加如下内容 1234567891011121314151617181920spring: application: name: springcloudeurekaserver # 注册到微服务中的服务名称。server: port: 8761 # 端口号eureka: instance: prefer-ip-address: true client: registerWithEureka: false # 是否注册自己，不注册 fetchRegistry: false # 禁止检测服务 service-url: defaultZone: http://$&#123;security.user.name&#125;:$&#123;security.user.password&#125;@localhost:$&#123;server.port&#125;/eureka/ #Eureka服务地址。# 处于安全考虑需要对用户进行登录。security: user: name: admin password: $&#123;REGISTRY_SERVER_PASSWORD:password&#125; 添加@EnableEurekaServer注解，开启对Eureka服务的支持。 1234567@SpringBootApplication@EnableEurekaServerpublic class SpringCloudEruekaApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudEruekaApplication.class, args); &#125;&#125; 运行Eureka服务，通过访问http://localhost:8761/eureka/进行访问Eureka注册中心，查看Eureka有哪些服务注册上，下图是Eureka主界面展示： 页面描述 nstances currently registered with Eureka：服务注册列表信息。 DS Replicas代表的集群部署时，server地址。 客户端 在pom文件中添加依赖项。 123456789101112131415161718192021&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt;&lt;!- - 处于安全考虑 - -&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;# 需要添加对Spring Cloud版本的控制，这里我们使用的事Dalston.SR4版本，要求Spring boot版本号低于2.0版本。&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt; Dalston.SR4&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 添加配置信息，在application.yml或application.properties中添加如下内容 1234567891011spring: application: name: springclouduser # 注册到微服务中的服务名称。server: port: 8889eureka: instance: prefer-ip-address: true client: service-url: defaultZone: http://admin:$&#123;REGISTRY_SERVER_PASSWORD:password&#125;@$&#123;eureka.instance.hostname&#125;:8761/eureka/ #Eureka服务地址。 添加@EnableEurekaClient注解或@ EnableDiscoveryClient，开启对Eureka客户端的支持。 1234567@SpringBootApplication@EnableEurekaServerpublic class SpringCloudEruekaApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudEruekaApplication.class, args); &#125;&#125; 这样三步骤就讲微服务注册到服务中心中，可以看到服务中心已经获取到当前服务信息。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.battleheart.cn/tags/SpringCloud/"}],"author":"BattleHeart"},{"title":"Java类加载器详解","slug":"java-class-loader","date":"2018-09-22T16:00:00.000Z","updated":"2018-10-08T02:11:35.891Z","comments":true,"path":"2018/09/23/java-class-loader/","link":"","permalink":"https://www.battleheart.cn/2018/09/23/java-class-loader/","excerpt":"","text":"类加载器详解 一、类加载器5大部分 加载 验证 准备 解析 初始化 二、类加载器 三、自定义类加载器 类加载器详解一、类加载器5大部分JVM类加载机制分为五个部分：加载，验证，准备，解析，初始化，下面我们就分别来看一下这五个过程。 加载加载是类加载过程中的一个阶段，这个阶段会在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的入口。注意这里不一定非得要从一个Class文件获取，这里既可以从ZIP包中读取（比如从jar包和war包中读取），也可以在运行时计算生成（动态代理），也可以由其它文件生成（比如将JSP文件转换成对应的Class类）。 验证这一阶段的主要目的是为了确保Class文件的字节流中包含的信息是否符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 准备准备阶段是正式为类变量分配内存并设置类变量的初始值阶段，即在方法区中分配这些变量所使用的内存空间。注意这里所说的初始值概念，比如一个类变量定义为： 1public static int v = 8080; 实际上变量v在准备阶段过后的初始值为0而不是8080，将v赋值为8080的putstatic指令是程序被编译后，存放于类构造器&lt;clinit&gt;方法之中，这里我们后面会解释。但是注意如果声明为： 1public static final int v = 8080; 在编译阶段会为v生成ConstantValue属性，在准备阶段虚拟机会根据ConstantValue属性将v赋值为8080。 解析解析阶段是指虚拟机将常量池中的符号引用替换为直接引用的过程。符号引用就是class文件中的： 123CONSTANT_Class_infoCONSTANT_Field_infoCONSTANT_Method_info 等类型的常量。下面我们解释一下符号引用和直接引用的概念：符号引用与虚拟机实现的布局无关，引用的目标并不一定要已经加载到内存中。各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。直接引用可以是指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那引用的目标必定已经在内存中存在。 初始化初始化阶段是类加载最后一个阶段，前面的类加载阶段之后，除了在加载阶段可以自定义类加载器以外，其它操作都由JVM主导。到了初始阶段，才开始真正执行类中定义的Java程序代码。初始化阶段是执行类构造器&lt;clinit&gt;方法的过程。&lt;clinit&gt;方法是由编译器自动收集类中的类变量的赋值操作和静态语句块中的语句合并而成的。虚拟机会保证&lt;clinit&gt;方法执行之前，父类的&lt;clinit&gt;方法已经执行完毕。p.s: 如果一个类中没有对静态变量赋值也没有静态语句块，那么编译器可以不为这个类生成&lt;clinit&gt;()方法。（clinit初始化是对类成员信息进行初始化，init是对对象实例进行初始化操作）注意以下几种情况不会执行类初始化：通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化。定义对象数组，不会触发该类的初始化。常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触发定义常量所在的类。通过类名获取Class对象，不会触发类的初始化。通过Class.forName加载指定类时，如果指定参数initialize为false时，也不会触发类初始化，其实这个参数是告诉虚拟机，是否要对类进行初始化。通过ClassLoader默认的loadClass方法，也不会触发初始化动作。 二、类加载器虚拟机设计团队把加载动作放到JVM外部实现，以便让应用程序决定如何获取所需的类，JVM提供了3种类加载器： 启动类加载器(Bootstrap ClassLoader)：负责加载 JAVA_HOME\\lib（JRE/lib/rt.jar） 目录中的，或通过-Xbootclasspath参数指定路径中的，且被虚拟机认可（按文件名识别，如rt.jar）的类。 扩展类加载器(Extension ClassLoader)：负责加载 JAVA_HOME\\lib\\ext（JRE/lib/ext/*.jar） 目录中的，或通过java.ext.dirs系统变量指定路径中的类库。 应用程序类加载器(Application ClassLoader)：负责加载用户路径（classpath）上的类库。 自定义的类加载器（User ClassLoader）：负责加载用户自定义的路径上的类库。JVM通过双亲委派模型进行类的加载，当然我们也可以通过继承java.lang.ClassLoader实现自定义的类加载器。 类加载器的委托机制： 首先当前线程去加载线程中的第一个类 如果A中引用了B，java虚拟机将使用加载类A的类加载取来加载B 还可以直接使用ClassLoader.loadClass()方法来指定某个类加载器去加载某个类。 每个类加载器加载类时，又先委托给其上级类加载器。 当所有祖先类加载器没有加载到类，回到发起者类加载器，还加载不了就抛出异常ClassNotFoundException，不是再去找发起类加载器的儿子节点，因为没有getChild方法。 eg.比如说我们自定义一个类A，当我们去获取当前类加载器的名称时，肯定是AppClassLoader加载器，因为我们当前类只有CLASSPATH路径下有没如果我们将当前的项目打包成test.jar将jar包放入到JRE/lib/ext路径下，这时候我们在CLASSPATH中类就不会被加载，首先加载的是ext下的类A。这时候我们输出类A加载器名称的时就会输出ExtClassLoader。下面做演示。 123public static void main(String[] args) &#123; System.out.printf(ClassLoaderTest.class.getClassLoader().getClass().getName());&#125; ClassLoaderTest是我们新建立的类，获取当前类的加载器时输出内容为： 1sun.misc.Launcher$AppClassLoader 如果打包成jar包放到，ext文件下我们来看一下内容： 这是输出一下内容查看一下： 1sun.misc.Launcher$ExtClassLoader 123456ClassLoader classLoader = com.classloadertest.ClassLoaderTest.class.getClassLoader();while (classLoader != null) &#123; System.out.println(classLoader.getClass().getName()); classLoader=classLoader.getParent();&#125;System.out.println(classLoader); 循环输出类加载器结构的时候会出现 12sun.misc.Launcher$ExtClassLoadernull 因为Bootstrap类加载器实现不是由Java实现所以获取不到字节码，也就是为null的时候意味着是树状结构的顶层。 三、自定义类加载器有些时候我们需要实现自定义的类加载器来加载一些类，这时候我们可以继承ClassLoader来进行实现自定义的类加载器。我们先看一下jdk中的ClassLoader的源码实现： 12345678910111213141516171819202122232425262728293031323334protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; // 递归先父类进行尝试加载。 c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125;&#125; 首先检测当前类有没有加载，如果加载在就不需要加载直接返回字节码 如果没有被加载，这时候会委托加载机制，通过递归从父加载器开始找，直到父类加载器为bootstrap ClassLoader为止，如果父类加载器找到了该字节码后没直接返回如果没有就返回让子类加载器加载，当子类加载器时， 如果还没有找到，这时候调用findClass方法进行查找。 最后根据resolve的值，判断这个class是否需要解析。 首先类加载器进行加载时当前线程的上线文的ClassLoader也就是APPClassLoader，当加载类时调用LoadClass方法，当调用的时候会检测当前类有没有被加载如果被加载了，就不需要在加载了直接返回，反之调用父类加载器的LoadClass方法，当父类加载器的父加载器不是null的时候就再去调用LoadClass方法，这时候的类加载器是ExtClassLoader加载器，父类加载是BootStrap ClassLoader，这时候继续递归调用LoadClass方法，这时候类加载器为BootStrap ClassLoader， 这时候就不需要再往下寻找了， parent ClassLoader为null。这是调用findBootstrapClassOrNull(name)方法，如果c不为null，这时候就直接返回，但是如果为null就调用findClass进行查询加载，如果还为null，这时候就会调用父类加载器ExtClassLoader的findClass方法，如果还是没有找到，则调用线程本身的类加载器调用findClass方法返回相应字节码，如果还没有找到抛出异常。 1类加载器采用了设计模式是模板方法，也就是LoadClass方法是不需要进行改变的，我们需要关注的就是findClass()方法就好了。所以我们写自己的ClassLoader只需要继承ClassLoader并重写findClass方法即可。 参考地址：https://www.ziwenxie.site/2017/06/07/java-jvm-classloader/http://blog.csdn.net/briblue/article/details/54973413","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.battleheart.cn/tags/Java/"}],"author":"BattleHeart"},{"title":"一文搭建Maven骨架","slug":"maven-skeleton-generation","date":"2018-09-22T16:00:00.000Z","updated":"2018-10-01T13:22:45.963Z","comments":true,"path":"2018/09/23/maven-skeleton-generation/","link":"","permalink":"https://www.battleheart.cn/2018/09/23/maven-skeleton-generation/","excerpt":"","text":"Maven骨架介绍 Maven archetype Maven骨架创建过程 使用archetype创建项目 使用本地Maven骨架 Maven骨架介绍Maven archetypeArchetype是一个Maven项目模板工具包，通过Archetype我们可以快速搭建Maven项目，通俗理解就是项目的基础架构，项目初始化的过程。我们在使用Idea开发工具的时候会有如下图操作：在这里选择的Maven进行生成的项目都是利用Maven骨架来进行生成的，通过选择骨架生成项目结构的方式方便了我们手动去搭建相关项目内容。可以直接通过自带骨架或自己构建的骨架进行项目的快速搭建，节约成本。我们构建一个完整的骨架整体的操作逻辑如下图所示：接下来将详细剖析每一步内容。 Maven骨架创建过程使用archetype创建项目 第一步建立Maven的项目，其实就是我们想要生成骨架的项目结构。 在pom.xml中添加插件maven-archetype-plugin。 1234567891011&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-archetype-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/plugin&gt;&lt;/plugins&gt; 打开命令行进入到项目主目录中，运行如下命令：mvn archetype:create-from-project此时会在该项目的target目录下发现如下文件：我们可以清晰的发现archetype目录下是我们的项目结构，项目结构下面src/main/resources/META-INF/包含archetype-metadata.xml，这个文件是用来自定义骨架内容的，接下内容中会对信息进行详细的说明。 进入到target/generated-sources/archetype目录下，使用mvn clean install进行打包到本地文件中。这时候你会在maven的本地仓库中多出一个文件archetype-catalog.xml打开文件发现这里面有我们添加的Maven骨架信息。 注意\b：如果想要删除本地的内容就直接删除archetype节点即可。 使用本地Maven骨架12345678mvn archetype:generate -DinteractiveMode=false 禁止询问，如果不加命令行会询问你填写版本号等信息是否正确。 -DarchetypeCatalog=local 生成项目解析方式，local=本地骨架 internal=内部的 remote=这是Maven中央存储库或其镜像的捷径 -DgroupId=com.jtech.wpark.test 生成项目的groupId -DartifactId=tetetetetet 生成项目的artifactId -DarchetypeGroupId=com.jtech 骨架的groupId -DarchetypeVersion=0.0.1-SNAPSHOT 骨架版本号 -DarchetypeArtifactId=yaoyuan-archetype 骨架的artifactId archetypeCatalog如果想要来自不同仓库的骨架信息，可以在maven的Setting.xml中设置如下内容： 1234567891011&lt;repository&gt; &lt;id&gt;archetype&lt;/id&gt; &lt;url&gt;https://repository.domain.com/path/to/repo/&lt;/url&gt;&lt;/repository&gt;&lt;!-- in case of a repository with authentication --&gt;&lt;server&gt; &lt;id&gt;archetype&lt;/id&gt; // 私服的Id &lt;username&gt;xxxx&lt;/username&gt; &lt;password&gt;xxxx&lt;/password&gt;&lt;/server&gt; 如果Maven中央存储库目录文件是空的，则使用内部目录。 Maven私服上传使用mvn clean deploy对骨架上传到私服中，这里会存在一个问题，也就是上传的地址需要在pom.xml配置下，pom.xml文件路径为target/generated-sources/archetype/pom.xml文件。需要对该pomw\b文件添加distributionManagement节点，节点内容主要是私服地址信息，配置之后使用mvn clean deplod会将骨架上传到私服中去。 使用私服服务器骨架12345678910mvn archetype:generate -DinteractiveMode=false -DarchetypeCatalog=internal,remote 类型改变 -DarchetypeRepository=http://xxxxxx:8181/nexus/content/groups/public 私服地址 -DarchetypeGroupId=com.jtech -DarchetypeArtifactId=yaoyuan-archetype -DarchetypeVersion=0.0.1-SNAPSHOT -DgroupId=com.jtech.wpark.test -DartifactId=tetetetetet -Dversion=0.1-SNAPSHOT 这里需要注意一下,我们发现修改了\b远程私服进行构建项目时，指定了Repository为什么没有下载下来反而会出现如下错误信息：解决方案是：修改maven的setting.xml文件，将文件修改为如下： 添加repository 12345678910111213141516&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;snapshot&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;snapshots /&gt; &lt;id&gt;my-snapshot&lt;/id&gt; &lt;name&gt;my-snapshot&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8181/nexus/content/groups/public/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;snapshot&lt;/activeProfile&gt; &lt;/activeProfiles&gt; 添加server 12345&lt;server&gt; &lt;id&gt;my-snapshot&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin&lt;/password&gt;&lt;/server&gt; 需要添加对私服的repository，以及Server，这里的Server ID和对应的archetype repository的Id是一致的。这样才会在私服中下载下来相应的archetype文件。 自定义骨架内容当我们按照上面步骤走完之后发现项目中多出了不需要的文件，这时候我们就需要对骨架的内容进行自定义。这里面.idea和yaoyuan.iml文件都不是我们想要的，这时候我们想到之前说过的一个文件archetype-metadata.xml，我们打开这个文件看一下。 （这里的xml指的是target\b\b生成的文件\b目录下的）包含了一堆没用的文件进来了，这时候我们将这些东西删除掉，在mvn install一下。 注意：这个文件很重要，主要是如果文件夹为空的时候当我们生成骨架的时候是不会包含当前文件的，你需要对上面xml进行配置包含当前文件即可。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"https://www.battleheart.cn/tags/Maven/"}],"author":"BattleHeart"},{"title":"动态代理的工作原理简要分析","slug":"how-dynamic-agents-work","date":"2018-09-19T16:00:00.000Z","updated":"2018-10-01T13:22:30.207Z","comments":true,"path":"2018/09/20/how-dynamic-agents-work/","link":"","permalink":"https://www.battleheart.cn/2018/09/20/how-dynamic-agents-work/","excerpt":"","text":"1. 动态代理的工作原理 1.1. 什么是代理 1.2. 什么是动态代理 1.3. 动态代理的原理 1.4. 实现AOP功能的封装和配置 动态代理的工作原理什么是代理比如说我们去租房子，需要通过中介代理来进行看房子，由于代理的手中有大量资源，有大部分房源都在代理手中掌握，所以不需要我们自己去一个一个去找寻，通过这样我们无需知道房东是谁就可以租到合适的房子，这就是代理，代理模式两个优点一是可以隐藏委托类的实现，二是可以实现客户与委托类间的解耦，在不修改委托类代码的情况下能够做一些额外的处理。 什么是动态代理代理类在运行时创建的过程叫做动态代理。也就是说这个代理类不是我们是事先写好的，而是由程序运行时自动生成的代理类，比如我们举一个静态代理例子：我们首先定义一个接口ISayHello 123public interface ISayHello &#123; void sayHello();&#125; 在写一个被代理对象：SayHello，并且继承自上面的接口，并实现接口中的方法。 123456public class SayHello implements ISayHello &#123; @Override public void sayHello() &#123; System.out.printf(\"hello world proxy！\"); &#125;&#125; 接下来是重点我们接下来要写代理类，代理类和被代理类之间是依赖组合关系，也就是说被代理类和代理类是同时存在的，也就是生命周期是一样的。 123456789101112131415161718public class SayProxy implements ISayHello&#123; private SayHello sayHello; public SayProxy() &#123; sayHello=new SayHello(); &#125; @Override public void sayHello() &#123; before(); sayHello.sayHello(); after(); &#125; public void before()&#123; System.out.printf(\"Say Hello Before\"); &#125; public void after()&#123; System.out.printf(\"Say Hello After\"); &#125;&#125; 这样就可以达到动态扩充被代理类的内容，上面的内容是静态的动态代理，也就是代理类是我们已经写好的，接下来我们就要演示如何实现动态代理类。 动态代理的原理 JVM可以在运行期动态生成出类的字节码，这种动态生成的类往往被用作代理类，即动态代理。 JVM生成的代理类必须实现一个或多个接口，所以JVM生成的动态代理类只能用作具有相同接口的目标类代理。 CGLIB库可以生成一个类的子类，一个类的子类也可以用作该类的代理，所以如果要为一个没有实现接口的类生成动态代理类那么可使用CGLIB。 Java提供了相应的代理类java.lang.reflect.Proxy，通过这个类能够动态生成代理类对象，接下来我们来做一下演示： 123456789101112//动态代理相关内容实现Class clazz = Proxy.getProxyClass(Collection.class.getClassLoader(), Collection.class);System.out.println(\"代理类名称：\" + clazz.getName(System.out.println(\"代理类类加载器：\" + clazz.getClassLoader());Constructor[] constructors = clazz.getConstructors();for (Constructor item : constructors) &#123; System.out.println(\"方法名字：\" + item.getName()); Parameter[] parameters = item.getParameters(); for (Parameter parameter : parameters) &#123; System.out.println(\"参数类型：\" + parameter.getParameterizedType() + \"参数名称：\" + parameter.getName()); &#125; &#125;&#125; 首先获取Collection的代理类，Proxy提供了getProxyClass方法来进行获取代理类，这个方法有两个参数，第一个参数是加载这个代理类对象的类加载器，第二个参数是代理类对象实现的接口。我们来看一下输出结果内容： 代理类名称：com.sun.proxy.$Proxy0 代理类类加载器：null 方法名字：com.sun.proxy.$Proxy0 参数类型：interface java.lang.reflect.InvocationHandler 参数名称：arg0 分析一下上面代码内容，首先我们创建了实现Collection接口的动态代理类对象，并返回动态代理类的字节码，这时候我们用反射方式查看一下动态代理对象的构造方法以及动态代理对象的名称和动态代理构造器方法。我们仔细看到加载com.sun.proxy.$Proxy0的类加载器是Bootstrap类加载器，由于Collection加载器就是Bootstrap类加载器。所以返回的是null，因为该类加载器不是java实现的。构造函数的参数类型是InvocationHandler这个接口类型主要是做什么呢？我们接下俩一步一步来进行解密，这里留一下一个小小的悬念。接下来通过反射的方式获取下当前代理类所实现的方法有哪些： 1234Method[] methods = clazz.getMethods();for (Method method : methods) &#123; System.out.println(\"方法名称：\" + method.getName());&#125; 输出的结果如下所示： 12345678910111213141516171819202122232425262728293031方法名称：add 方法名称：remove 方法名称：equals 方法名称：toString 方法名称：hashCode 方法名称：clear 方法名称：contains 方法名称：isEmpty 方法名称：iterator 方法名称：size 方法名称：toArray 方法名称：toArray 方法名称：spliterator 方法名称：addAll 方法名称：stream 方法名称：forEach 方法名称：containsAll 方法名称：removeAll 方法名称：removeIf 方法名称：retainAll 方法名称：parallelStream 方法名称：isProxyClass方法名称：getInvocationHandler 方法名称：newProxyInstance 方法名称：getProxyClass 方法名称：wait 方法名称：wait 方法名称：wait 方法名称：getClass 方法名称：notify 方法名称：notifyAll 由于代理类实现了Collection接口，所以接口中所有类方法都会被继承，还有Object中的方法，当然Object中不是所有方法都会交给代理类来执行，只有hashCode,equals和toString方法会交给代理类处理。也就是说当我们调用collection.getClass()会输出com.sun.proxy.$Proxy0而不是输出目标对象ArrayList，这就说明Object中的方法不是所有方法都派发给目标对象来执行，只有上面说的三个方法才会委托给InvocationHandler中的invoke方法来进行执行。而其他的方法有自己的实现。 到这里我们的动态代理对象字节码分析完毕，这时候我们要创建动态代理的对象实例。我们上面了解到动态代理对象是只有一个构造函数，这个构造函数传递参数是InvocationHandler接口，这时候我们就需要创建一个自己MyInvocationHandler对象实现InvocationHandler接口。 1234567891011121314public class MyInvocationHandler implements InvocationHandler &#123; //代理对象 ArrayList target = new ArrayList(); @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //前置通知 System.out.println(\"方法调用前:\" + method.getName()); //代理对象方法调用 Object o = method.invoke(target, args); //后置通知 System.out.println(\"方法调用后:\" + method.getName()); return o; &#125;&#125; 我们来详细分析下这个接口中的方法，该接口中只有一个方法，也就是invoke方法，这个方法主要是什么作用呢？当我们调用代理类的方法是首先会调用MyInvocationHandler中invoke方法，通过调用这个方法来调用目标对象的方法体。实际上动态代理类实现的方法如下所示，例如我们现在实现的Collection接口的size方法，代理类对象的方法大致实现如下： 12345678910public $Proxy0 implements Collection&#123; InvocationHandler hander; public $Proxy0(InvocationHandler handler)&#123; this.handler=handler; &#125; int size()&#123; return handler.invoke(this,this.getClass().getMethod(“size”),null); &#125;&#125; Handler的invoke 方法三要素：代理对象，代理对象方法，代理对象参数。也就是说代理对象首先先调用我们构造函数中传递的handler对象的invoke方法，通过调用invoke方法来调用目标对象中存在的size方法。这也是Aop的原理，AOP的实现就是用了动态代理的方式进行操作的，目标对象返回的结果就是代理类返回的结果。创建动态代理对象如下所示: 123456Constructor constructor = clazz.getConstructor(InvocationHandler.class);Collection collection = (Collection) constructor.newInstance(new MyInvocationHandler());collection.add(\"111\");collection.add(\"222\");collection.add(\"333\");System.out.println(collection.size()); 这时候输出结果如下所示： 123456789方法调用前:add 方法调用后:add 方法调用前:add 方法调用后:add 方法调用前:add 方法调用后:add 方法调用前:size 方法调用后:size 3 正如我们上面分析的内容，我们来看一下动态代理类内部结构图： 当客户端调用代理对象的方法时，首先先经过InvocationHandler的invoke方法，这个方法体中可以扩充我们想要的内容，比如前置通知，后置通知，参数过滤等一系列操作，然后再通过该方法传入的method调用目标对象的方法，达到代理的作用。 实现AOP功能的封装和配置实现思路是我们在配置文件中配置我们需要代理的目标对象，通知对象，通过配置文件进行切换是否生成代理对象，通过代理对象工厂进行判断是否生成代理类。工厂类BeanFactory负责创建目标类或代理类的实例对象，其getBean方法根据参数字符串返回一个响应的实例对象，也就是上面是通过ProxyFactoryBean进行判断是否生成代理对象，如果配置文件中配置的对象为ProxyFactoryBean的话，通过调用ProxyFactoryBean中的getProxy生成代理对象并返回，反之直接创建该对象实例并返回。直接上代码首先看一下BeanFactory，主要是创建代理对象或者非代理对象实例 1234567891011121314151617181920212223242526public class BeanFactory &#123; private Properties properties = new Properties(); //从配置文件中读取相应配置 public BeanFactory(InputStream ips) &#123; try &#123; properties.load(ips); &#125; catch (Exception ex) &#123;&#125; &#125; public Object getBean(String name) &#123; String className = properties.getProperty(name); try &#123; Class clazz = Class.forName(className); Object bean = clazz.newInstance(); if (bean instanceof ProxyFactoryBean) &#123; ProxyFactoryBean proxyFactoryBean = (ProxyFactoryBean) bean; String tagertClassName = properties.getProperty(name + \".target\"); Class tagertClazz = Class.forName(tagertClassName); String adviceClassName = properties.getProperty(name + \".advice\");Class adviceClazz = Class.forName(adviceClassName); proxyFactoryBean.setAdvice((Advice)adviceClazz.newInstance()); proxyFactoryBean.setTarget(tagertClazz.newInstance()); return proxyFactoryBean.getProxy(); &#125; return bean; &#125;catch (Exception ex)&#123; System.out.println(ex.getMessage()); &#125; return null; &#125;&#125; 代码主要内容是首先构造函数是InputStream流用来加载properties配置文件的内容，配置相关内容如下： 123xxx=com.test.Aop.ProxyFactoryBeanxxx.advice=com.test.Aop.MyAdvicexxx.target=java.util.ArrayList xxx也就是我们要获取的bean对象，如果对象类型为ProxyFactoryBean的话，就给该对象设置代理对象和通知对象。接下来我们看看ProxyFactoryBean中到底做了什么东西？前面我们已经提到了ProxyFactoryBean主要是创建代理对象。 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 获得代理类 * Created by battleheart on 2017/6/29. */public class ProxyFactoryBean &#123; //代理对象 private Object target; //Advice通知 private Advice advice; //获取代理对象 public Object getProxy() &#123; Object proxy = (Object) Proxy.newProxyInstance(getTarget().getClass().getClassLoader(), getTarget().getClass().getInterfaces(), new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; getAdvice().before(); Object result = method.invoke(getTarget(), args); getAdvice().after(); return result; &#125; &#125; ); return proxy; &#125; public Object getTarget() &#123; return target; &#125; public void setTarget(Object target) &#123; this.target = target; &#125; public Advice getAdvice() &#123; return advice; &#125; public void setAdvice(Advice advice) &#123; this.advice = advice; &#125;&#125; target主要是目标代理对象，也就是我们要代理的目标对象，Advice对象主要是我们的通知对象，通知对象中只包含前置通知和后置通知这两个。主要是getProxy获取代理对象这个方法。 12345678910111213141516public Object getProxy() &#123; Object proxy = (Object) Proxy.newProxyInstance(getTarget().getClass().getClassLoader(), getTarget().getClass().getInterfaces(), new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; getAdvice().before(); Object result = method.invoke(getTarget(), args); getAdvice().after(); return result; &#125; &#125; ); return proxy;&#125; 这个方法中我们可以看到直接调用了Proxy.newProxyInstance方法，而不再是调用Proxy.getClassProxy这个方法获取字节码的方式，这就告诉我们Proxy的创建可以分为两种方式进行创建，这种方式比较简便，方法中有三个参数第一个参数指定类加载器，第二个参数是代理对象要实现的接口有哪些，第三个方法就是InvocationHandler，这里我们传入的参数目标类的加载器，以及目标类实现的接口，第三个参数我们这边才用的是匿名内部类的方式传递。其中Invoke方法中要调用目标对象的方法，也就是method.invoke(target,args);接下来我们看一下通知类Advice中写了什么内容。首先我们声明了接口Advice 123456789/** * Created by battleheart on 2017/6/29. */public interface Advice &#123; //前置通知 void before(); //后置通知 void after();&#125; 又写了MyAdvice类继承并实现Advice接口： 1234567891011121314151617/** * Created by battleheart on 2017/6/29. */public class MyAdvice implements Advice &#123; public MyAdvice() &#123; &#125; @Override public void before() &#123; System.out.println(\"前置通知\"); &#125; @Override public void after() &#123; System.out.println(\"后置通知\"); &#125;&#125; 通知方法中没有写太多东西就是输出一些信息表示已经应用了通知内容。接下来就是调用方法： 123456789InputStream ips = TestApplication.class.getClassLoader().getResourceAsStream(\"application.properties\");Object bean = new com.test.Aop.BeanFactory(ips).getBean(\"xxx\");Collection collection = (Collection) bean;collection.add(\"111\");collection.add(\"222\");collection.add(\"333\");collection.add(\"444\");System.out.println(collection.size());System.out.println(bean.getClass().getName()); 由于我是用Spring boot 搭建的项目所以配置文件名称为application.properties，这个不重要，重要的是配置文件内容，上面我已经提到了第一种配置内容为 123xxx=com.test.Aop.ProxyFactoryBean xxx.advice=com.test.Aop.MyAdvice xxx.target=java.util.ArrayList 当我们调用getBean获取xxx时，如果xxx配置为ProxyFactoryBean的话就会创建代理类我们看一下输出内容： 123456789101112前置通知后置通知前置通知后置通知前置通知后置通知前置通知后置通知前置通知后置通知4com.sun.proxy.$Proxy0 最后输出内容为￥Proxy0表示创建代理对象成功，并调用了通知方法，如果配置文件修改为如下： 1xxx= java.util.ArrayList 输出内容则为： 124java.util.ArrayList 因为没有创建代理对象所以获取类型是返回ArrayList类型。完结","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.battleheart.cn/tags/Java/"}],"author":"BattleHeart"},{"title":"我的blog之旅又要开始了","slug":"hello-world","date":"2018-09-17T16:00:00.000Z","updated":"2018-10-01T13:22:26.257Z","comments":true,"path":"2018/09/18/hello-world/","link":"","permalink":"https://www.battleheart.cn/2018/09/18/hello-world/","excerpt":"","text":"1距离我的个人博客服务器到期到现在也有一段时间了，这段时间里面已经停止了些东西，最近要把写文章这件事慢慢的拾起来，制定写作计划。 博客主要内容博客主要内容是针对技术的分享与交流，主要技术有spring，spring boot，spring cloud，java，mybatis等技术框架的技术分享，也业余分享\bpython等，大数据相关技术的内容的文章。","categories":[{"name":"生活杂谈","slug":"生活杂谈","permalink":"https://www.battleheart.cn/categories/生活杂谈/"}],"tags":[{"name":"Life","slug":"Life","permalink":"https://www.battleheart.cn/tags/Life/"}],"author":"BattleHeart"},{"title":"带你走进git-远程仓库","slug":"git-learning-5-remote","date":"2016-01-14T13:22:19.000Z","updated":"2019-04-11T08:13:51.353Z","comments":true,"path":"2016/01/14/git-learning-5-remote/","link":"","permalink":"https://www.battleheart.cn/2016/01/14/git-learning-5-remote/","excerpt":"","text":"一、文件，指令讲解首先讲一下远程仓库和本地仓库在文件上面的区别，首先我们来看下对比图（当然这里说的区别是在于.git文件下面的文件内容，至于里面内容我们不会关注）這裡我们进行了相同的操作就是本地仓库里面新建了version.txt内容也是一样的v1.0： 图一为本地仓库，图二为克隆的远程仓库，首先我们应该看一下config里面的区别： 很容易看到了区别就是图四为远程仓库内容。 从这个文件中我们可以了解到： 本地库的当前分支为master，其关联的远程库名称为origin（不同的名称可以指向同一个远程库，参见git remote命令） 远程库origin所在的位置为(URL)：https://github.com/dwlsxj/BattleHeart.git然后进行了version.txt的编辑和提交。这是我们刚才新建version.txt（远程）以及再添加内容为“v1.0”，在添加到暂存区，提交到本地提交中，最后提交到远程服务器，下面是我们生成的commit对象和git对象还有就是tree对象内容： 1234$ find .git/objects/ -type f.git/objects/18/6c4629f6de8c956548570a113fa181d9b22692 commit对象.git/objects/90/e34626d7993cf8d6c5e3e458744df4a9a31594 tree对象.git/objects/c6/94c68edd99aeefa053f25308cd71ecca922036 blob对象 接下来我们就来看一下这个commit对象和tree对象下面的树分支和commit的指向内容。 1234567891011121314151617181920$ git cat-file -t 186c46commit$ git cat-file -t 90e346tree$ git cat-file -t c694c6blob$ git cat-file -p 186c46tree 90e34626d7993cf8d6c5e3e458744df4a9a31594author BattleHeart &lt;dwlsxj@126.com&gt; 1452303321 +0800committer BattleHeart &lt;dwlsxj@126.com&gt; 1452303321 +0800inital commit$ git cat-file -p 90e346100644 blob c694c68edd99aeefa053f25308cd71ecca922036 version.txt$ git cat-file -p c694c6V1.0 当我们git push origin master（命令格式：git push [remote-name] [branch-name]）时候会生成一个我们会发现.git/refs/文件夹下多了一个remote文件夹 我们跟进去看一下会有一个默认origin服务器名称，下面会有一个master分支，也就是这个代表的是远程服务器的master分支并不代表我们本地的master分支。看一下这个master分支内容和本地分支的内容是否一致，因为我们刚才将提交的内容提交到origin服务器上，应该两个分支引用指向的commit记录是一样的。 12345$ find .git/objects/ -type f.git/objects/18/6c4629f6de8c956548570a113fa181d9b22692.git/objects/90/e34626d7993cf8d6c5e3e458744df4a9a31594.git/objects/9f/aadaec6f7c8657372544e6f414f9b0b6910279.git/objects/c6/94c68edd99aeefa053f25308cd71ecca922036 提交到本地版本控制中。 123$ git commit -m &apos;second commit version.txt&apos;[master 5777c82] second commit version.txt1 file changed, 1 insertion(+) 提交之后产生的commit对象和新的tree对象内容 1234567$ find .git/objects/ -type f.git/objects/18/6c4629f6de8c956548570a113fa181d9b22692.git/objects/57/77c8270e24ff7417fa6f8d27f73c068acd42b0.git/objects/90/e34626d7993cf8d6c5e3e458744df4a9a31594.git/objects/9f/aadaec6f7c8657372544e6f414f9b0b6910279.git/objects/a4/3a49679a6ecd3cbcdd889aeb9906b8620e7976.git/objects/c6/94c68edd99aeefa053f25308cd71ecca922036 看一下了两个master分支内容： 12345$ cat .git/refs/heads/master5777c8270e24ff7417fa6f8d27f73c068acd42b0$ cat .git/refs/remotes/origin/master186c4629f6de8c956548570a113fa181d9b22692 啊哈，果然不出我们所料，这就是说明本地提交的记录还没有提交的远程服务器上面所以说这个远程服务器的master分支还是指向了原来的commit对象。当我们使用的了git fetch [remote-name]从服务器里面拉去数据的时候会产生一个FETCH_HEAD指针。这个命令会访问远程仓库，从中拉取所有你还没有的数据。 执行完成后，你将会拥有那个远程仓库中所有分支的引用，可以随时合并或查看。这时候我们会发现有一个FETCH_HEAD指针是一个指向远程最后一次获取的指针位置。首先我们看一下这个FETCH_HEAD指针的主要作用： 也就是说我们每次获取的本地没有的文件后都会有一个fetch_HEAD，这个指针和本地的HEAD指针有着区别，这样我们现在还看不出来因为本地和服务器上的记录都是一样的。这时候我们来在服务器上面添加一个readme文件提交上去，再在本地获取。添加readme文件这里是在服务器上直接提交的记录，所以跟本地数据没有任何关系。 当我们使用git fetch origin命令的之后，我们来看一下.git/objects在服务器上产生的新的commit记录和tree对象还有git对象内容。 12345678910$ find .git/objects/ -type f.git/objects/18/6c4629f6de8c956548570a113fa181d9b22692.git/objects/50/204399d2b99a020ac03dbca151570a959b7523.git/objects/56/f565ecbaa66b236c42914bfd7e93a5eb0844f7.git/objects/57/77c8270e24ff7417fa6f8d27f73c068acd42b0.git/objects/90/e34626d7993cf8d6c5e3e458744df4a9a31594.git/objects/9f/aadaec6f7c8657372544e6f414f9b0b6910279.git/objects/a4/3a49679a6ecd3cbcdd889aeb9906b8620e7976.git/objects/c6/94c68edd99aeefa053f25308cd71ecca922036.git/objects/e0/26393257f8b7519ac7c378c6ff470ca737fe10 这里面有三个对象是git fetch后新增加的就是如下几个，然后我们通过查看其类型以及其中的内容就能看到确实是从服务器上拉取出来的数据。 1234567891011121314151617181920212223242526$ git cat-file -t 502043commit$ git cat-file -p 502043tree e026393257f8b7519ac7c378c6ff470ca737fe10parent 186c4629f6de8c956548570a113fa181d9b22692author BattleHeart &lt;dwlsxj2013@hotmail.com&gt; 1452324317 +0800committer BattleHeart &lt;dwlsxj2013@hotmail.com&gt; 1452324317 +0800Create commit ReadmeCreate commit Readme$ git cat-file -t 56f565blob$ git cat-file -p 56f565# BattleHeartREADME$ git cat-file -t e02639tree$ git cat-file -p e02639100644 blob 56f565ecbaa66b236c42914bfd7e93a5eb0844f7 README.md100644 blob c694c68edd99aeefa053f25308cd71ecca922036 version.txt 其实这时候我们来看一下git的历史记录图。 这里的lol命令是我取的别名log –oneline –decorate –graph –all。可以看到这个命令分了两个，就是说origin/master是服务器的master分支。我们来看一下master分支。 12345$ cat .git/refs/heads/master 本地分支引用5777c8270e24ff7417fa6f8d27f73c068acd42b0$ cat .git/refs/remotes/origin/master 服务器master分支引用50204399d2b99a020ac03dbca151570a959b7523 也就是说本地分支引用是没有变化的，变化的是服务器master分支引用的地址从186c46变化到了最新的502043这个commit提交记录上面了。其实这之后FETCH_HEAD也会将最新的commit记录在里面（这里不是指向master分支上而是指向了commit记录上面），也就是说FETCH_HEAD指的是: 某个branch在服务器上的最新状态。其中每一行对应于远程服务器的一个分支.当前分支指向FETCH_HEAD, 就是这个文件第一行对应的那个分支。这里服务器里面只有一个master分支是默认的分支。 虽然说拉去出来的数据但是并不是我们想要的，拉去的数据并没有放在本地仓库指向的内容里面而是服务器分支指向的内容里面。这时候我们是用git merge来进行合并。也就是说这个FETCH_HEAD里面存在的是服务器上每一个分支上面最后一个提交记录内容，当然我们也可以使用git merge FETCH_HEAD这个命令来合并分支，但是多条分支记录的时候他只会取出第一条merge记录。这时候我们就需要使用服务器的分支来进行合并了，比如origin/test指针就可以git merge origin/test。这与后面要讲的git pull的区别就是从服务器上面获取下来的内容分支之类的不会直接合并到本地，而是自己去合并但是git pull是git pull = git fetch + git merge的操作。 git pull命令：接下来我们就来演示下git pull内容，首先我们在服务上面新建了一个空的仓库，把这个空的仓库拉到本地来，新建一个文件a，在文件a里面添加一条记录this is file a on local master，把他提交到本地仓库里面，我们看一下如下操作：新建一个文件a并赋值。 1$ echo &apos;this is file a on local master&apos; &gt; a 看一下文件内容 12$ cat athis is file a on local master 添加到暂存区内将添加的文件 1$ git add . 将文件添加版本记录中去。 1234567$ git commit -m &apos;local first commit&apos;[master (root-commit) 7358cc0] local first commitwarning: LF will be replaced by CRLF in a.The file will have its original line endings in your working directory.1 file changed, 1 insertion(+)create mode 100644 a 这时候看一下产生的对象 1234$ find .git/objects/ -type f.git/objects/34/da50374fa7eaa9d2ea609198237ed8af97c7e9.git/objects/73/58cc0797e6bf72393ab54c543c6261784c27dc.git/objects/7e/8f2d0c90cdd5dffd9bfb5f32604f74199725e4 分别查看一下这些对象的类型以及对象的内容： 123456789101112131415$ git cat-file -t 34da50tree$ git cat-file -p 34da50100644 blob 7e8f2d0c90cdd5dffd9bfb5f32604f74199725e4 a$ git cat-file -p 7e8f2dthis is file a on local master$ git cat-file -p 7358cctree 34da50374fa7eaa9d2ea609198237ed8af97c7e9author BattleHeart &lt;dwlsxj@126.com&gt; 1452330539 +0800committer BattleHeart &lt;dwlsxj@126.com&gt; 1452330539 +0800local first commit 这时候我们将新的文件提交到服务器上面。 123456$ git push origin masterCounting objects: 3, done.Writing objects: 100% (3/3), 235 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)To https://github.com/dwlsxj/test.git* [new branch] master -&gt; master OK提交成功了，这时候.git/refs就会生成一个remote文件文件里面有默认服务器名称origin文件夹，该文件夹下面保存了服务器上最新的master分支指向的内容。让我们来看一下： 12345$ cat .git/refs/remotes/origin/master 服务器master分支7358cc0797e6bf72393ab54c543c6261784c27dc$ cat .git/refs/heads/master 本地master分支7358cc0797e6bf72393ab54c543c6261784c27dc 这时候是一样的，因为服务器分支和本地分支是一样的。接下来我们在服务器分支上面修改下a文件如下图所示： 这时候我们会想到服务器上面会产生commit记录这时候服务器的master分支的指向就不再是本地这个指向了。这时候我们也来修改下本地的a文件。添加文本内容为this is file a on local master second edit。提交到版本控制中。看一下所有的操作内容:编辑文件a 1$ vim a 将a文件添加到暂存区内容 123$ git add .warning: LF will be replaced by CRLF in a.The file will have its original line endings in your working directory. 看一下新生成的git对象内容 12345$ find .git/objects/ -type f.git/objects/34/da50374fa7eaa9d2ea609198237ed8af97c7e9.git/objects/73/58cc0797e6bf72393ab54c543c6261784c27dc.git/objects/7e/8f2d0c90cdd5dffd9bfb5f32604f74199725e4.git/objects/af/cc87af98402de78840dc0737700a62345abff4 将修改的a文件提交到记录里面。 1234567$ git commit -m &apos;local second commit on master&apos;[master warning: LF will be replaced by CRLF in a.The file will have its original line endings in your working directory.de7c4cd] local second commit on masterwarning: LF will be replaced by CRLF in a.The file will have its original line endings in your working directory.1 file changed, 1 insertion(+) 这时候我们来看一下提交记录的图，这时候HEAD指针是指向最新的master分支的，但是服务器的master分支则是指向原有的commit记录。 123$ git lol* de7c4cd (HEAD -&gt; master) local second commit on master* 7358cc0 (origin/master) local first commit 看一下产生的tree对象以及tree对象内容，还有commit对象。 12345678910111213141516171819202122232425$ find .git/objects/ -type f.git/objects/34/da50374fa7eaa9d2ea609198237ed8af97c7e9.git/objects/66/e33f7b7a44ad93bcb3a049075e666b9041f63c.git/objects/73/58cc0797e6bf72393ab54c543c6261784c27dc.git/objects/7e/8f2d0c90cdd5dffd9bfb5f32604f74199725e4.git/objects/af/cc87af98402de78840dc0737700a62345abff4.git/objects/de/7c4cd49e32f197afc6161d0d6f5e6d413212c8$ git cat-file -t 66e33ftree$ git cat-file -p 66e33f100644 blob afcc87af98402de78840dc0737700a62345abff4 a$ git cat-file -p afcc87this is file a on local masterthis is file a on local master second edit$ git cat-file -p de7c4ctree 66e33f7b7a44ad93bcb3a049075e666b9041f63cparent 7358cc0797e6bf72393ab54c543c6261784c27dcauthor BattleHeart &lt;dwlsxj@126.com&gt; 1452331483 +0800committer BattleHeart &lt;dwlsxj@126.com&gt; 1452331483 +0800local second commit on master OK，到了这里我们就要开始见证奇迹的时候到了，因为我们同时修改了a文件都是从第一次提交的commit记录里面衍生出来的（服务器上和本地提交），接下来就是见证奇迹了。 12345678910$ git pull originremote: Counting objects: 3, done.remote: Compressing objects: 100% (2/2), done.remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0Unpacking objects: 100% (3/3), done.From https://github.com/dwlsxj/test7358cc0..67f70c5 master -&gt; origin/masterAuto-merging aCONFLICT (content): Merge conflict in aAutomatic merge failed; fix conflicts and then commit the result. Pull之后我们先不着急看a文件的内容，我们先来看一下生成的对象内容。 1234567891011$ find .git/objects/ -type f.git/objects/34/da50374fa7eaa9d2ea609198237ed8af97c7e9.git/objects/59/7f7359a768d3e98b65cd8b1558e09489d920b3.git/objects/66/e33f7b7a44ad93bcb3a049075e666b9041f63c.git/objects/67/f70c522e9e5b748445abbb41ea0cfa0fd171f9.git/objects/73/58cc0797e6bf72393ab54c543c6261784c27dc.git/objects/7e/8f2d0c90cdd5dffd9bfb5f32604f74199725e4.git/objects/af/cc87af98402de78840dc0737700a62345abff4.git/objects/de/7c4cd49e32f197afc6161d0d6f5e6d413212c8.git/objects/de/fb97746b25d3963454d4ff69fc903956b12075.git/objects/f5/537ea43f681442d2656105a2f348284181ef95 接下来就要看一下新增加的对象内容，其实我们猜想就能才想到肯定有三个对象是git对象和commit对象、tree对象因为这是在服务器上提交记录产生的。那么还多一个对象是什么呢？我们来看一下吧。 123Administrator@USER-20150201IC MINGW64 ~/Desktop/rrr/test (master|MERGING)$ git cat-file -t 597f73 该对象是服务器上提交内容对象blob 对象的内容如下 1234Administrator@USER-20150201IC MINGW64 ~/Desktop/rrr/test (master|MERGING)$ git cat-file -p 597f73this is file a on local masterthis is file a on server master 接下来67f70c是提交记录，是和上面blob一起的 1234567891011121314Administrator@USER-20150201IC MINGW64 ~/Desktop/rrr/test (master|MERGING)$ git cat-file -t 67f70ccommitAdministrator@USER-20150201IC MINGW64 ~/Desktop/rrr/test (master|MERGING)$ git cat-file -p 67f70ctree f5537ea43f681442d2656105a2f348284181ef95parent 7358cc0797e6bf72393ab54c543c6261784c27dcauthor BattleHeart &lt;dwlsxj2013@hotmail.com&gt; 1452330567 +0800committer BattleHeart &lt;dwlsxj2013@hotmail.com&gt; 1452330567 +0800this is file a on server masterthis is file a on server master 接下来是tree对象内容，都是服务器上第二次提交产生的。 12345678Administrator@USER-20150201IC MINGW64 ~/Desktop/rrr/test (master|MERGING)$ git cat-file -t f5537eatree$ git cat-file -p f5537ea100644 blob 597f7359a768d3e98b65cd8b1558e09489d920b3 a$ git cat-file -t defb97blob 哎呦，这个对象叼了，这个对象是在本地产生的，产生的冲突文件，我们会发现我没有将Administrator这一行去掉是因为我们现在文件是由冲突的，我们可以看到master|MERGING 12345678Administrator@USER-20150201IC MINGW64 ~/Desktop/rrr/test (master|MERGING)$ git cat-file -p defb97this is file a on local master&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADthis is file a on local master second edit=======this is file a on server master&gt;&gt;&gt;&gt;&gt;&gt;&gt; 67f70c522e9e5b748445abbb41ea0cfa0fd171f9 那么下来我们看一下commit的图是如何的： 我们发现origin/master分支指向也更新为了最新的记录。并且现在还是两个分支，因为还有冲突没有解决。这时候我们需要解决冲突在提交就好了。 并将其提交到记录里面这时候我们就会发现最后的commit图就合并到了一起。 12345678910111213141516171819Administrator@USER-20150201IC MINGW64 ~/Desktop/rrr/test (master|MERGING)$ git add .$ git commit -m &apos;merge&apos;[master 0dd66df] mergeAdministrator@USER-20150201IC MINGW64 ~/Desktop/rrr/test (master)$ git lol* 0dd66df (HEAD -&gt; master) merge|\\| * 67f70c5 (origin/master) this is file a on server master* | de7c4cd local second commit on master|/* 7358cc0 local first commit 最后来一张图清晰地告诉大家git fetch和git push的区别。 二、结束语本篇文章分析完毕，希望各位能够喜欢并且指正里面的错误，分析的有不正确的就指出来。谢谢啦。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.battleheart.cn/tags/Git/"}]},{"title":"带你走进git-重写历史记录","slug":"git-learning-4-rewriting-history","date":"2016-01-14T07:19:19.000Z","updated":"2019-04-11T08:14:02.542Z","comments":true,"path":"2016/01/14/git-learning-4-rewriting-history/","link":"","permalink":"https://www.battleheart.cn/2016/01/14/git-learning-4-rewriting-history/","excerpt":"","text":"一、git对象文件创建开篇先补充一个知识点，就是比如我建立一个文件之后，使用git add就会生成一个git对象，但是git对象生成后可以在.git/objects里面对应，首先我们来初始化一个仓库git init。 1$ git init 然后我们来创建两个文件文件名分别为a和b。 1$ touch a b 将a文件添加到暂存区，然后再将b添加到暂存区，我们会想到这时候有两个git对象产生，但是git对象对应.git/objects文件。 12345678$ git add .$ find .git/objects/.git/objects/.git/objects/e6.git/objects/e6/9de29bb2d1d6434b8b29ae775ad8c2e48c5391.git/objects/info.git/objects/pack 我们来查看下.git/objects文件下面会产生几条git对象库。这时候超出了我们想象，我们认为对象文件也应该创建两个但是仅仅创建了一个，这是为什么呢？那么着一个文件又指的是什么呢？ 123$ git cat-file -t e69de29bb2d1d6434b8b29ae775ad8c2e48c5391blob 上述命令查看了当前sha-1是git对象（blob）。这时候我们根本就看不出来这个a和b的存放位置。我们将暂存区的文件提交到记录中，git commit –m “initial commit” 12345$ git commit -m &apos;initial commit&apos;[master (root-commit) 5b077dd] initial commit2 files changed, 0 insertions(+), 0 deletions(-)create mode 100644 acreate mode 100644 b 这时候我们再来看一下.git/object文件下内容，产生了一个tree对象和commit对象，这个commit对象指向了tree对象。 12345678910$ find .git/objects/.git/objects/.git/objects/29.git/objects/29/6e56023cdc034d2735fee8c0d85a659d1b07f4.git/objects/5b.git/objects/5b/077ddc03fa28dff8a1ac0d85969fcc2ac40c0b.git/objects/e6.git/objects/e6/9de29bb2d1d6434b8b29ae775ad8c2e48c5391.git/objects/info.git/objects/pack 分别查看下各自的对象类型： 123456$ git cat-file -t 296e56023cdc034d2735fee8c0d85a659d1b07f4Tree$ git cat-file -t 5b077ddc03fa28dff8a1ac0d85969fcc2ac40c0bCommit$ git cat-file -t e69de29bb2d1d6434b8b29ae775ad8c2e48c5391Blob 那么这时候我们要查看一下tree对象里面的内容，应该是a和b分别创建的git对象。 12345$ git cat-file -p 296e56023cdc034d2735fee8c0d85a659d1b07f4100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 a100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 b OK，我们到了这里才看到了，原来产生的两个git对象都存放在了e6/9de29bb2d1d6434b8b29ae775ad8c2e48c5391这个文件里面，接下来我要讲一下为什么会存放在一起。首先来说一下sha-1的生成，一个将待存储的数据外加一个头部信息（header）一起做 SHA-1 校验运算而得的校验和，也就是说我们创建一个文件a他会根据文件a里面的数据和头部信息拼在一起生成一个sha-1的值，这个头部信息是固定的，如下图所示： 正因为a和b文件的内容一样都是blob空文本所以生成sha-1是一样的所以会放在一个文件里面。 二、重写历史记录以下的命令帮我们重写历史记录 git commit –amend可以产生一个新的提交用来替换掉当前所提交的这个commit git rebase 维护线性历史 git reset比如说我们做了一个合并的提交我们想要撤销掉提交然历史记录跟没有产生这样的历史记录一个合并 git reflog它维护了一个HEAD引用的历史信息，通常配合git reset来使用 三、指令详解 git commit –amend有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。 此时，可以运行带有–amend 选项的提交命令尝试重新提交：新建两个文件a和b这时候我们只提交一个文件a到暂存区里面 12touch a b$ git add a 提交a文件到暂存区内这时候我们就要来看一下生成的对象以及对象类型。 123456$ find .git/objects/.git/objects/.git/objects/e6.git/objects/e6/9de29bb2d1d6434b8b29ae775ad8c2e48c5391.git/objects/info.git/objects/pack 发现生成了一个e6的文件夹和9de29bb2d1d6434b8b29ae775ad8c2e48c5391文件名的文件。 12$ git cat-file -t e69de29bb2d1d6434b8b29ae775ad8c2e48c5391blob 查看下新生成对象的类型是git对象blob。接下来我们将a文件进行提交到记录里面去。 12345$ git commit -m &apos;commit file a&apos;[master (root-commit) 96696f0] commit file a1 file changed, 0 insertions(+), 0 deletions(-)create mode 100644 a提交完成后，我们再来看一下.git/objects文件下面的内容。 12345678910$ find .git/objects/.git/objects/.git/objects/49.git/objects/49/6d6428b9cf92981dc9495211e6e1120fb6f2ba.git/objects/96.git/objects/96/696f06370488cc9b271dbd870d8ba0d4e7ce3c.git/objects/e6.git/objects/e6/9de29bb2d1d6434b8b29ae775ad8c2e48c5391.git/objects/info.git/objects/pack 分别查看下96696f和496d64的对象类型。 12345$ git cat-file -t 496d6428b9cf92981dc9495211e6e1120fb6f2batree$ git cat-file -t 96696f06370488cc9b271dbd870d8ba0d4e7ce3ccommit 这时候确定了96696f为commit对象，那么496d64就是tree对象。查看下他们的内容。 123456$ git cat-file -p 96696f06370488cc9b271dbd870d8ba0d4e7ce3ctree 496d6428b9cf92981dc9495211e6e1120fb6f2baauthor BattleHeart &lt;dwlsxj@126.com&gt; 1452085041 +0800committer BattleHeart &lt;dwlsxj@126.com&gt; 1452085041 +0800 commit file a commit对象内容下面是指向496d64这个tree对象，并且有作者和提交时写的提交信息。 12$ git cat-file -p 496d6428b9cf92981dc9495211e6e1120fb6f2ba100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 a Tree对象内容则是他的叶子内容，因为我们只提交了a文件所以只有a文件这个内容。这时候我们发现应该a文件和b文件一起提交而不是分开提交，这时候就是用到接下来的命令–amend命令。那么首先要做的就先把b文件放到暂存区理面 1$ git add b 这时候再使用git commit –amend就会将暂存区的文件一起提交 1$ git commit –amend 当我们输入的时候git commit –amend命令后我们先不着急操作，我们先来看一下产生的文件内容.git/objects文件里面。 12345$ find .git/objects/ -type f.git/objects/29/6e56023cdc034d2735fee8c0d85a659d1b07f4.git/objects/49/6d6428b9cf92981dc9495211e6e1120fb6f2ba.git/objects/96/696f06370488cc9b271dbd870d8ba0d4e7ce3c.git/objects/e6/9de29bb2d1d6434b8b29ae775ad8c2e48c5391 会新生成一个296e56这样一个对象。那么这个对象是什么呢？我们来仔细观察下。 123456$ git cat-file -t 296e56023cdc034d2735fee8c0d85a659d1b07f4tree$ git cat-file -p 296e56023cdc034d2735fee8c0d85a659d1b07f4100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 a100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 b 啊哈，原来是个tree对象当然这里同样也产生了blob对象只是内容和a内容一样所以合并成一个文件了，因为296e56树下面有两个子节点。 我们这时候再进行填写注释，我们会发现我上一次提交的信息他给展现出来了，这里我们可以修改成first commit。当我们保存退出后就会产生如下输出信息： 123456$ git commit --amend[master 433aedb] first commitDate: Wed Jan 6 20:57:21 2016 +08002 files changed, 0 insertions(+), 0 deletions(-)create mode 100644 acreate mode 100644 b 这回我们再来看一下.git/objects里面内容。 1234567891011121314$ find .git/objects/.git/objects/.git/objects/29.git/objects/29/6e56023cdc034d2735fee8c0d85a659d1b07f4.git/objects/43.git/objects/43/3aedb274b59386535efa27c874d1ff5ded4a9b.git/objects/49.git/objects/49/6d6428b9cf92981dc9495211e6e1120fb6f2ba.git/objects/96.git/objects/96/696f06370488cc9b271dbd870d8ba0d4e7ce3c.git/objects/e6.git/objects/e6/9de29bb2d1d6434b8b29ae775ad8c2e48c5391.git/objects/info.git/objects/pack 多出来了一个433aed对象，那么这个对象是什么东西呢？以及里面存放的东西是什么？ 123456789$ git cat-file -t 433aedb274b59386535efa27c874d1ff5ded4a9bcommit $ git cat-file -p 433aedb274b59386535efa27c874d1ff5ded4a9btree 296e56023cdc034d2735fee8c0d85a659d1b07f4author BattleHeart &lt;dwlsxj@126.com&gt; 1452085041 +0800committer BattleHeart &lt;dwlsxj@126.com&gt; 1452085549 +0800first commit 我们看到了这个是个commit对象并且这个commit对象指向了新生成的树对象，以及commit对象没有父节点也就是说本次提交相当于第一次提交。 git rebase新建两个文件a和b文件，添加文件a的内容为this is file a，添加文件内容b为this is file b。并将其添加到暂存区内。 git add .添加到暂存区内，查看一下.git/objects里面的内容，会产生两个git对象，对象类型为blob。 123456789$ git add .$ find .git/objects/.git/objects/.git/objects/77.git/objects/77/486f708f7f7a0dab6f951148b75365081fcc3c.git/objects/ba.git/objects/ba/f5b90e3bc9f0c775c8d52764d353212259ffb3.git/objects/info.git/objects/pack 查看下git对象的类型以及git对象下的内容。 1234567891011$ git cat-file -t 77486f708f7f7a0dab6f951148b75365081fcc3cblob$ git cat-file -t baf5b90e3bc9f0c775c8d52764d353212259ffb3blob$ git cat-file -p baf5b90e3bc9f0c775c8d52764d353212259ffb3this is file a$ git cat-file -p 77486f708f7f7a0dab6f951148b75365081fcc3cthis is file b 将两个文件同时提交到记录里面。Git commit 123456789$ git commit -m &apos;first commit&apos;[master (root-commit) 4bd85c6] first commitwarning: LF will be replaced by CRLF in a.The file will have its original line endings in your working directory.warning: LF will be replaced by CRLF in b.The file will have its original line endings in your working directory.2 files changed, 2 insertions(+)create mode 100644 acreate mode 100644 b 这时候我们来看一下objects文件下内容。 123456789101112$ find .git/objects/.git/objects/.git/objects/4b.git/objects/4b/d85c6b6ed389f268ca7c183e560fb9cb33430e.git/objects/77.git/objects/77/486f708f7f7a0dab6f951148b75365081fcc3c.git/objects/ba.git/objects/ba/f5b90e3bc9f0c775c8d52764d353212259ffb3.git/objects/bd.git/objects/bd/887f9b4dc0d570bd7cae7e604e0da5dd3f466a.git/objects/info.git/objects/pack 这时候会多两个文件。 12345$ git cat-file -t bd887fTree$ git cat-file -t 4bd85cCommit 这时候整体记录的内容结构如下图所示： 这时候我们新建一个分支test，并切换到test分支上面，在分支上面修改下a文件内容添加内容。 1$ git branch test 这时候结构是这个样子的。 这时候我们要在master分支上面修改下a文件并且提交a文件内容，这时候会产生新的commit对象以及tree对象和新生成git对象。首先我们要做到在master分值上面先修改下a文件然后commit到记录里面，然后在修改下b文件在提交到记录里面。这是会产生两条记录让我们来看一下：首先做的就是添加a文件内容为this is master branch，并且添加到暂存区。 123$ vim a$ git add . 在来查看下新生成的git对象（blob），这个对象的sha-1为a4cb8b4（与上次对比） 1234567891011121314$ find .git/objects/.git/objects/.git/objects/4b.git/objects/4b/d85c6b6ed389f268ca7c183e560fb9cb33430e.git/objects/77.git/objects/77/486f708f7f7a0dab6f951148b75365081fcc3c.git/objects/a4.git/objects/a4/cb8b4e0819ae97811f650886390e17e54bc93c.git/objects/ba.git/objects/ba/f5b90e3bc9f0c775c8d52764d353212259ffb3.git/objects/bd.git/objects/bd/887f9b4dc0d570bd7cae7e604e0da5dd3f466a.git/objects/info.git/objects/pack 查看下a4cb8b4类型是blob那么查看下当前文件下的内容正是我们添加的内容一致。 123456$ git cat-file -t a4cb8b4blob$ git cat-file -p a4cb8b4this is file athis is master branch 这时候提交到版本控制里面去，将修改的文件a。 1234567$ git commit -m &apos;master commit&apos;[master warning: LF will be replaced by CRLF in a.The file will have its original line endings in your working directory.a6bcbb7] master commitwarning: LF will be replaced by CRLF in a.The file will have its original line endings in your working directory.1 file changed, 1 insertion(+) 当然提交上去的时候这时候必然会产生commit对象和新的tree对象。让我们看一下谁是commit对象，谁是tree对象。 12345678$ find .git/objects/ -type f.git/objects/4b/d85c6b6ed389f268ca7c183e560fb9cb33430e.git/objects/77/486f708f7f7a0dab6f951148b75365081fcc3c.git/objects/a4/cb8b4e0819ae97811f650886390e17e54bc93c.git/objects/ba/f5b90e3bc9f0c775c8d52764d353212259ffb3.git/objects/bd/887f9b4dc0d570bd7cae7e604e0da5dd3f466a.git/objects/99/1f631d3674f37a8595fd782ce9fd57d354103a.git/objects/a6/bcbb77ada043da6df0a55918cac224bae50ef1 这时候我们发现比上一次对象多出了两个对象分别是991f63和a6bcbb，多出了这两个对象，那么我们来看一下这两个对象就是是什么类型的。 123456$ git cat-file -t 991f63tree$ git cat-file -p 991f63100644 blob a4cb8b4e0819ae97811f650886390e17e54bc93c a100644 blob 77486f708f7f7a0dab6f951148b75365081fcc3c b OK，991f63是tree对象，而且tree对象下面的内容中有一个是我们刚修改的a文件的git对象和第一次提交的b文件的git对象。那么a6bcbb就是commit对象，且commit对象的指向是上面的tree对象。 123456789$ git cat-file -t a6bcbbcommit$ git cat-file -p a6bcbbtree 991f631d3674f37a8595fd782ce9fd57d354103aparent 4bd85c6b6ed389f268ca7c183e560fb9cb33430eauthor BattleHeart &lt;dwlsxj@126.com&gt; 1452165520 +0800committer BattleHeart &lt;dwlsxj@126.com&gt; 1452165520 +0800master commit Ok，这时候整体的提交之后的示意图如下所示： 这时候按照上面步骤看一下b的，这时候git对象变成了af379ed，commit对象变成了359118，tree对象变成了73f2e9。下面是操作记录： 这时候生成commit结构图： 接下来就要换做另一个分支了，按照上面的步骤从新来一遍，先修改下a文件，然后提交到暂存区，然后在修改下b文件再提交到暂存区，这里演示和分析过程就不做了。偷个懒，因为和上面分析过程是一样的不在这里做重复说明了，这时候我们会看到一个分支，分支的commit提交记录是这样的。 详细的结构图我也画了一份出来了，这样方便我们对原文本的追踪以及对整体原理的理解，通过分析哪些对象是新生成的那些对象是原有的就能分析出整体的结构走向。下面就上整体详细的分析图。 这时候我们会发现有两个分支出来了，因为我们现在test分支上面，我们使用git rebase master命令来维护一个线性的记录。当我是用vim的时候肯定会产生冲突，这时候我们解决下冲突文件a和b文件再调用git rebase –continue命令即可，这里要详细讲解下合成的原理以及内容，当我git rebase master的时候会产生两个树对象和一个git对象出来，这时候我们的HEAD头部将会切换到master分支上面，也就是说接下来的操作是在master分支指向的最后一个分支上面进行与test分支上面每一个进行合并，这里我们来看一下git对象的内容是：这个树对象的sha-1是：1de9f3f3cb3c87aaf2e43732ae13bf2aff1f8cda，我们会发现这个tree文件下面git对象是我们之前创建的，并不是这一次产生的，这个git对象是cce4bf，我们查看下他的内容如下所示：（这tree对象下面blob是test分支最后生成的内容） 123$ git cat-file -p cce4bfthis is file athis is test branch (file a) 而产生的第二个tree对象是3ada29384374b5219c3564ce1fa999ac4fde99aa是这个，我们发现他的git对象子节点也是之前创建的baf5b9，这个对象的内容是：（这个tree对象下面的blob是master分支第一次产生的内容） 12$ git cat-file -p baf5b9this is file a 这时候我们会发现还有一个git对象blob，这个git对象里面到底是什么东西呢？这会引起我们很大的想象，为什么会产生上面两个tree并指向了之前的git对象呢？下面揭开谜底，原来新生成的blob对象就是a文件产生的冲突文件，文件的sha-1是： 12345678.git/objects/72/038d17664a165e8a0bc65b9b028f3322e7f418 blob$ git cat-file -p 72038dthis is file a&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADthis is master branch=======this is test branch (file a)&gt;&gt;&gt;&gt;&gt;&gt;&gt; this is commit on test branch 这个文件是怎么产生的，这要说一下冲突产生的算法，我喜欢用数学的思维方式思考：给定两个提交 A和 B，合并提交（commit）操作 A∨B 就可以描述为： [A∨B ]=[ A]+[ B]−[ C ] 这里的 C是A 和 B的合并共有项(最近提交树祖先共同含有的部分)，我们必须要“减去” C，因为如果不这样的话，我们就会有两个A∧B。也就是第一个树对象是B也就是不是HEAD指针指向的master分支下的a的内容，HEAD指针下的内容就是A，内容如下： 12this is file athis is master branch A和B的共同之处就是this is file a这个内容（C），A+B-C就是我们现在看到冲突的文件blob（72038d）这时候我们解决完冲突时候，git add . 之后就会生成一个新的blob对象就是这个对象。 1234.git/objects/07/cf0edd220a022c7447a8cf111bac3ed3422db9 blob对象this is file athis is master branchthis is test branch (file a) 这个对象我们在调用git rebase –continue的时候就会产生新的commit对象和tree对象。 123456789101112131415.git/objects/77/14fb6ec6a19ba0d546d1cd10f89261445d3553 commit对象$ git cat-file -p 7714fbtree 000fbac4af12a11f969d5e46d86d135f62adff8bparent 35911829097e90763845733d090e17c32d9a218cauthor BattleHeart &lt;dwlsxj@126.com&gt; 1452168533 +0800committer BattleHeart &lt;dwlsxj@126.com&gt; 1452169355 +0800this is commit on test branch.git/objects/00/0fbac4af12a11f969d5e46d86d135f62adff8b tree对象Administrator@USER-20150201IC MINGW64 ~/Desktop/test (test)$ git cat-file -p 000fba100644 blob 07cf0edd220a022c7447a8cf111bac3ed3422db9 a100644 blob af379ed27a46022aca5a851bc55a8f69fd7afe3a b 这里我们会发现b文件af379e是HEAD指针的指向的master分支的b文件的内容。 1234.git/objects/af/379ed27a46022aca5a851bc55a8f69fd7afe3a blob$ git cat-file -p af379ethis is file bthis is branch master(b) 这时候我们在进行第二次处理冲突内容，也就是b文件的内容，这时候产生的内容和上面的一样的内容。这时候下面的内容就变成这样：（第二部分的分析请读者自行分析）一样的步骤。结构图就变成如下的样子： 整体的commit对象的图就变成这样：(c4’和c5’都是C3的基础上进行合并的) 花絮接下来的内容就是上图中的节点，至于中间产生的节点只有第一次使用git rebase –continue的时候的结果，第二次的结果还请读者自行分析。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849.git/objects/43be0ce752cdabca0968e721fb030000093baa4d commit对象tree eefcff716912aa684576546f63a06f3a52ce0959parent 7714fb6ec6a19ba0d546d1cd10f89261445d3553author BattleHeart &lt;dwlsxj@126.com&gt; 1452168857 +0800committer BattleHeart &lt;dwlsxj@126.com&gt; 1452169398 +0800下面tree对象.git/objects/eefcff716912aa684576546f63a06f3a52ce0959 tree对象$ git cat-file -p eefcff100644 blob 07cf0edd220a022c7447a8cf111bac3ed3422db9 a100644 blob 19f1ba2426ee5e72b95412c2707e75d9feb2833e b下面得内容.git/objects/07cf0edd220a022c7447a8cf111bac3ed3422db9 blob对象在上面tree对象里this is file athis is master branchthis is test branch (file a).git/objects/19/f1ba2426ee5e72b95412c2707e75d9feb2833e blobthis is file bthis is branch master(b)this is test branch (file b)第一次commit对象.git/objects/7714fb6ec6a19ba0d546d1cd10f89261445d3553 commit对象$ git cat-file -p 7714fbtree 000fbac4af12a11f969d5e46d86d135f62adff8bparent 35911829097e90763845733d090e17c32d9a218cauthor BattleHeart &lt;dwlsxj@126.com&gt; 1452168533 +0800committer BattleHeart &lt;dwlsxj@126.com&gt; 1452169355 +0800this is commit on test branch.git/objects/00/0fbac4af12a11f969d5e46d86d135f62adff8b tree对象Administrator@USER-20150201IC MINGW64 ~/Desktop/test (test)$ git cat-file -p 000fba100644 blob 07cf0edd220a022c7447a8cf111bac3ed3422db9 a100644 blob af379ed27a46022aca5a851bc55a8f69fd7afe3a b.git/objects/07/cf0edd220a022c7447a8cf111bac3ed3422db9 blob对象this is file athis is master branchthis is test branch (file a).git/objects/af/379ed27a46022aca5a851bc55a8f69fd7afe3a blob$ git cat-file -p af379ethis is file bthis is branch master(b) git reflog 罗列出所有的commit对象的sha-1码和commit提交内容，看到我们上面merge操作我们想要换药到之前的操作就用git reset –hard HEAD@{5}这里的HEAD@{5}是根据reflog查出来的，hard就是将暂存区内容还原到之前。 四、结束语本文的分析全是有本人自己分析，分析的时间有点长，结果有点有仓促，如果有哪里写的不清楚或者不详细的请指正，小丁再次谢过。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.battleheart.cn/tags/Git/"}]},{"title":"带你走进git-撤销修改","slug":"git-learning-3-revert-operation","date":"2016-01-14T00:48:19.000Z","updated":"2019-04-11T07:35:27.139Z","comments":true,"path":"2016/01/14/git-learning-3-revert-operation/","link":"","permalink":"https://www.battleheart.cn/2016/01/14/git-learning-3-revert-operation/","excerpt":"","text":"一、撤销指令 git checkout还原工作区的功能 git reset 还原暂存区的功能 git clean 还没有被添加进暂存区的文件也就是git还没有跟踪的文件可以使用这个命令清除他们 git revert 撤销本次提交。 二、指令讲解 Git checkout 首先我们对文件的一个修改，对master.txt进行了修改 修改结果我们利用上面的知识来进行查看。 新增加了Test这么一段话，如果我们想要将工作区的内容添加到暂存区会使用git add这个命令，如果我们想要还原工作区内容这时候就要用的git checkout命令，实际上做的工作是用暂存区的内容来覆盖我们工作区的内容。看下面操作： 查看一下git status 发现我们之前的修改被还原了。 这时候我们在对master.txt进行修改并添加到暂存区里面去。修改内容如下 修改完成之后我们来进行提交到暂存区，使用git add 命令。这时候再次查看下状态就变成了changes to be committed的状态。 我们可以使用git reset HEAD（HEAD~2）这种方式进行还原到某一个提交记录上。因为HEAD所指向的commit就是我们想要恢复的内容，也就是我们HEAD指向的commit就是我们要用这些数据覆盖暂存区数据。 这时候我们在git status看一下，暂存区的内容就被还原了。 我们可以使用这种还原工作区 Git checkout v0 — master.txt ,v0是指向首次提交的commit的记录（这里的v0是给commit打的一个tag记录）。我们来看一下工作区和暂存区的区别： 发现少了一行提交内容。我们这时候再用当前HEAD指向的commit还原一下工作区就可以了。 这时候就没有了区别了。使用提交记录还原暂存区的内容格式和checkout是一致的这里就不做演示了。（例如用v0 tag的记录还原暂存区，git reset v0 – master.txt还原指定文件） 在工作区内新建两个文件然后不将文件添加到暂存区内，使用git clean进行清理。 这时候使用git clean –n将要删除的文件展示出来。 这时候再用git clean –f进行删除掉这些文件。 我们在这里新建一个vim .gitignore的文件过滤掉后缀为o和a的文件。 添加到历史记录里面去，然后在新建文件进行清理。 新建了三个文件test.o、test1.a、test2.c这时候我们来使用git clean –n的时候就会显示一条清除记录就是test2.c，默认他不清理gitignore里面的文件。 这里我们正好相反我们想要保留ignore以外的文件，清理掉ignore里面的文件。这时候我们就会用到下面的这个指令git chean -n -X后面跟一个大写的X，我们发现得到了我们想要的结果。 我们执行它，清理掉这些文件。git chean -X –f这时候就清理了.o和.a的文件 我们可以使用git revert产生一个新的提交来覆盖我们不想要的上面的ignore提交记录。git revert HEAD 下面来演示下git revert的工作原理： 第一种情况：当我们第一次提交记录时就revert。当我们用touch 生成一个文件a，生成后将a文件放入到暂存区，这时候就会产生一个a的git对象，这个对象存放在.git/objects目录，如下图所示： 当我们还有add的时候objects文件下面就两个默认文件夹。当git add的时候就会产生一个git对象。 这个就是git对象，一个文件对应一条内容，以该内容加上特定头部信息一起的 SHA-1 校验和为文件命名。 校验和的前两个字符用于命名子目录，余下的 38 个字符则用作文件名。这里不作详解。那么整体的sha-1校验和就是文件名+子目录名。当我调用git commit 的时候会产生一个树对象一个commit对象，并且commit对象指向树对象。 接下来我们来看一下那个sha-1是树对象哪一个是commit对象，并且验证下commit对象下面是不是树对象。 整体生成本次提交的结构如下图所示： 当我们git revert的时候会产生一个新的tree对象，这个tree对象是创建一个撤销上次修改的tree对象。 就变成了现在这个样子了。 还有第二种情况就是我们第二次提交之后再进行revert的时候这时候就会生成一个新的commit指向原来的tree对象。接下来我们就来演示下 首先第一步就是初始化一个仓库这里就不多说了，第二部就是下面图的步骤先新建两个文件a,b两个文件，然后将a和b文件分别添加到暂存区中，这时候就会产生git对象，我们来看一下git对象的类型，确定是blob类型，然后将暂存区的文件提交到记录中。演示如下图所示： 接下来就在查看下.git/objects文件下面生成的对象以及对象的类型，然后我们就开始准备第二题提交，首先编辑下a文件添加到暂存区里面这时候会产生一个git对象（blob）。如下图所示： 这时候就能看到我们新增加的git对象内容以及sha-1。 接下来我们就要查看新生成对象的类型，在进行第二次提交git commit，当我们提交之后会生成新的对象，再看一下新对象类型的属性，刚好查看第一个对象是commit对象看一下他的内容。详细请见下图： 接下来就要看一下tree对象以及tree对象下的元素都有哪些，详情请见下图 那么这是我们看一下它产生的记录结构如下图所示： 当我们revert之后，就会生成一个新的commit将指向第一次提交的tree对象。我们来看一下新生成的commit对象的sha-1。 这时候看一下它产生的记录结构如下图所示： 三、结束语本文内容皆为研究成果以及学习文章后总结，如果上述问题有错误之处请指正，我发现截图太多了，应该换一种方式。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.battleheart.cn/tags/Git/"}]},{"title":"带你走进git-工作区、暂存区、分支","slug":"git-study-2","date":"2016-01-13T11:37:07.000Z","updated":"2018-10-26T06:43:56.086Z","comments":true,"path":"2016/01/13/git-study-2/","link":"","permalink":"https://www.battleheart.cn/2016/01/13/git-study-2/","excerpt":"","text":"Git基本工作流程 初始化一个仓库12git initgit clone git仓库分为两种情况：第一种是在现有项目或目录下导入所有文件到 Git 中； 第二种是从一个服务器克隆一个现有的 Git 仓库 1git init –bare git 创建一个裸仓库 git仓库有三个区域 工作区working directory日常编辑代码的地方 历史仓库history repository是commit指向的一个树形结构 暂存区Staging area相当于是工作区与历史提交中间的缓存，它代表着是你要提交代码的一个工作状态，它维护的是一个虚拟的树形结构 讲述完了git的区域，接下来讲解下git文件的状态，其实git的状态无外乎两种：已跟踪和未跟踪，已跟踪的文件说明的是被纳入版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后，它们的状态可能处于未修改，已修改或已放入暂存区。 工作目录中除已跟踪文件以外的所有其它文件都属于未跟踪文件，它们既不存在于上次快照的记录中，也没有放入暂存区。 初次克隆某个仓库的时候，工作目录中的所有文件都属于已跟踪文件，并处于未修改状态。 讲解下文件变化周期，比如我们在项目中添加了一个文件a,这时候文件a处于的状态则是Untracked未跟踪状态，当我们git add的时候这时候就会将文件放到暂存区中这时候状态变为Stage，当我们commit这个暂存区的文件后这个文件就变成未修改状态，因为没有进行修改过了相对于版本控制中的文件，当我们修改了a文件后这时候从unmodified变成modified（修改状态），这是再git add的时候就会将修改的文件变成stage，放入暂存区用于等待commit。 接下来就详细讲解下这些命令：往暂存区里面添加东西使用如下git指令 1git add 从暂存区提交到历史记录使用如下指令 1git commit 查看工作区和暂存区之间的区别，来确保提交时我们所需要的呢？ 1git status 从暂存区里面删除内容 1git rm 工作区内重命名文件或者移动文件，然后再把他们添加到暂存区 1git mv 确保工作区内里面不需要的文件不被添加进去添加到暂存区和历史。 1.gitignore 实例讲解 新建一个仓库，并且新建一个文件a，将其添加到暂存区。 1234git init git_initcd git_inittouch a //新建a文件git add a //将a添加到暂存区 git status会显示我们要提交的内容a文件，这时候a两个文件都是Changes to be committed也就是待commit的状态。 123456$ git statusOn branch masterChanges to be committed:(use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: agit commit -m “initial commit”//提交a文件到版本控制中。 touch b新建文件b，将其放入暂存区，观察\bgit status返回的状态信息。 12touch b //新建文件bgit add b //将b放入暂存区中 12345$ git statusOn branch masterChanges to be committed:(use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: b 编辑一下a文件，这时候在调用git status 123456$ git statusOn branch masterChanges to be committed:(use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: a new file: bb 这时候a文件是出于修改状态，那么如果我们在进行修改a文件时候，在调用下git status会发生什么奇怪的事呢？let’s go。 12345678910$ git statusOn branch masterChanges to be committed:(use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: a new file: bbChanges not staged for commit:(use &quot;git add &lt;file&gt;...&quot; to update what will be committed)(use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: a 这时候我们会发现两个modified a，这是为什么呢？但是两个文件分别存在暂存区和非暂存区，实际上暂存区内只保存了git add的版本，而最新修改的一份没有提交到暂存区内还在工作区域中，所以我们会看到两个，如果这时候调用git commit的话就只会讲已经在暂存区的文件存入到版本控制中，而最新修改的那一次记录没有被提交。当然这里还提供了跳过暂存区的方法就是git commit –a –m“注释内容”可以直接跳过暂存区直接提交到记录里面去。 将a移除整个项目 1git rm a 清楚缓存中的内容，也就是已经暂存的文件 1git rm a –cached 给文件重命名将a文件名换成c 1git mv a c Git暂存区假设工作区里面有这么一些文件如下图所示： 在第一次add都还没有进行的时候，暂存区还没有被创建出来，当我们add的时候会创建一个暂存区出来（文件分开add产生两个数据对象），如下图所示： .git目录下面多了一个index的文件，那么这个index文件就是我们所说的暂存区的文件，那么每一条索引都是hash值表示以及它对应的文件名。每个索引还包含了他的文件模式权限还有status number来表示他的合并状态、时间戳等。每一个索引都是跟对象库的文件是对应的。比如说file.txt这里对应的是标号1，那么file2.txt对应的就是标号2(上图所示标号)，这个index里面除了维护了索引之外还维护了提前计算好的tree对象的内容，也就是我们的顶层的目录tree以及folder的tree对象内容，当我们提交的时候他可以迅速的根据我们已经计算好的内容生成一个tree对象，然后添加到历史记录里面。 当我们修改了file2.txt的时候，这时候git add到暂存区时，发现对象库里面新创了一个对象，那么暂存区的这条索引就被指向新对象的索引替换掉。这时候git暂存区又从新计算了下顶层目录tree对象的一个内容。当我们提交的时候我们直接使用已经计算好的内容创建好一个新的tree对象，生成一个commit对象将master分支上面的HEAD指针指向当前commit对象上去。如下图所示： 这里的标号8指向的就是新生成的commit对象。 Git本地分支与合并 创建分支git branch 给固定的commit做标记 git tag 分支之间进行切换 git checkout 切换分支之前保存本地修改 git stash 合并分支 git merge 例子创建一个分支名字叫test并切换到当前的分支上去。 这时候分支的名称不再是master而是改变成为test分支。编辑下a文件用test分支进行提交 切换到master分支上面我们看一下a的内容 并没有test分支在a中添加的内容这时候我们切换分支时会使用我们分支上最新的一个提交来还原我们的暂存区和工作区内容，那么可以让我们在不同的分支之间独立的做自己的工作。 1git log –oneline –decorate –graph –all 我们可以看到提交的记录或提交这些提交的引用 给第一个提交加一个名称tag 1git tag “v0” f6699b3 在查看下git log –oneline –decorate –graph –all 多了一个tag：v0使用git show v0查看下内容，这是打的tag是一个轻量级的只是一个固定的引用。 而使用git tag –a的方式进行添加时会是一个tag对象，他有tag的属性，包括提交人时间等信息。 Tag指向了一个提交commit Tag也可以使用checkout进行操作 但是它当前的没有指向一个分支而是指向了一个commit，这时候就会出现一个问题就是我们切换分支的时候这一部分内容就有可能被遗弃掉，也就是说head引用直接指向了一个commit而不是一个分支名，checkout提供了针对当前commit新建一个分支的方法并切换到当前分支。 1git checkout -b “ttt_v0” 接下来切换master分支 这时候会用的git stash进行保存工作区，因为我们切换checkout的时候会覆盖掉当前的内容所以我们先将其保存起来。如果想要保存暂存区就可以使用-a来保存。 1Git stash save -a “stash1” 这时候我们来查看下缓存区状态git status的时候是很干净的如下图： 下面我们切换到master分之下，在切换会ttt_v0下时我们要还原stash里面的内容 会有一个stash的缓存内容存在，下面我们来恢复stash里面的内容，并将缓存区内容还原。 git stash pop –index stash@{0} 这里的标记红色的表示stash里面的第0个stash 我们会发现之前修改的a文件已经在暂存区内贮备提交了 使用git stash apply –index stash@{0}这种方式时git stash list里面的内容是不会被清理掉的这里–index是恢复暂存区内容 使用git stash drop stash@{0}清除掉，如果不加stash@{0}引用的话他默认会清楚stash栈最上面的一个。 清楚多个stash的时候使用git stash clear 查看与对比历史记录 git show git log git diff 输入git log –oneline –decorate –graph –all查看完整的历史示意图。 git log -p常用的选项是 -p，用来显示每次提交的内容差异， 你也可以加上 -2 来仅显示最近两次提交： 我们可以根据查看git show f6699b3的信息 最新的一次提交可以用git show master 或者git show HEAD，也可以使用git show master^表示master分支的第一次提交master^2表示第二次提交 通常我们会用git diff来回答两个问题：第一个就是当前做了什么还没有提交暂存区？第二个问题就是当前那些文件已经暂存了等待提交？ git diff 这个命令是查看当前工作区与暂存区快照的差异，也就是那些还没有暂存起来。 图中显示的是暂存区和工作区的区别在于a文件被修改了添加了next edit file。请注意，git diff 本身只显示尚未暂存的改动，而不是自上次提交以来所做的所有改动。 所以有时候你一下子暂存了所有更新过的文件后，运行 git diff 后却什么也没有，就是这个原因。 回顾： 所谓的分支就是一个commit记录的引用如下图所示： 在这些分支上工作会产生各自的历史记录（commit记录）所谓的分支切换就是指的Head指针的切换以及暂存区和工作区的一个还原，比如说我们现在当前Head指向的位置处再建两个分支之后他们所指向的commit都是同一个如下图所示： 分支切换后如下图所示： 而tag指向了一个固定的commit记录，如下图所示： 分为两种一种是轻量级的一种是标签对象，主要区别就是轻量级的tag只是一个固定的连接，但是标签对象就是创建标签的时候会产生一个标签对象，这个标签对象存储在.git/object目录里面，tag对象里面包括对数据对象的指向，以及创建时间数据对象类型和创建人等信息。 举个例子来说明一下分支切换以及合并： 开始的状态是这样的，我们提交了三次commit后的示意图如下： 当我们使用了git branch test的时候，将会在当前位置处新建一个分支，分支的名称叫test，但是分支并没有切换依然是master分支（Head的指向）如下图所示： 我们在master分支上面工作会产生master分支上面的commit记录如下图所示： 这个时候我们是用git checkout test的时候HEAD指针就会指向test，并且还原暂存区和工作区内容。如下图所示： 继续在test分支上面进行工作，会产生test对应分支上面的commit记录 我们来说一下合并，合并分为两种一种是fast-farword merge也就是说test所指向的commit记录他其实是master所指向的commit所衍生出来的如下图所示： 蓝色部分是master分支，红色部分是master分支所衍生出来的分支。这时候我们在master分支上面进行合并git merge test不会产生新的commit记录出来，master分支指向test分支所指向的commit记录上去，然后把工作区和暂存区还原成了test的暂存区和工作区内容。如下图所示： 另外一种就是non-fast-farword merge也就是我们的三方合并。 我们可以看到master指向的commit和test只想的commit有一个共同的父节点就是70e4d8这个节点。Master指向的commit和test指向的commit并没有一个衍生的关系，这时候我们在master分支上面git merge test，会生成一个新的commit来承载两个分支的历史内容 五、结束语这篇文章非一天写完的我也是在学习的过程中总结，以及参考大婶们写的文章加自己的理解写成的，如果这里有些错的或者有雷同的请各位大神指点一二。小丁谢过，写一篇文章确实不容易，能支持的就支持下不能支持的就当没看过这篇文章就好了。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.battleheart.cn/tags/Git/"}],"author":"BattleHeart"},{"title":"带你走进git-基础配置","slug":"git-config","date":"2016-01-13T05:00:37.000Z","updated":"2018-10-26T06:00:34.565Z","comments":true,"path":"2016/01/13/git-config/","link":"","permalink":"https://www.battleheart.cn/2016/01/13/git-config/","excerpt":"","text":"git的简单配置配置提交代码的信息，例如是谁提交的代码之类的。 12git config –global user.name BattleHeaert 这里是设置提交代码的人的名称git config –global user.email github@126.com 这里是设置提交代码的人的邮箱 查看当前的用户名 1git config user.name 或者 1git config –get user.name 这时候会显示BattleHeart这个用户名，但是如果我们再添加一个用户的名称的时候这时候就会显示最后一个添加的用户名 1git config –global –add user.name BH 当我们再次使用git config user.name时这时候显得是就是BH如下图所示我们可以使用如下指令来列出基本的信息 1git config –global –list 基本信息如下图所示（这里其实是有两个user.name的结果，只不过使用的是最后一个值）那么我们来取消一个user.name使用以下指令来进行操作 1git config –global –unset user.name BH 这里user.name后面必须添加上取消的name的名称否则它是找不到你要取消那个名称的，会提示警告user.name有多个值。 如果只有一个键值对的时候就可以不用带后面name的名称直接使用如下方式即可 1git config –global –unset user.name 修改一个键值对的内容 1git config –global user.name BH 修改后的结果如下图 给git子命令的参数起别名例如给checkout起别名叫co 1git config –global alias.co checkout 设置带参数的命令别名给log –online起别名如下所示 1git config –global alias.lol “log –online” 结束语献给所有新学Git的系列，这是文章的开篇，后续会陆陆续续将文章发布出来。如果文章用有不正确的地方请给我大神指点，小丁在此谢过了。","categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.battleheart.cn/tags/Git/"}],"author":"BattleHeart"}],"categories":[{"name":"个人技术","slug":"个人技术","permalink":"https://www.battleheart.cn/categories/个人技术/"},{"name":"生活杂谈","slug":"生活杂谈","permalink":"https://www.battleheart.cn/categories/生活杂谈/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://www.battleheart.cn/tags/并发编程/"},{"name":"多线程","slug":"多线程","permalink":"https://www.battleheart.cn/tags/多线程/"},{"name":"C++","slug":"C","permalink":"https://www.battleheart.cn/tags/C/"},{"name":"Assembly","slug":"Assembly","permalink":"https://www.battleheart.cn/tags/Assembly/"},{"name":"栈","slug":"栈","permalink":"https://www.battleheart.cn/tags/栈/"},{"name":"Git","slug":"Git","permalink":"https://www.battleheart.cn/tags/Git/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://www.battleheart.cn/tags/Spring-Boot/"},{"name":"dubbo","slug":"dubbo","permalink":"https://www.battleheart.cn/tags/dubbo/"},{"name":"Java","slug":"Java","permalink":"https://www.battleheart.cn/tags/Java/"},{"name":"Shiro","slug":"Shiro","permalink":"https://www.battleheart.cn/tags/Shiro/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.battleheart.cn/tags/Hexo/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.battleheart.cn/tags/SpringCloud/"},{"name":"ELK","slug":"ELK","permalink":"https://www.battleheart.cn/tags/ELK/"},{"name":"Maven","slug":"Maven","permalink":"https://www.battleheart.cn/tags/Maven/"},{"name":"Life","slug":"Life","permalink":"https://www.battleheart.cn/tags/Life/"}]}